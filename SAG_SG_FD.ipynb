{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projet de IFT6512 de François David  -  Matricule: 20171906\n",
    "### Enseignant: Dr. Fabian Bastin\n",
    "#### Université de Montréal - Hiver 2020  - Jeudi, le 30 Avril, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce projet, je compare les 3 méthodes d'algorithmes de convergence discutés dans l'article “Minimizing Finite Sums with Stochastic Average Gradient” écrit par Mark Schmidt, Nicolas Le Roux & Francis Bach. \n",
    "Les trois méthodes sont le Stocastic Gradient (SG), le Finite Difference  (FD) ainsi que le Stochastic Average Gradient (SAG). Par la suite, je discute les conditions d'arrêts des algorithmes et je les compare avec une technique de rétrospective approximation. Chacun de ceux-ci est testé sur le MNIST, un exercice de classification d'images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies nécessaire.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import gzip\n",
    "from random import randint\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de fonction qui charge le DataSet \"MNIST\", pour la classification d'images de chiffres écrits à la main allants de 0 à 9, chaque image est composé de 784 pixels. J'ai décidé d'utiliser toutes les 50 000 images accessibles de l'ensemble d'apprentissage et toutes les images de l'ensemble de validation disponnibles (5000).\n",
    "Il y  a donc 50 000 paires d'images et de labels (numéro correspondant à ce que l'image associée représente) pour l'entrainement,  5000 paires pour la validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, n_classes=10):\n",
    "    return np.eye(n_classes)[y]\n",
    "def load_mnist():\n",
    "    data_file = gzip.open(\"mnist.pkl.gz\", \"rb\")\n",
    "    train_data, val_data, test_data = pickle.load(data_file, encoding=\"latin1\")\n",
    "    data_file.close()\n",
    "\n",
    "    train_inputs = [np.reshape(x, (784, 1)) for x in train_data[0][:20000]]\n",
    "    train_results = [one_hot(y, 10) for y in train_data[1][:20000]]\n",
    "    train_data = np.array(train_inputs).reshape(-1, 784), np.array(train_results).reshape(-1, 10)\n",
    "\n",
    "    val_inputs = [np.reshape(x, (784, 1)) for x in val_data[0][:3000]]\n",
    "    val_results = [one_hot(y, 10) for y in val_data[1][:3000]]\n",
    "    val_data = np.array(val_inputs).reshape(-1, 784), np.array(val_results).reshape(-1, 10)\n",
    "\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y, n_classes=10):\n",
    "    return np.eye(n_classes)[y]\n",
    "def load_mnist():\n",
    "    data_file = gzip.open(\"mnist.pkl.gz\", \"rb\")\n",
    "    train_data, val_data, test_data = pickle.load(data_file, encoding=\"latin1\")\n",
    "    data_file.close()\n",
    "\n",
    "    train_inputs = [np.reshape(x, (784, 1)) for x in train_data[0]]\n",
    "    train_results = [one_hot(y, 10) for y in train_data[1]]\n",
    "    train_data = np.array(train_inputs).reshape(-1, 784), np.array(train_results).reshape(-1, 10)\n",
    "\n",
    "    val_inputs = [np.reshape(x, (784, 1)) for x in val_data[0]]\n",
    "    val_results = [one_hot(y, 10) for y in val_data[1]]\n",
    "    val_data = np.array(val_inputs).reshape(-1, 784), np.array(val_results).reshape(-1, 10)\n",
    "\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition des fonctions nécessaire pour les algorithms, mais communes au 3 algorithmes.  Certaines petites parties de code ont été adapté du repository git : https://github.com/CW-Huang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights( dims, hidden_dims):\n",
    "        weights = {}\n",
    "        # Dictionnaire pour les bias et weights de chaque layers\n",
    "        all_dims = [dims[0]] + list(hidden_dims) + [dims[1]]\n",
    "       \n",
    "        for layer_n in range(1, len(hidden_dims) + 2):\n",
    "            # Initialize biases to 0.\n",
    "            weights[f\"b{layer_n}\"] = np.zeros((1, all_dims[layer_n]))\n",
    "            # glorot initialization.\n",
    "            dl = np.sqrt(6)/np.sqrt(all_dims[layer_n - 1] + all_dims[layer_n])\n",
    "            weights[f\"W{layer_n}\"] = np.random.uniform(-dl, dl, (all_dims[layer_n - 1], all_dims[layer_n]))\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction de propagation vers l'avant, commune au 3 algorithmes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " def forward(x, weights, hidden_dims):\n",
    "        cache = {\"Z0\": x}\n",
    "        for layer in range(1, len(hidden_dims) + 2):\n",
    "            # Créer  une variable qui va calculer les chaques inputs avec les  weights + le bias. \n",
    "            cache[f\"A{layer}\"] = np.dot(cache[f\"Z{layer-1}\"], weights[f\"W{layer}\"]) + weights[f\"b{layer}\"]\n",
    "            if layer == len(hidden_dims) + 1:\n",
    "                # Activation  de l'output pour créer une distribution de probabilité.\n",
    "                cache[f\"Z{layer}\"] = softmax(cache[f\"A{layer}\"])\n",
    "            else:\n",
    "                # Activation de cette layer.\n",
    "                cache[f\"Z{layer}\"] = relu(cache[f\"A{layer}\"])\n",
    "        return cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour transformer les outputs en une distribution discrete de probabilité, commune au 3 algorithmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "        if len(x.shape) == 1:\n",
    "            newVector = np.exp(x - np.max(x))\n",
    "            return newVector / np.sum(newVector, axis=0, keepdims=True)\n",
    "        else:\n",
    "            newVector = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "            return newVector / np.sum(newVector, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction d'activation, commune au 3 algorithmes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x, grad=False):\n",
    "        #print(\"Shape : \", x.shape, \"Negative: \", np.count_nonzero(x < 0), \"Positive: \", np.count_nonzero(x > 0))\n",
    "        if grad:\n",
    "            x[x <= 0.0] = 0.0\n",
    "            x[x > 0.0] = 1.0\n",
    "            # print(x)\n",
    "            #print(\"Shape : \", x.shape, \"Negative: \", np.count_nonzero(x < 0), \"Positive: \", np.count_nonzero(x > 0))\n",
    "            return x\n",
    "        return np.maximum(x, 0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction de Backpropagatin, commune au 3 algorithmes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(weights, cache, labels, hidden_dims):\n",
    "        output = cache[f\"Z{len(hidden_dims) + 1}\"]\n",
    "        grads = {} # Dictionnaire des gradients\n",
    "        grads[f\"dA{len(hidden_dims) + 1}\"] = - (labels - output)\n",
    "\n",
    "        for layer in range(len(hidden_dims) + 1, 0 , -1):\n",
    "            #m  = grads[f\"dA{layer}\"].shape[0]\n",
    "            #print(\"shape: \", m)\n",
    "            grads[f\"dW{layer}\"] = np.dot(grads[f\"dA{layer}\"].T, cache[f\"Z{layer -1}\"]).T\n",
    "            grads[f\"db{layer}\"] = np.sum(grads[f\"dA{layer}\"], axis=0, keepdims=True)\n",
    "\n",
    "            if layer != 1:\n",
    "                grads[f\"dZ{layer - 1}\"] = np.dot(weights[f\"W{layer}\"], grads[f\"dA{layer}\"].T).T\n",
    "                grads[f\"dA{layer - 1}\"] = grads[f\"dZ{layer - 1}\"] * relu(cache[f\"A{layer - 1}\"], True)\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " def lossCalculation(prediction, labels):\n",
    "        # Pour une marge de manoeuvre.\n",
    "        epsilon=1e-6 \n",
    "        prediction[np.where(prediction < epsilon)] = epsilon\n",
    "        prediction[np.where(prediction > 1 - epsilon)] = 1 - epsilon\n",
    "        crossEntropy = -sum(np.multiply(labels, np.log(prediction)))\n",
    "\n",
    "        return np.sum(crossEntropy)\n",
    "\n",
    "def compute_loss_and_accuracy(X, y, weights, hidden_dims):\n",
    "        one_y = y\n",
    "        y = np.argmax(y, axis=1) \n",
    "        cache = forward(X, weights, hidden_dims)\n",
    "        predictions = np.argmax(cache[f\"Z{len(hidden_dims) + 1}\"], axis=1)\n",
    "        accuracy = np.mean(y == predictions)\n",
    "        loss = lossCalculation(cache[f\"Z{len(hidden_dims) + 1}\"], one_y)\n",
    "        return loss, accuracy, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(grads, weights, hidden_dims, alpha):\n",
    "        for layer in range(1, len(hidden_dims) + 2):\n",
    "            weights[f\"W{layer}\"] = weights[f\"W{layer}\"] - (alpha * grads[f\"dW{layer}\"])\n",
    "            weights[f\"b{layer}\"] = weights[f\"b{layer}\"] - (alpha * grads[f\"db{layer}\"])\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture choisie du réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la comparaison des algorithmes, j'ai décidé d'utiliser une architecture qui est composée de deux étages cachés de 64 et 32 neurones. J'ai tenté d'utiliser des étages plus volumineux mais étant donné que pour l'algorithme du SAG nous devons garder en mémoire tous les gradients, la mémoire requise était trop volumineuse pour l'exécution du programme (même en Pyhton native). Le premier étage du réseau est composé de 784 neurones (une par pixel des images du MNIST) et le dernier étage est composé de 10 neurones (pour la classification de 0 à 9). L'initialisation des poids (weights) et biais de l'architecture est faite avec la technique de Glorot. De plus, j'utilise la technique d'activation non-linéaire Relu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même avec cette architecture relativement réduite, le nombre de gradients qu'il faut garder en mémoire par paires de données d'entrainement est de $784 \\times  64 + 64 \\times 32 + 32 \\times 10  + 784 + 64 + 32 = 53424$ ce qui est relativement large considèrent que l'ensemble d'apprentissage est composé  de 50 000 paires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les modifications pour le Stocastic  Gradient Algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le training loop de l'algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À chaque itération, je génère un index aléatoire entre 0 et la taille de l'ensemble d'apprentissage (50 000) pour pouvoir utiliser qu'une seule des paires de cet ensemble. Le gradient est calculé (à cette itération) avec la paire choisie avec la backpropagation et les weights sont modifiés en fonction de celui-ci. Le cout d'itérations est donc constant et n'est pas en fonction de la taille de l'ensemble , soit n, comme dans l'algorithme du Finite Gradient. Le taux de convergence reste tout de même de $O(1/k)$ par itération (taux de convergence sous-linéaire)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loopSG(n_epochs):\n",
    "    train_logs = {'train_accuracySG': [], 'validation_accuracySG': [], 'train_lossSG': [], 'validation_lossSG': [], 'time': []}\n",
    "    X_train, y_train = train\n",
    "    y_onehot = y_train\n",
    "    dims = [X_train.shape[1], y_onehot.shape[1]]\n",
    "    hidden_dims = hidden_dims = (64, 32)\n",
    "    weights = initialize_weights(dims, hidden_dims)\n",
    "    batch_size = 1\n",
    "    alpha = 3.5e-2\n",
    "    n_batches = 50000\n",
    "    previousLoss = 2147483647 # Le plus grand integer possible (python)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 1000 == 0 or epoch == 1 or epoch == 501:\n",
    "            start = timeit.default_timer()\n",
    "        #  Selection d'un index aléatoire dépendament du nombre de donnée dans le training data.\n",
    "        indexAleatoire = randint(0, n_batches)\n",
    "        minibatchX = X_train[batch_size * indexAleatoire:batch_size * (indexAleatoire + 1), :]\n",
    "        minibatchY = y_onehot[batch_size * indexAleatoire:batch_size * (indexAleatoire + 1), :]\n",
    "        cache = forward(minibatchX, weights, hidden_dims)\n",
    "        grads = backward(weights, cache, minibatchY, hidden_dims)\n",
    "        weights = update(grads, weights, hidden_dims, alpha)\n",
    "\n",
    "        if epoch % 1000 == 999 or epoch == 0 or epoch == 500:\n",
    "            X_train, y_train = train\n",
    "            train_loss, train_accuracy, _ = compute_loss_and_accuracy(X_train, y_train, weights, hidden_dims)\n",
    "            X_valid, y_valid = valid\n",
    "            valid_loss, valid_accuracy, _ = compute_loss_and_accuracy(X_valid, y_valid, weights, hidden_dims)\n",
    "            stop = timeit.default_timer()\n",
    "\n",
    "            # Imprimer la loss et la precision. Ça l'aide a suivre le progrès\n",
    "            print(f\"Epoch {epoch} : Train Accuracy : {train_accuracy}, \\tValid  Accuracy : {valid_accuracy},\\t Train Loss : {train_loss}, \\tValid Loss :  {valid_loss}, \\t Time for 1000 Epochs: {stop - start}\")\n",
    "            \n",
    "        # Ajuster le taux d'apprentissage si pas de déscente\n",
    "        if train_loss > previousLoss:\n",
    "            alpha  = alpha  *  .999999999\n",
    "        previousLoss = train_loss\n",
    "        \n",
    "        train_logs['train_accuracySG'].append(train_accuracy)\n",
    "        train_logs['validation_accuracySG'].append(valid_accuracy)\n",
    "        train_logs['train_lossSG'].append(train_loss)\n",
    "        train_logs['validation_lossSG'].append(valid_loss)\n",
    "        train_logs['time'].append(stop - start)\n",
    "        \n",
    "\n",
    "    return train_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Train Accuracy : 0.08144, \tValid  Accuracy : 0.0822,\t Train Loss : 122796.04174478057, \tValid Loss :  24455.056903564644, \t Time for 1000 Epochs: 0.5547342349891551\n",
      "Epoch 500 : Train Accuracy : 0.59038, \tValid  Accuracy : 0.6077,\t Train Loss : 59935.42572618314, \tValid Loss :  11479.655458592179, \t Time for 1000 Epochs: 0.7936142139951698\n",
      "Epoch 999 : Train Accuracy : 0.76578, \tValid  Accuracy : 0.7864,\t Train Loss : 35844.083468580466, \tValid Loss :  6631.835288689429, \t Time for 1000 Epochs: 0.8010772799898405\n",
      "Epoch 1999 : Train Accuracy : 0.82346, \tValid  Accuracy : 0.8384,\t Train Loss : 29084.345323703685, \tValid Loss :  5212.778018040548, \t Time for 1000 Epochs: 0.8726126739929896\n",
      "Epoch 2999 : Train Accuracy : 0.80194, \tValid  Accuracy : 0.8257,\t Train Loss : 32747.45250612174, \tValid Loss :  5731.721896061396, \t Time for 1000 Epochs: 0.8308217450103257\n",
      "Epoch 3999 : Train Accuracy : 0.84374, \tValid  Accuracy : 0.8597,\t Train Loss : 25563.3048405344, \tValid Loss :  4583.749289244016, \t Time for 1000 Epochs: 0.808096389984712\n",
      "Epoch 4999 : Train Accuracy : 0.8249, \tValid  Accuracy : 0.845,\t Train Loss : 38162.5976560469, \tValid Loss :  6709.845535051513, \t Time for 1000 Epochs: 0.8733168019971345\n",
      "Epoch 5999 : Train Accuracy : 0.84402, \tValid  Accuracy : 0.8507,\t Train Loss : 26688.840084278272, \tValid Loss :  4985.450956605885, \t Time for 1000 Epochs: 0.8646310780022759\n",
      "Epoch 6999 : Train Accuracy : 0.76896, \tValid  Accuracy : 0.7748,\t Train Loss : 47410.07082852311, \tValid Loss :  9064.327081306154, \t Time for 1000 Epochs: 0.9074168789957184\n",
      "Epoch 7999 : Train Accuracy : 0.88876, \tValid  Accuracy : 0.8969,\t Train Loss : 18626.37957432075, \tValid Loss :  3374.4877484052595, \t Time for 1000 Epochs: 0.8382639119809028\n",
      "Epoch 8999 : Train Accuracy : 0.85998, \tValid  Accuracy : 0.8606,\t Train Loss : 22561.42064960111, \tValid Loss :  4300.69540531635, \t Time for 1000 Epochs: 0.9504991540161427\n",
      "Epoch 9999 : Train Accuracy : 0.88258, \tValid  Accuracy : 0.8893,\t Train Loss : 20868.944990737, \tValid Loss :  3806.4002103518274, \t Time for 1000 Epochs: 0.8856308199756313\n",
      "Epoch 10999 : Train Accuracy : 0.90066, \tValid  Accuracy : 0.9107,\t Train Loss : 17394.250887033468, \tValid Loss :  3094.3009436950174, \t Time for 1000 Epochs: 0.806181577994721\n",
      "Epoch 11999 : Train Accuracy : 0.88616, \tValid  Accuracy : 0.8984,\t Train Loss : 20643.324022288027, \tValid Loss :  3710.377234188463, \t Time for 1000 Epochs: 0.8714874570141546\n",
      "Epoch 12999 : Train Accuracy : 0.8985, \tValid  Accuracy : 0.9053,\t Train Loss : 18167.512338563214, \tValid Loss :  3334.6471707680607, \t Time for 1000 Epochs: 0.8201629940012936\n",
      "Epoch 13999 : Train Accuracy : 0.91018, \tValid  Accuracy : 0.9182,\t Train Loss : 16383.874541548841, \tValid Loss :  3036.275372134155, \t Time for 1000 Epochs: 0.8985960950085428\n",
      "Epoch 14999 : Train Accuracy : 0.91644, \tValid  Accuracy : 0.9194,\t Train Loss : 14781.185825634995, \tValid Loss :  2763.7152603704144, \t Time for 1000 Epochs: 0.8449713820009492\n",
      "Epoch 15999 : Train Accuracy : 0.90836, \tValid  Accuracy : 0.9152,\t Train Loss : 17781.93679290615, \tValid Loss :  3299.7083858567494, \t Time for 1000 Epochs: 0.8257500579929911\n",
      "Epoch 16999 : Train Accuracy : 0.92134, \tValid  Accuracy : 0.9287,\t Train Loss : 14073.861545944348, \tValid Loss :  2530.198362120897, \t Time for 1000 Epochs: 0.9799237670085859\n",
      "Epoch 17999 : Train Accuracy : 0.88902, \tValid  Accuracy : 0.8919,\t Train Loss : 17146.619550278665, \tValid Loss :  3309.5896241641994, \t Time for 1000 Epochs: 0.995992458978435\n",
      "Epoch 18999 : Train Accuracy : 0.90452, \tValid  Accuracy : 0.9126,\t Train Loss : 17387.76517818128, \tValid Loss :  3225.8938181215944, \t Time for 1000 Epochs: 0.904352913988987\n",
      "Epoch 19999 : Train Accuracy : 0.9104, \tValid  Accuracy : 0.9197,\t Train Loss : 16934.979538691263, \tValid Loss :  3076.7101593287434, \t Time for 1000 Epochs: 0.8330356299993582\n",
      "Epoch 20999 : Train Accuracy : 0.90712, \tValid  Accuracy : 0.913,\t Train Loss : 17749.493736722714, \tValid Loss :  3247.4749796521546, \t Time for 1000 Epochs: 0.9777040039771236\n",
      "Epoch 21999 : Train Accuracy : 0.90512, \tValid  Accuracy : 0.9112,\t Train Loss : 17137.948839059303, \tValid Loss :  3273.232689289818, \t Time for 1000 Epochs: 0.9154429449990857\n",
      "Epoch 22999 : Train Accuracy : 0.8996, \tValid  Accuracy : 0.9073,\t Train Loss : 18096.298170681504, \tValid Loss :  3251.092402647662, \t Time for 1000 Epochs: 0.9520180109830108\n",
      "Epoch 23999 : Train Accuracy : 0.92762, \tValid  Accuracy : 0.9305,\t Train Loss : 12915.361531204186, \tValid Loss :  2369.466113172745, \t Time for 1000 Epochs: 0.8367174149898347\n",
      "Epoch 24999 : Train Accuracy : 0.90726, \tValid  Accuracy : 0.9138,\t Train Loss : 17413.10633660872, \tValid Loss :  3320.716642741432, \t Time for 1000 Epochs: 0.8713417190010659\n",
      "Epoch 25999 : Train Accuracy : 0.92092, \tValid  Accuracy : 0.9262,\t Train Loss : 14754.607767971193, \tValid Loss :  2732.9991164297885, \t Time for 1000 Epochs: 0.9198248710017651\n",
      "Epoch 26999 : Train Accuracy : 0.9206, \tValid  Accuracy : 0.9249,\t Train Loss : 14325.535939423562, \tValid Loss :  2722.2741830345103, \t Time for 1000 Epochs: 0.888002525025513\n",
      "Epoch 27999 : Train Accuracy : 0.92904, \tValid  Accuracy : 0.9358,\t Train Loss : 13108.634935953198, \tValid Loss :  2433.0677335333016, \t Time for 1000 Epochs: 0.8750660670048092\n",
      "Epoch 28999 : Train Accuracy : 0.90664, \tValid  Accuracy : 0.909,\t Train Loss : 15491.256790089055, \tValid Loss :  2916.3538039246305, \t Time for 1000 Epochs: 1.1414354509906843\n",
      "Epoch 29999 : Train Accuracy : 0.91574, \tValid  Accuracy : 0.9185,\t Train Loss : 16139.211939358705, \tValid Loss :  3083.1936551663066, \t Time for 1000 Epochs: 1.0151273149822373\n",
      "Epoch 30999 : Train Accuracy : 0.92288, \tValid  Accuracy : 0.9233,\t Train Loss : 13622.628639736271, \tValid Loss :  2689.54410378034, \t Time for 1000 Epochs: 0.9651821760053281\n",
      "Epoch 31999 : Train Accuracy : 0.91656, \tValid  Accuracy : 0.9196,\t Train Loss : 15558.821648141413, \tValid Loss :  3083.757656949998, \t Time for 1000 Epochs: 0.9667071140138432\n",
      "Epoch 32999 : Train Accuracy : 0.91858, \tValid  Accuracy : 0.9205,\t Train Loss : 14960.468297561481, \tValid Loss :  2952.4774053789993, \t Time for 1000 Epochs: 0.8479625949985348\n",
      "Epoch 33999 : Train Accuracy : 0.92912, \tValid  Accuracy : 0.9311,\t Train Loss : 14017.133197892774, \tValid Loss :  2695.6308980934505, \t Time for 1000 Epochs: 0.854279482999118\n",
      "Epoch 34999 : Train Accuracy : 0.9307, \tValid  Accuracy : 0.9342,\t Train Loss : 12770.582162533849, \tValid Loss :  2502.744093569552, \t Time for 1000 Epochs: 0.8638913430040702\n",
      "Epoch 35999 : Train Accuracy : 0.89036, \tValid  Accuracy : 0.8967,\t Train Loss : 18151.687401062984, \tValid Loss :  3591.719433234926, \t Time for 1000 Epochs: 0.8705018350156024\n",
      "Epoch 36999 : Train Accuracy : 0.91326, \tValid  Accuracy : 0.9149,\t Train Loss : 16479.72087528542, \tValid Loss :  3291.0537866990976, \t Time for 1000 Epochs: 0.903924066980835\n",
      "Epoch 37999 : Train Accuracy : 0.91954, \tValid  Accuracy : 0.9271,\t Train Loss : 14855.471240688024, \tValid Loss :  2668.120697197767, \t Time for 1000 Epochs: 0.9200523819890805\n",
      "Epoch 38999 : Train Accuracy : 0.92362, \tValid  Accuracy : 0.9291,\t Train Loss : 13552.744406338355, \tValid Loss :  2643.3458206560904, \t Time for 1000 Epochs: 0.8730741890030913\n",
      "Epoch 39999 : Train Accuracy : 0.93562, \tValid  Accuracy : 0.9335,\t Train Loss : 11996.627590450275, \tValid Loss :  2454.957819769035, \t Time for 1000 Epochs: 0.8817156960139982\n",
      "Epoch 40999 : Train Accuracy : 0.91918, \tValid  Accuracy : 0.9202,\t Train Loss : 15774.774705296591, \tValid Loss :  3068.0861647222496, \t Time for 1000 Epochs: 1.1153522060194518\n",
      "Epoch 41999 : Train Accuracy : 0.93168, \tValid  Accuracy : 0.9363,\t Train Loss : 12770.110722058178, \tValid Loss :  2477.935971143893, \t Time for 1000 Epochs: 0.9382008490210865\n",
      "Epoch 42999 : Train Accuracy : 0.9031, \tValid  Accuracy : 0.9047,\t Train Loss : 17040.275584438175, \tValid Loss :  3408.2813766986305, \t Time for 1000 Epochs: 0.9063179020013195\n",
      "Epoch 43999 : Train Accuracy : 0.92758, \tValid  Accuracy : 0.9301,\t Train Loss : 14308.612934306075, \tValid Loss :  2914.401999606895, \t Time for 1000 Epochs: 0.8843987279979046\n",
      "Epoch 44999 : Train Accuracy : 0.92862, \tValid  Accuracy : 0.9311,\t Train Loss : 14312.415028668353, \tValid Loss :  2721.499682836481, \t Time for 1000 Epochs: 0.8835263850050978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45999 : Train Accuracy : 0.93446, \tValid  Accuracy : 0.9343,\t Train Loss : 13195.585844372888, \tValid Loss :  2638.8615277646686, \t Time for 1000 Epochs: 1.0094504170119762\n",
      "Epoch 46999 : Train Accuracy : 0.9093, \tValid  Accuracy : 0.9145,\t Train Loss : 17523.186897063595, \tValid Loss :  3417.409678252878, \t Time for 1000 Epochs: 0.9606634679948911\n",
      "Epoch 47999 : Train Accuracy : 0.93062, \tValid  Accuracy : 0.9356,\t Train Loss : 12187.15682210928, \tValid Loss :  2293.638464684593, \t Time for 1000 Epochs: 0.9239213289984036\n",
      "Epoch 48999 : Train Accuracy : 0.9291, \tValid  Accuracy : 0.9332,\t Train Loss : 13646.439004895326, \tValid Loss :  2670.7128992433845, \t Time for 1000 Epochs: 1.0025465709913988\n",
      "Epoch 49999 : Train Accuracy : 0.94672, \tValid  Accuracy : 0.9472,\t Train Loss : 10077.336959259826, \tValid Loss :  2137.8064744380194, \t Time for 1000 Epochs: 1.084523182013072\n",
      "Epoch 50999 : Train Accuracy : 0.9246, \tValid  Accuracy : 0.9243,\t Train Loss : 13513.448685902085, \tValid Loss :  2867.00398545397, \t Time for 1000 Epochs: 1.0726208020059858\n",
      "Epoch 51999 : Train Accuracy : 0.92734, \tValid  Accuracy : 0.9292,\t Train Loss : 14588.214477693771, \tValid Loss :  2877.3302418524995, \t Time for 1000 Epochs: 1.0212838239967823\n",
      "Epoch 52999 : Train Accuracy : 0.93236, \tValid  Accuracy : 0.9352,\t Train Loss : 13700.876289719517, \tValid Loss :  2704.09302303597, \t Time for 1000 Epochs: 0.9568900630110875\n",
      "Epoch 53999 : Train Accuracy : 0.9322, \tValid  Accuracy : 0.936,\t Train Loss : 12197.102695447757, \tValid Loss :  2453.3576861709225, \t Time for 1000 Epochs: 0.9878844479972031\n",
      "Epoch 54999 : Train Accuracy : 0.92862, \tValid  Accuracy : 0.929,\t Train Loss : 12992.825277870592, \tValid Loss :  2603.361750805745, \t Time for 1000 Epochs: 0.9246855280071031\n",
      "Epoch 55999 : Train Accuracy : 0.93308, \tValid  Accuracy : 0.9348,\t Train Loss : 12593.759192969763, \tValid Loss :  2547.9666468117825, \t Time for 1000 Epochs: 1.0192348939890508\n",
      "Epoch 56999 : Train Accuracy : 0.93682, \tValid  Accuracy : 0.9407,\t Train Loss : 12273.681111620335, \tValid Loss :  2318.257875192835, \t Time for 1000 Epochs: 0.9484276970033534\n",
      "Epoch 57999 : Train Accuracy : 0.94516, \tValid  Accuracy : 0.9473,\t Train Loss : 10533.78622840203, \tValid Loss :  2084.8184144005713, \t Time for 1000 Epochs: 0.8990944229881279\n",
      "Epoch 58999 : Train Accuracy : 0.90192, \tValid  Accuracy : 0.9059,\t Train Loss : 16453.110170346445, \tValid Loss :  3130.871706894785, \t Time for 1000 Epochs: 0.896654079988366\n",
      "Epoch 59999 : Train Accuracy : 0.93512, \tValid  Accuracy : 0.9367,\t Train Loss : 11844.234852742868, \tValid Loss :  2417.1648638291144, \t Time for 1000 Epochs: 0.8750541649933439\n",
      "Epoch 60999 : Train Accuracy : 0.92896, \tValid  Accuracy : 0.9343,\t Train Loss : 13936.646772378666, \tValid Loss :  2621.3848005595755, \t Time for 1000 Epochs: 0.8812247029854916\n",
      "Epoch 61999 : Train Accuracy : 0.93326, \tValid  Accuracy : 0.9337,\t Train Loss : 13126.394952718447, \tValid Loss :  2695.49600193037, \t Time for 1000 Epochs: 0.8825630130013451\n",
      "Epoch 62999 : Train Accuracy : 0.91152, \tValid  Accuracy : 0.9185,\t Train Loss : 17040.506931428958, \tValid Loss :  3196.1677071224767, \t Time for 1000 Epochs: 1.0268975630169734\n",
      "Epoch 63999 : Train Accuracy : 0.93488, \tValid  Accuracy : 0.9355,\t Train Loss : 12853.617497084037, \tValid Loss :  2659.9949641695425, \t Time for 1000 Epochs: 1.2403320239973255\n",
      "Epoch 64999 : Train Accuracy : 0.9295, \tValid  Accuracy : 0.9286,\t Train Loss : 13800.159959096745, \tValid Loss :  2769.4278947341786, \t Time for 1000 Epochs: 1.2970495570043568\n",
      "Epoch 65999 : Train Accuracy : 0.94346, \tValid  Accuracy : 0.9436,\t Train Loss : 10654.139617201074, \tValid Loss :  2095.3376907236575, \t Time for 1000 Epochs: 1.400739403004991\n",
      "Epoch 66999 : Train Accuracy : 0.8491, \tValid  Accuracy : 0.8483,\t Train Loss : 64418.139063129274, \tValid Loss :  13281.59726033901, \t Time for 1000 Epochs: 1.1536327910143882\n",
      "Epoch 67999 : Train Accuracy : 0.91082, \tValid  Accuracy : 0.9108,\t Train Loss : 16203.969079326684, \tValid Loss :  3212.116336531808, \t Time for 1000 Epochs: 0.8586033050087281\n",
      "Epoch 68999 : Train Accuracy : 0.93446, \tValid  Accuracy : 0.939,\t Train Loss : 11691.496991580101, \tValid Loss :  2174.0515798768633, \t Time for 1000 Epochs: 1.0759738470078446\n",
      "Epoch 69999 : Train Accuracy : 0.93468, \tValid  Accuracy : 0.9364,\t Train Loss : 13725.755422494594, \tValid Loss :  2657.152356103907, \t Time for 1000 Epochs: 0.9848487729905173\n",
      "Epoch 70999 : Train Accuracy : 0.94494, \tValid  Accuracy : 0.9468,\t Train Loss : 10724.035047234738, \tValid Loss :  2160.871966461234, \t Time for 1000 Epochs: 1.236678816989297\n",
      "Epoch 71999 : Train Accuracy : 0.93226, \tValid  Accuracy : 0.9369,\t Train Loss : 13251.296955706941, \tValid Loss :  2564.5991362727846, \t Time for 1000 Epochs: 1.1873512049787678\n",
      "Epoch 72999 : Train Accuracy : 0.94032, \tValid  Accuracy : 0.9424,\t Train Loss : 11744.628439496557, \tValid Loss :  2372.1884483358613, \t Time for 1000 Epochs: 0.9830678680154961\n",
      "Epoch 73999 : Train Accuracy : 0.93886, \tValid  Accuracy : 0.9378,\t Train Loss : 11847.328334804348, \tValid Loss :  2512.161704825788, \t Time for 1000 Epochs: 1.0083651120075956\n",
      "Epoch 74999 : Train Accuracy : 0.93884, \tValid  Accuracy : 0.9427,\t Train Loss : 12183.152662172684, \tValid Loss :  2433.9248926148425, \t Time for 1000 Epochs: 0.963315094995778\n",
      "Epoch 75999 : Train Accuracy : 0.9337, \tValid  Accuracy : 0.9373,\t Train Loss : 12483.829433151845, \tValid Loss :  2408.4506795667244, \t Time for 1000 Epochs: 0.8795186250063125\n",
      "Epoch 76999 : Train Accuracy : 0.9436, \tValid  Accuracy : 0.9452,\t Train Loss : 11194.115180528235, \tValid Loss :  2302.3309577289447, \t Time for 1000 Epochs: 0.9446062899951357\n",
      "Epoch 77999 : Train Accuracy : 0.91484, \tValid  Accuracy : 0.9151,\t Train Loss : 16990.533063017916, \tValid Loss :  3480.5641137524503, \t Time for 1000 Epochs: 0.8758899200183805\n",
      "Epoch 78999 : Train Accuracy : 0.93986, \tValid  Accuracy : 0.9413,\t Train Loss : 12141.712920132144, \tValid Loss :  2408.7421837606935, \t Time for 1000 Epochs: 0.7922235270089004\n",
      "Epoch 79999 : Train Accuracy : 0.93568, \tValid  Accuracy : 0.9373,\t Train Loss : 13251.548140178944, \tValid Loss :  2607.2491209564546, \t Time for 1000 Epochs: 0.9940320890164003\n",
      "Epoch 80999 : Train Accuracy : 0.94694, \tValid  Accuracy : 0.9468,\t Train Loss : 10153.468990504214, \tValid Loss :  2121.1348349081427, \t Time for 1000 Epochs: 1.0202595290029421\n",
      "Epoch 81999 : Train Accuracy : 0.93892, \tValid  Accuracy : 0.9409,\t Train Loss : 12659.928762481584, \tValid Loss :  2543.8903080594923, \t Time for 1000 Epochs: 0.921315761981532\n",
      "Epoch 82999 : Train Accuracy : 0.94446, \tValid  Accuracy : 0.945,\t Train Loss : 11003.379465371389, \tValid Loss :  2189.684773524529, \t Time for 1000 Epochs: 0.9450949449965265\n",
      "Epoch 83999 : Train Accuracy : 0.94626, \tValid  Accuracy : 0.948,\t Train Loss : 10758.740139350719, \tValid Loss :  2260.108360126574, \t Time for 1000 Epochs: 0.9542809569975361\n",
      "Epoch 84999 : Train Accuracy : 0.93538, \tValid  Accuracy : 0.9361,\t Train Loss : 11925.20740371061, \tValid Loss :  2431.6238257538485, \t Time for 1000 Epochs: 0.8805956259893719\n",
      "Epoch 85999 : Train Accuracy : 0.94342, \tValid  Accuracy : 0.9417,\t Train Loss : 10053.523216239952, \tValid Loss :  2111.0102469562758, \t Time for 1000 Epochs: 0.935921349999262\n",
      "Epoch 86999 : Train Accuracy : 0.9442, \tValid  Accuracy : 0.9427,\t Train Loss : 10472.165261551118, \tValid Loss :  2191.1878900715687, \t Time for 1000 Epochs: 0.9453600819979329\n",
      "Epoch 87999 : Train Accuracy : 0.93716, \tValid  Accuracy : 0.9429,\t Train Loss : 11445.06535072394, \tValid Loss :  2238.3073961888044, \t Time for 1000 Epochs: 0.916775037010666\n",
      "Epoch 88999 : Train Accuracy : 0.94658, \tValid  Accuracy : 0.9455,\t Train Loss : 9999.98035746949, \tValid Loss :  2191.29695107025, \t Time for 1000 Epochs: 0.7951298960251734\n",
      "Epoch 89999 : Train Accuracy : 0.94528, \tValid  Accuracy : 0.9437,\t Train Loss : 10954.409501098657, \tValid Loss :  2426.4353142474038, \t Time for 1000 Epochs: 0.8481577950005885\n",
      "Epoch 90999 : Train Accuracy : 0.93514, \tValid  Accuracy : 0.9368,\t Train Loss : 14648.530254833864, \tValid Loss :  2994.745676862187, \t Time for 1000 Epochs: 0.9647914840024896\n",
      "Epoch 91999 : Train Accuracy : 0.94074, \tValid  Accuracy : 0.9426,\t Train Loss : 12054.8375198323, \tValid Loss :  2365.084843201059, \t Time for 1000 Epochs: 0.8918848970206454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92999 : Train Accuracy : 0.88972, \tValid  Accuracy : 0.887,\t Train Loss : 29323.631083531196, \tValid Loss :  6516.756745357527, \t Time for 1000 Epochs: 0.782509023003513\n",
      "Epoch 93999 : Train Accuracy : 0.93722, \tValid  Accuracy : 0.9399,\t Train Loss : 11769.0705986875, \tValid Loss :  2375.44043025802, \t Time for 1000 Epochs: 0.8065611989877652\n",
      "Epoch 94999 : Train Accuracy : 0.93614, \tValid  Accuracy : 0.9391,\t Train Loss : 14067.244699701512, \tValid Loss :  2673.474029404563, \t Time for 1000 Epochs: 0.7961180459824391\n",
      "Epoch 95999 : Train Accuracy : 0.94578, \tValid  Accuracy : 0.9448,\t Train Loss : 11278.798420110264, \tValid Loss :  2390.131414503051, \t Time for 1000 Epochs: 0.8887272159918211\n",
      "Epoch 96999 : Train Accuracy : 0.94196, \tValid  Accuracy : 0.9408,\t Train Loss : 11737.84133645713, \tValid Loss :  2483.866080824819, \t Time for 1000 Epochs: 0.8550111359800212\n",
      "Epoch 97999 : Train Accuracy : 0.93584, \tValid  Accuracy : 0.9395,\t Train Loss : 12436.587590789903, \tValid Loss :  2495.0586431471384, \t Time for 1000 Epochs: 0.807349756010808\n",
      "Epoch 98999 : Train Accuracy : 0.95212, \tValid  Accuracy : 0.9529,\t Train Loss : 9673.994979479343, \tValid Loss :  1965.3836213606362, \t Time for 1000 Epochs: 0.8102323510101996\n",
      "Epoch 99999 : Train Accuracy : 0.92292, \tValid  Accuracy : 0.928,\t Train Loss : 15055.603210578589, \tValid Loss :  2959.383967192958, \t Time for 1000 Epochs: 0.8122163219959475\n",
      "Epoch 100999 : Train Accuracy : 0.9295, \tValid  Accuracy : 0.9306,\t Train Loss : 13897.939909899065, \tValid Loss :  2888.420582755314, \t Time for 1000 Epochs: 0.7690034230181482\n",
      "Epoch 101999 : Train Accuracy : 0.9289, \tValid  Accuracy : 0.9263,\t Train Loss : 12550.847210145721, \tValid Loss :  2664.580725525936, \t Time for 1000 Epochs: 0.8458589179790579\n",
      "Epoch 102999 : Train Accuracy : 0.94258, \tValid  Accuracy : 0.9398,\t Train Loss : 11097.797083850779, \tValid Loss :  2393.1013181601543, \t Time for 1000 Epochs: 0.7966822820017114\n",
      "Epoch 103999 : Train Accuracy : 0.95188, \tValid  Accuracy : 0.9498,\t Train Loss : 9341.149933569817, \tValid Loss :  1984.4520824993187, \t Time for 1000 Epochs: 0.8098717700049747\n",
      "Epoch 104999 : Train Accuracy : 0.94254, \tValid  Accuracy : 0.9407,\t Train Loss : 10876.05287805156, \tValid Loss :  2324.8179662851467, \t Time for 1000 Epochs: 0.879401769983815\n",
      "Epoch 105999 : Train Accuracy : 0.93602, \tValid  Accuracy : 0.9371,\t Train Loss : 12446.490770135548, \tValid Loss :  2619.486904771291, \t Time for 1000 Epochs: 0.8460257480037399\n",
      "Epoch 106999 : Train Accuracy : 0.9446, \tValid  Accuracy : 0.9433,\t Train Loss : 10304.299069060107, \tValid Loss :  2226.1907741577616, \t Time for 1000 Epochs: 0.8755155739781912\n",
      "Epoch 107999 : Train Accuracy : 0.9494, \tValid  Accuracy : 0.9451,\t Train Loss : 9715.690391022848, \tValid Loss :  2128.7453216950257, \t Time for 1000 Epochs: 0.8762682670203503\n",
      "Epoch 108999 : Train Accuracy : 0.95328, \tValid  Accuracy : 0.9501,\t Train Loss : 9176.536038946524, \tValid Loss :  2096.742359632657, \t Time for 1000 Epochs: 0.8979684269870631\n",
      "Epoch 109999 : Train Accuracy : 0.9488, \tValid  Accuracy : 0.9469,\t Train Loss : 10287.775425808857, \tValid Loss :  2220.246528509932, \t Time for 1000 Epochs: 0.9779782969853841\n",
      "Epoch 110999 : Train Accuracy : 0.94204, \tValid  Accuracy : 0.9387,\t Train Loss : 11481.887327058514, \tValid Loss :  2562.7886714614, \t Time for 1000 Epochs: 0.8132550409936812\n",
      "Epoch 111999 : Train Accuracy : 0.94848, \tValid  Accuracy : 0.9457,\t Train Loss : 10707.420316351621, \tValid Loss :  2339.169055895418, \t Time for 1000 Epochs: 0.903176046005683\n",
      "Epoch 112999 : Train Accuracy : 0.92928, \tValid  Accuracy : 0.9317,\t Train Loss : 12892.416109419923, \tValid Loss :  2618.1356297733255, \t Time for 1000 Epochs: 0.9155067240062635\n",
      "Epoch 113999 : Train Accuracy : 0.93324, \tValid  Accuracy : 0.9329,\t Train Loss : 13676.555837419157, \tValid Loss :  2922.19809556591, \t Time for 1000 Epochs: 0.9061779600160662\n",
      "Epoch 114999 : Train Accuracy : 0.9367, \tValid  Accuracy : 0.9351,\t Train Loss : 12307.247490516078, \tValid Loss :  2571.959248536268, \t Time for 1000 Epochs: 0.8354777630011085\n",
      "Epoch 115999 : Train Accuracy : 0.94734, \tValid  Accuracy : 0.9444,\t Train Loss : 10936.4921021282, \tValid Loss :  2531.5427851272175, \t Time for 1000 Epochs: 0.8297360370052047\n",
      "Epoch 116999 : Train Accuracy : 0.95206, \tValid  Accuracy : 0.9485,\t Train Loss : 9302.944785692243, \tValid Loss :  2133.1478342108603, \t Time for 1000 Epochs: 0.8375615940021817\n",
      "Epoch 117999 : Train Accuracy : 0.94924, \tValid  Accuracy : 0.9497,\t Train Loss : 10513.486988957564, \tValid Loss :  2351.0549902671423, \t Time for 1000 Epochs: 0.8964849590265658\n",
      "Epoch 118999 : Train Accuracy : 0.93854, \tValid  Accuracy : 0.9362,\t Train Loss : 14488.482520718204, \tValid Loss :  3280.2473588394787, \t Time for 1000 Epochs: 0.7996585259970743\n",
      "Epoch 119999 : Train Accuracy : 0.95134, \tValid  Accuracy : 0.949,\t Train Loss : 9765.925096465511, \tValid Loss :  2207.878337437192, \t Time for 1000 Epochs: 0.9748166580102406\n",
      "Epoch 120999 : Train Accuracy : 0.94914, \tValid  Accuracy : 0.9467,\t Train Loss : 9845.57488919206, \tValid Loss :  2167.3286632301124, \t Time for 1000 Epochs: 1.0468373610056005\n",
      "Epoch 121999 : Train Accuracy : 0.9498, \tValid  Accuracy : 0.9478,\t Train Loss : 9459.502953722873, \tValid Loss :  2077.8762284677227, \t Time for 1000 Epochs: 0.9782938159769401\n",
      "Epoch 122999 : Train Accuracy : 0.95098, \tValid  Accuracy : 0.9487,\t Train Loss : 9327.235939964343, \tValid Loss :  2069.4335438511775, \t Time for 1000 Epochs: 0.9664315999834798\n",
      "Epoch 123999 : Train Accuracy : 0.94504, \tValid  Accuracy : 0.9411,\t Train Loss : 11503.287380469954, \tValid Loss :  2537.3763214817313, \t Time for 1000 Epochs: 0.8317058290122077\n",
      "Epoch 124999 : Train Accuracy : 0.94044, \tValid  Accuracy : 0.9383,\t Train Loss : 11795.99847979705, \tValid Loss :  2671.0509131093404, \t Time for 1000 Epochs: 0.902410859009251\n",
      "Epoch 125999 : Train Accuracy : 0.95006, \tValid  Accuracy : 0.949,\t Train Loss : 10064.635389061352, \tValid Loss :  2158.815529504886, \t Time for 1000 Epochs: 0.9460987999918871\n",
      "Epoch 126999 : Train Accuracy : 0.94708, \tValid  Accuracy : 0.944,\t Train Loss : 10747.831984072087, \tValid Loss :  2243.538368628223, \t Time for 1000 Epochs: 0.9548324120114557\n",
      "Epoch 127999 : Train Accuracy : 0.95574, \tValid  Accuracy : 0.951,\t Train Loss : 8830.567792966773, \tValid Loss :  1982.489553839478, \t Time for 1000 Epochs: 0.9059044850000646\n",
      "Epoch 128999 : Train Accuracy : 0.92184, \tValid  Accuracy : 0.9254,\t Train Loss : 14867.918570071499, \tValid Loss :  2979.468569063197, \t Time for 1000 Epochs: 0.9097069239942357\n",
      "Epoch 129999 : Train Accuracy : 0.94858, \tValid  Accuracy : 0.9468,\t Train Loss : 10431.429143827134, \tValid Loss :  2331.392811172448, \t Time for 1000 Epochs: 0.8739168030151632\n",
      "Epoch 130999 : Train Accuracy : 0.95162, \tValid  Accuracy : 0.9493,\t Train Loss : 9265.429594613941, \tValid Loss :  2032.0552831763464, \t Time for 1000 Epochs: 0.8892493309976999\n",
      "Epoch 131999 : Train Accuracy : 0.91728, \tValid  Accuracy : 0.9146,\t Train Loss : 20080.20898614154, \tValid Loss :  4257.790687919962, \t Time for 1000 Epochs: 0.870156388002215\n",
      "Epoch 132999 : Train Accuracy : 0.93688, \tValid  Accuracy : 0.9345,\t Train Loss : 13384.905483472956, \tValid Loss :  2908.5952486748974, \t Time for 1000 Epochs: 0.9484443230030593\n",
      "Epoch 133999 : Train Accuracy : 0.9534, \tValid  Accuracy : 0.9529,\t Train Loss : 9702.681565043478, \tValid Loss :  2049.795275755505, \t Time for 1000 Epochs: 0.9224982819869183\n",
      "Epoch 134999 : Train Accuracy : 0.9127, \tValid  Accuracy : 0.9151,\t Train Loss : 14570.794010601978, \tValid Loss :  2947.534861278111, \t Time for 1000 Epochs: 0.884263944986742\n",
      "Epoch 135999 : Train Accuracy : 0.95194, \tValid  Accuracy : 0.9497,\t Train Loss : 9078.624775420365, \tValid Loss :  1895.4685165572787, \t Time for 1000 Epochs: 0.7901710319856647\n",
      "Epoch 136999 : Train Accuracy : 0.95336, \tValid  Accuracy : 0.9498,\t Train Loss : 9253.363352234874, \tValid Loss :  2134.131201563426, \t Time for 1000 Epochs: 0.9042248519835994\n",
      "Epoch 137999 : Train Accuracy : 0.93504, \tValid  Accuracy : 0.9303,\t Train Loss : 14414.347434801608, \tValid Loss :  3176.573913922897, \t Time for 1000 Epochs: 0.8848045920021832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138999 : Train Accuracy : 0.94466, \tValid  Accuracy : 0.9428,\t Train Loss : 11428.258524131857, \tValid Loss :  2413.810179419185, \t Time for 1000 Epochs: 0.8997261929907836\n",
      "Epoch 139999 : Train Accuracy : 0.91388, \tValid  Accuracy : 0.9169,\t Train Loss : 17533.748010218587, \tValid Loss :  3381.054753928992, \t Time for 1000 Epochs: 0.7899998879875056\n",
      "Epoch 140999 : Train Accuracy : 0.95544, \tValid  Accuracy : 0.9537,\t Train Loss : 8975.243594859508, \tValid Loss :  2000.8593177232283, \t Time for 1000 Epochs: 0.8208613579918165\n",
      "Epoch 141999 : Train Accuracy : 0.89672, \tValid  Accuracy : 0.9004,\t Train Loss : 18103.941332615675, \tValid Loss :  3739.1071033599055, \t Time for 1000 Epochs: 0.9040363729873206\n",
      "Epoch 142999 : Train Accuracy : 0.94464, \tValid  Accuracy : 0.943,\t Train Loss : 10872.482231316426, \tValid Loss :  2297.6632269054094, \t Time for 1000 Epochs: 0.8962876099976711\n",
      "Epoch 143999 : Train Accuracy : 0.94984, \tValid  Accuracy : 0.9481,\t Train Loss : 10265.580879333933, \tValid Loss :  2204.2199127982826, \t Time for 1000 Epochs: 1.0197673040092923\n",
      "Epoch 144999 : Train Accuracy : 0.95036, \tValid  Accuracy : 0.9501,\t Train Loss : 11179.959150043887, \tValid Loss :  2424.1609208914483, \t Time for 1000 Epochs: 0.9052340870257467\n",
      "Epoch 145999 : Train Accuracy : 0.93064, \tValid  Accuracy : 0.9284,\t Train Loss : 14003.680924533179, \tValid Loss :  3068.4172159555615, \t Time for 1000 Epochs: 0.8494325400097296\n",
      "Epoch 146999 : Train Accuracy : 0.95362, \tValid  Accuracy : 0.9494,\t Train Loss : 9768.31439726243, \tValid Loss :  2235.0153588868498, \t Time for 1000 Epochs: 0.9277207590057515\n",
      "Epoch 147999 : Train Accuracy : 0.95516, \tValid  Accuracy : 0.9521,\t Train Loss : 9223.596058576817, \tValid Loss :  2074.4131571996754, \t Time for 1000 Epochs: 0.8138441409973893\n",
      "Epoch 148999 : Train Accuracy : 0.94918, \tValid  Accuracy : 0.946,\t Train Loss : 10118.846042948046, \tValid Loss :  2243.899353842597, \t Time for 1000 Epochs: 0.8347848779812921\n",
      "Epoch 149999 : Train Accuracy : 0.94774, \tValid  Accuracy : 0.9455,\t Train Loss : 9902.261748121375, \tValid Loss :  2229.9469400787502, \t Time for 1000 Epochs: 0.8229475039988756\n",
      "Epoch 150999 : Train Accuracy : 0.94918, \tValid  Accuracy : 0.945,\t Train Loss : 9969.938667019054, \tValid Loss :  2225.8083680480768, \t Time for 1000 Epochs: 0.9121518559986725\n",
      "Epoch 151999 : Train Accuracy : 0.95116, \tValid  Accuracy : 0.9497,\t Train Loss : 9620.75463964555, \tValid Loss :  2215.4629029350035, \t Time for 1000 Epochs: 0.9327798929880373\n",
      "Epoch 152999 : Train Accuracy : 0.94544, \tValid  Accuracy : 0.9462,\t Train Loss : 10998.197399214943, \tValid Loss :  2430.317732025794, \t Time for 1000 Epochs: 1.0223836750083137\n",
      "Epoch 153999 : Train Accuracy : 0.95474, \tValid  Accuracy : 0.9532,\t Train Loss : 9723.955966914275, \tValid Loss :  2098.560062467933, \t Time for 1000 Epochs: 0.8545512450218666\n",
      "Epoch 154999 : Train Accuracy : 0.94938, \tValid  Accuracy : 0.9475,\t Train Loss : 10115.939259196726, \tValid Loss :  2293.926508488373, \t Time for 1000 Epochs: 0.7971996650157962\n",
      "Epoch 155999 : Train Accuracy : 0.9557, \tValid  Accuracy : 0.9522,\t Train Loss : 8908.125956585664, \tValid Loss :  2002.0998178339996, \t Time for 1000 Epochs: 0.8176085019949824\n",
      "Epoch 156999 : Train Accuracy : 0.95108, \tValid  Accuracy : 0.9504,\t Train Loss : 9983.099876219825, \tValid Loss :  2127.162863240422, \t Time for 1000 Epochs: 0.8499761119892355\n",
      "Epoch 157999 : Train Accuracy : 0.9438, \tValid  Accuracy : 0.9435,\t Train Loss : 11072.845744165015, \tValid Loss :  2354.807910240924, \t Time for 1000 Epochs: 0.8485486219869927\n",
      "Epoch 158999 : Train Accuracy : 0.88048, \tValid  Accuracy : 0.8707,\t Train Loss : 13813.882848776828, \tValid Loss :  3001.321711571095, \t Time for 1000 Epochs: 0.9953955989913084\n",
      "Epoch 159999 : Train Accuracy : 0.95822, \tValid  Accuracy : 0.9534,\t Train Loss : 8107.369634878239, \tValid Loss :  1881.2840035856675, \t Time for 1000 Epochs: 0.8248133120068815\n",
      "Epoch 160999 : Train Accuracy : 0.94954, \tValid  Accuracy : 0.9467,\t Train Loss : 11230.242409167748, \tValid Loss :  2407.6321459812184, \t Time for 1000 Epochs: 0.9153557080135215\n",
      "Epoch 161999 : Train Accuracy : 0.9585, \tValid  Accuracy : 0.9572,\t Train Loss : 8907.137601476712, \tValid Loss :  1908.802713034893, \t Time for 1000 Epochs: 0.8560466979979537\n",
      "Epoch 162999 : Train Accuracy : 0.94762, \tValid  Accuracy : 0.9449,\t Train Loss : 10113.995654636186, \tValid Loss :  2175.847769799457, \t Time for 1000 Epochs: 0.9487118720135186\n",
      "Epoch 163999 : Train Accuracy : 0.93448, \tValid  Accuracy : 0.9347,\t Train Loss : 13427.185099158438, \tValid Loss :  2894.8469392502125, \t Time for 1000 Epochs: 0.8502177049813326\n",
      "Epoch 164999 : Train Accuracy : 0.957, \tValid  Accuracy : 0.9552,\t Train Loss : 8370.268602963704, \tValid Loss :  1843.982314699786, \t Time for 1000 Epochs: 0.8212426849931944\n",
      "Epoch 165999 : Train Accuracy : 0.95168, \tValid  Accuracy : 0.9491,\t Train Loss : 10356.457182590373, \tValid Loss :  2305.063688110179, \t Time for 1000 Epochs: 0.9639931319979951\n",
      "Epoch 166999 : Train Accuracy : 0.95128, \tValid  Accuracy : 0.9483,\t Train Loss : 10693.527826935626, \tValid Loss :  2364.9967620023745, \t Time for 1000 Epochs: 0.8143510599911679\n",
      "Epoch 167999 : Train Accuracy : 0.94614, \tValid  Accuracy : 0.9462,\t Train Loss : 12413.395563512164, \tValid Loss :  2514.536850934097, \t Time for 1000 Epochs: 0.8512110380106606\n",
      "Epoch 168999 : Train Accuracy : 0.9535, \tValid  Accuracy : 0.9521,\t Train Loss : 9464.759330753788, \tValid Loss :  1990.7636928639274, \t Time for 1000 Epochs: 0.9729955219954718\n",
      "Epoch 169999 : Train Accuracy : 0.94988, \tValid  Accuracy : 0.9488,\t Train Loss : 10696.649248446627, \tValid Loss :  2209.463808451212, \t Time for 1000 Epochs: 0.8316860469931271\n",
      "Epoch 170999 : Train Accuracy : 0.95112, \tValid  Accuracy : 0.9507,\t Train Loss : 9602.710858060596, \tValid Loss :  2018.4748357453473, \t Time for 1000 Epochs: 0.9487108820176218\n",
      "Epoch 171999 : Train Accuracy : 0.95476, \tValid  Accuracy : 0.9535,\t Train Loss : 8800.436417483656, \tValid Loss :  2016.1232755929193, \t Time for 1000 Epochs: 0.8187465639784932\n",
      "Epoch 172999 : Train Accuracy : 0.94466, \tValid  Accuracy : 0.9446,\t Train Loss : 12029.964723056086, \tValid Loss :  2567.8901100112093, \t Time for 1000 Epochs: 1.0365047119848896\n",
      "Epoch 173999 : Train Accuracy : 0.95168, \tValid  Accuracy : 0.9505,\t Train Loss : 9778.280127196409, \tValid Loss :  2180.701502572796, \t Time for 1000 Epochs: 0.857044918986503\n",
      "Epoch 174999 : Train Accuracy : 0.95156, \tValid  Accuracy : 0.9462,\t Train Loss : 10308.002593909629, \tValid Loss :  2378.465543758525, \t Time for 1000 Epochs: 0.9538553569873329\n",
      "Epoch 175999 : Train Accuracy : 0.94896, \tValid  Accuracy : 0.9459,\t Train Loss : 10910.033736886853, \tValid Loss :  2437.178078666364, \t Time for 1000 Epochs: 0.9326433810056187\n",
      "Epoch 176999 : Train Accuracy : 0.94264, \tValid  Accuracy : 0.9379,\t Train Loss : 10796.898739067936, \tValid Loss :  2455.3891731614967, \t Time for 1000 Epochs: 0.9180530369922053\n",
      "Epoch 177999 : Train Accuracy : 0.94944, \tValid  Accuracy : 0.9461,\t Train Loss : 10508.33425997727, \tValid Loss :  2432.985695484832, \t Time for 1000 Epochs: 0.8155698619957548\n",
      "Epoch 178999 : Train Accuracy : 0.94378, \tValid  Accuracy : 0.9386,\t Train Loss : 11544.615535341685, \tValid Loss :  2533.1952094724165, \t Time for 1000 Epochs: 0.8050925139978062\n",
      "Epoch 179999 : Train Accuracy : 0.95396, \tValid  Accuracy : 0.9525,\t Train Loss : 9126.7494441787, \tValid Loss :  2174.686393949568, \t Time for 1000 Epochs: 0.8562729839759413\n",
      "Epoch 180999 : Train Accuracy : 0.9425, \tValid  Accuracy : 0.9383,\t Train Loss : 11758.246652391148, \tValid Loss :  2690.7897249145085, \t Time for 1000 Epochs: 0.9912795159907546\n",
      "Epoch 181999 : Train Accuracy : 0.95, \tValid  Accuracy : 0.9452,\t Train Loss : 9820.65588447884, \tValid Loss :  2236.8610252477133, \t Time for 1000 Epochs: 0.8469935950124636\n",
      "Epoch 182999 : Train Accuracy : 0.93192, \tValid  Accuracy : 0.9309,\t Train Loss : 13247.309698084668, \tValid Loss :  2970.8728192181347, \t Time for 1000 Epochs: 1.0311755889852066\n",
      "Epoch 183999 : Train Accuracy : 0.9458, \tValid  Accuracy : 0.9434,\t Train Loss : 10927.097914507553, \tValid Loss :  2503.1371017594292, \t Time for 1000 Epochs: 0.8963415839825757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184999 : Train Accuracy : 0.95068, \tValid  Accuracy : 0.9465,\t Train Loss : 10347.353085727183, \tValid Loss :  2413.6025430286036, \t Time for 1000 Epochs: 0.8416555110015906\n",
      "Epoch 185999 : Train Accuracy : 0.9445, \tValid  Accuracy : 0.9415,\t Train Loss : 12436.7085952865, \tValid Loss :  2835.901084226012, \t Time for 1000 Epochs: 0.8696729080111254\n",
      "Epoch 186999 : Train Accuracy : 0.95794, \tValid  Accuracy : 0.9542,\t Train Loss : 8853.754445512765, \tValid Loss :  2258.8783681059112, \t Time for 1000 Epochs: 0.8242343189776875\n",
      "Epoch 187999 : Train Accuracy : 0.95744, \tValid  Accuracy : 0.9499,\t Train Loss : 8621.687083524299, \tValid Loss :  2205.247569760762, \t Time for 1000 Epochs: 0.8922923380159773\n",
      "Epoch 188999 : Train Accuracy : 0.94522, \tValid  Accuracy : 0.941,\t Train Loss : 10772.681953693962, \tValid Loss :  2555.6404266410254, \t Time for 1000 Epochs: 0.7993441949947737\n",
      "Epoch 189999 : Train Accuracy : 0.95262, \tValid  Accuracy : 0.9474,\t Train Loss : 9948.093041945373, \tValid Loss :  2411.5715197923805, \t Time for 1000 Epochs: 0.9585809019918088\n",
      "Epoch 190999 : Train Accuracy : 0.9437, \tValid  Accuracy : 0.9394,\t Train Loss : 11878.30199279348, \tValid Loss :  2741.8421878521735, \t Time for 1000 Epochs: 0.9354394449910615\n",
      "Epoch 191999 : Train Accuracy : 0.9468, \tValid  Accuracy : 0.9405,\t Train Loss : 10436.428336636804, \tValid Loss :  2483.6500039304633, \t Time for 1000 Epochs: 0.9772013649926521\n",
      "Epoch 192999 : Train Accuracy : 0.96108, \tValid  Accuracy : 0.9538,\t Train Loss : 8023.421673314992, \tValid Loss :  1985.252034932407, \t Time for 1000 Epochs: 0.9680331489944365\n",
      "Epoch 193999 : Train Accuracy : 0.94548, \tValid  Accuracy : 0.9432,\t Train Loss : 11228.6736018899, \tValid Loss :  2391.7739664880937, \t Time for 1000 Epochs: 0.9782603250059765\n",
      "Epoch 194999 : Train Accuracy : 0.94944, \tValid  Accuracy : 0.948,\t Train Loss : 9781.717218380225, \tValid Loss :  2198.4100413879364, \t Time for 1000 Epochs: 0.8229867339832708\n",
      "Epoch 195999 : Train Accuracy : 0.9494, \tValid  Accuracy : 0.947,\t Train Loss : 9771.53756366486, \tValid Loss :  2259.362937024074, \t Time for 1000 Epochs: 0.7630956149951089\n",
      "Epoch 196999 : Train Accuracy : 0.95164, \tValid  Accuracy : 0.9506,\t Train Loss : 10096.637481998661, \tValid Loss :  2118.0081422433364, \t Time for 1000 Epochs: 0.8449331910233013\n",
      "Epoch 197999 : Train Accuracy : 0.9576, \tValid  Accuracy : 0.957,\t Train Loss : 8479.706440997028, \tValid Loss :  1816.3712647956568, \t Time for 1000 Epochs: 0.8592421030043624\n",
      "Epoch 198999 : Train Accuracy : 0.95308, \tValid  Accuracy : 0.9501,\t Train Loss : 9240.433025498332, \tValid Loss :  2030.9274865430843, \t Time for 1000 Epochs: 0.8666480380052235\n",
      "Epoch 199999 : Train Accuracy : 0.956, \tValid  Accuracy : 0.9537,\t Train Loss : 8299.350086457913, \tValid Loss :  1956.4690975485855, \t Time for 1000 Epochs: 0.8809077740006614\n",
      "Epoch 200999 : Train Accuracy : 0.9517, \tValid  Accuracy : 0.949,\t Train Loss : 9553.751034748146, \tValid Loss :  2226.0101801279716, \t Time for 1000 Epochs: 0.8244236210011877\n",
      "Epoch 201999 : Train Accuracy : 0.94804, \tValid  Accuracy : 0.9428,\t Train Loss : 9663.942369476732, \tValid Loss :  2235.9280830337116, \t Time for 1000 Epochs: 0.9001002510194667\n",
      "Epoch 202999 : Train Accuracy : 0.94294, \tValid  Accuracy : 0.9411,\t Train Loss : 12061.864843793428, \tValid Loss :  2872.6311092371247, \t Time for 1000 Epochs: 0.8955381319974549\n",
      "Epoch 203999 : Train Accuracy : 0.93234, \tValid  Accuracy : 0.9308,\t Train Loss : 13088.19586028917, \tValid Loss :  2767.628290397457, \t Time for 1000 Epochs: 0.9535761500010267\n",
      "Epoch 204999 : Train Accuracy : 0.95758, \tValid  Accuracy : 0.9515,\t Train Loss : 8322.7918926521, \tValid Loss :  1911.8780037710226, \t Time for 1000 Epochs: 0.9973250790208112\n",
      "Epoch 205999 : Train Accuracy : 0.95608, \tValid  Accuracy : 0.9515,\t Train Loss : 8417.199795639315, \tValid Loss :  1984.2594365121045, \t Time for 1000 Epochs: 0.9071120500157122\n",
      "Epoch 206999 : Train Accuracy : 0.95606, \tValid  Accuracy : 0.9543,\t Train Loss : 8796.74036628256, \tValid Loss :  1879.7313196149976, \t Time for 1000 Epochs: 0.8255812040006276\n",
      "Epoch 207999 : Train Accuracy : 0.95422, \tValid  Accuracy : 0.9486,\t Train Loss : 9068.03870090315, \tValid Loss :  2209.4040494300366, \t Time for 1000 Epochs: 0.9196746249799617\n",
      "Epoch 208999 : Train Accuracy : 0.95658, \tValid  Accuracy : 0.9554,\t Train Loss : 9211.081674082467, \tValid Loss :  2087.8275515110854, \t Time for 1000 Epochs: 0.8232446449983399\n",
      "Epoch 209999 : Train Accuracy : 0.95144, \tValid  Accuracy : 0.9476,\t Train Loss : 9585.229412564715, \tValid Loss :  2190.765221731572, \t Time for 1000 Epochs: 0.8036037019919604\n",
      "Epoch 210999 : Train Accuracy : 0.95398, \tValid  Accuracy : 0.9517,\t Train Loss : 8206.044087111984, \tValid Loss :  1944.7046765143245, \t Time for 1000 Epochs: 0.9164307970204391\n",
      "Epoch 211999 : Train Accuracy : 0.95996, \tValid  Accuracy : 0.9589,\t Train Loss : 8084.355857737938, \tValid Loss :  1823.9791386104234, \t Time for 1000 Epochs: 0.9160455259843729\n",
      "Epoch 212999 : Train Accuracy : 0.9573, \tValid  Accuracy : 0.9526,\t Train Loss : 8107.517810070465, \tValid Loss :  1980.8644073356352, \t Time for 1000 Epochs: 0.8231655549898278\n",
      "Epoch 213999 : Train Accuracy : 0.95902, \tValid  Accuracy : 0.9539,\t Train Loss : 8429.986467253568, \tValid Loss :  2068.3203789389727, \t Time for 1000 Epochs: 0.8801688029780053\n",
      "Epoch 214999 : Train Accuracy : 0.95028, \tValid  Accuracy : 0.9476,\t Train Loss : 10835.386186250518, \tValid Loss :  2494.7042179797586, \t Time for 1000 Epochs: 0.8779719030135311\n",
      "Epoch 215999 : Train Accuracy : 0.9479, \tValid  Accuracy : 0.9457,\t Train Loss : 11882.834661665069, \tValid Loss :  2606.5686551425147, \t Time for 1000 Epochs: 0.919865267991554\n",
      "Epoch 216999 : Train Accuracy : 0.94918, \tValid  Accuracy : 0.9465,\t Train Loss : 10013.944852093713, \tValid Loss :  2224.3277900476814, \t Time for 1000 Epochs: 0.9397937660105526\n",
      "Epoch 217999 : Train Accuracy : 0.95746, \tValid  Accuracy : 0.9526,\t Train Loss : 9517.203070436908, \tValid Loss :  2210.464938545523, \t Time for 1000 Epochs: 0.9066471959813498\n",
      "Epoch 218999 : Train Accuracy : 0.95216, \tValid  Accuracy : 0.9488,\t Train Loss : 10956.173344537225, \tValid Loss :  2470.4811928399404, \t Time for 1000 Epochs: 0.9193302329804283\n",
      "Epoch 219999 : Train Accuracy : 0.94866, \tValid  Accuracy : 0.9455,\t Train Loss : 10468.08746713756, \tValid Loss :  2293.634836475067, \t Time for 1000 Epochs: 0.8894596780010033\n",
      "Epoch 220999 : Train Accuracy : 0.94666, \tValid  Accuracy : 0.9431,\t Train Loss : 10804.781746740771, \tValid Loss :  2411.5729158754893, \t Time for 1000 Epochs: 0.9047001809813082\n",
      "Epoch 221999 : Train Accuracy : 0.90278, \tValid  Accuracy : 0.8962,\t Train Loss : 16299.485464465575, \tValid Loss :  3608.83634190309, \t Time for 1000 Epochs: 0.9060450349934399\n",
      "Epoch 222999 : Train Accuracy : 0.93478, \tValid  Accuracy : 0.9389,\t Train Loss : 11262.238794026434, \tValid Loss :  2415.4669269036795, \t Time for 1000 Epochs: 0.8160441810032353\n",
      "Epoch 223999 : Train Accuracy : 0.939, \tValid  Accuracy : 0.9386,\t Train Loss : 11253.950490997588, \tValid Loss :  2443.6688495212416, \t Time for 1000 Epochs: 0.9098466529976577\n",
      "Epoch 224999 : Train Accuracy : 0.95228, \tValid  Accuracy : 0.9489,\t Train Loss : 10033.344497260563, \tValid Loss :  2357.0800344356967, \t Time for 1000 Epochs: 0.917634594021365\n",
      "Epoch 225999 : Train Accuracy : 0.95182, \tValid  Accuracy : 0.9476,\t Train Loss : 11477.713380567275, \tValid Loss :  2659.882546697588, \t Time for 1000 Epochs: 0.945802624017233\n",
      "Epoch 226999 : Train Accuracy : 0.94304, \tValid  Accuracy : 0.9414,\t Train Loss : 12605.200147667283, \tValid Loss :  2677.4545546675226, \t Time for 1000 Epochs: 0.9546082220040262\n",
      "Epoch 227999 : Train Accuracy : 0.95892, \tValid  Accuracy : 0.9548,\t Train Loss : 9170.664936845384, \tValid Loss :  2238.256063069269, \t Time for 1000 Epochs: 1.0213707580114715\n",
      "Epoch 228999 : Train Accuracy : 0.95156, \tValid  Accuracy : 0.9473,\t Train Loss : 12222.31811653888, \tValid Loss :  2910.821973672794, \t Time for 1000 Epochs: 1.0038817220192868\n",
      "Epoch 229999 : Train Accuracy : 0.94974, \tValid  Accuracy : 0.9453,\t Train Loss : 10967.744600287942, \tValid Loss :  2547.709938276672, \t Time for 1000 Epochs: 1.1166775810124818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230999 : Train Accuracy : 0.93686, \tValid  Accuracy : 0.9349,\t Train Loss : 12312.233569836208, \tValid Loss :  2650.8751987203277, \t Time for 1000 Epochs: 0.8961734759795945\n",
      "Epoch 231999 : Train Accuracy : 0.95156, \tValid  Accuracy : 0.9489,\t Train Loss : 9912.102078747175, \tValid Loss :  2170.1664642412256, \t Time for 1000 Epochs: 0.8139872090250719\n",
      "Epoch 232999 : Train Accuracy : 0.94372, \tValid  Accuracy : 0.9404,\t Train Loss : 12720.237087407642, \tValid Loss :  2950.492197229813, \t Time for 1000 Epochs: 0.9661752789979801\n",
      "Epoch 233999 : Train Accuracy : 0.93878, \tValid  Accuracy : 0.9352,\t Train Loss : 13130.715704056987, \tValid Loss :  2977.883636666263, \t Time for 1000 Epochs: 0.9148655989847612\n",
      "Epoch 234999 : Train Accuracy : 0.9463, \tValid  Accuracy : 0.9439,\t Train Loss : 10445.5423980243, \tValid Loss :  2423.204654471782, \t Time for 1000 Epochs: 0.8955072999815457\n",
      "Epoch 235999 : Train Accuracy : 0.95748, \tValid  Accuracy : 0.952,\t Train Loss : 8790.626582160989, \tValid Loss :  2158.0091587366687, \t Time for 1000 Epochs: 0.8178672270150855\n",
      "Epoch 236999 : Train Accuracy : 0.95564, \tValid  Accuracy : 0.9521,\t Train Loss : 9080.735084811366, \tValid Loss :  2291.43194593076, \t Time for 1000 Epochs: 0.8060852990020066\n",
      "Epoch 237999 : Train Accuracy : 0.9481, \tValid  Accuracy : 0.9436,\t Train Loss : 10386.473841174347, \tValid Loss :  2498.2123285860334, \t Time for 1000 Epochs: 0.8843457920011133\n",
      "Epoch 238999 : Train Accuracy : 0.94862, \tValid  Accuracy : 0.9426,\t Train Loss : 11208.771370434817, \tValid Loss :  2538.59203091276, \t Time for 1000 Epochs: 0.8060098169953562\n",
      "Epoch 239999 : Train Accuracy : 0.95372, \tValid  Accuracy : 0.9473,\t Train Loss : 10269.721589132689, \tValid Loss :  2531.638225888655, \t Time for 1000 Epochs: 0.8539159509819001\n",
      "Epoch 240999 : Train Accuracy : 0.95608, \tValid  Accuracy : 0.9498,\t Train Loss : 9500.524267722092, \tValid Loss :  2363.297214422188, \t Time for 1000 Epochs: 0.8684923750115559\n",
      "Epoch 241999 : Train Accuracy : 0.95918, \tValid  Accuracy : 0.9499,\t Train Loss : 8136.0450489316, \tValid Loss :  2117.832634407845, \t Time for 1000 Epochs: 0.8442922969989013\n",
      "Epoch 242999 : Train Accuracy : 0.93688, \tValid  Accuracy : 0.9269,\t Train Loss : 15324.911597148086, \tValid Loss :  3948.6978421826816, \t Time for 1000 Epochs: 0.8674320650170557\n",
      "Epoch 243999 : Train Accuracy : 0.9584, \tValid  Accuracy : 0.9532,\t Train Loss : 9193.402519331254, \tValid Loss :  2224.4150247452876, \t Time for 1000 Epochs: 0.8041568150219973\n",
      "Epoch 244999 : Train Accuracy : 0.94534, \tValid  Accuracy : 0.9446,\t Train Loss : 11017.10004829929, \tValid Loss :  2498.458164682821, \t Time for 1000 Epochs: 0.9065464859886561\n",
      "Epoch 245999 : Train Accuracy : 0.95664, \tValid  Accuracy : 0.9504,\t Train Loss : 8679.506716346114, \tValid Loss :  2154.083096825262, \t Time for 1000 Epochs: 0.8011450940102804\n",
      "Epoch 246999 : Train Accuracy : 0.95006, \tValid  Accuracy : 0.9431,\t Train Loss : 10113.97805502153, \tValid Loss :  2487.324037772392, \t Time for 1000 Epochs: 0.9004654760065023\n",
      "Epoch 247999 : Train Accuracy : 0.95642, \tValid  Accuracy : 0.95,\t Train Loss : 8667.167893793381, \tValid Loss :  2180.7525446890977, \t Time for 1000 Epochs: 0.8845142700010911\n",
      "Epoch 248999 : Train Accuracy : 0.9619, \tValid  Accuracy : 0.9541,\t Train Loss : 7815.533502386683, \tValid Loss :  1941.7682861790445, \t Time for 1000 Epochs: 0.783622473012656\n",
      "Epoch 249999 : Train Accuracy : 0.95928, \tValid  Accuracy : 0.9526,\t Train Loss : 8593.5669550688, \tValid Loss :  2167.803133653213, \t Time for 1000 Epochs: 0.8235098159930203\n",
      "Epoch 250999 : Train Accuracy : 0.95348, \tValid  Accuracy : 0.9484,\t Train Loss : 10363.147741140361, \tValid Loss :  2462.234288126852, \t Time for 1000 Epochs: 1.0268015199981164\n",
      "Epoch 251999 : Train Accuracy : 0.95492, \tValid  Accuracy : 0.9498,\t Train Loss : 9646.715368407376, \tValid Loss :  2291.394565122108, \t Time for 1000 Epochs: 0.8660502699785866\n",
      "Epoch 252999 : Train Accuracy : 0.95414, \tValid  Accuracy : 0.9491,\t Train Loss : 9244.810557925022, \tValid Loss :  2304.0053898296164, \t Time for 1000 Epochs: 1.0562797359889373\n",
      "Epoch 253999 : Train Accuracy : 0.95644, \tValid  Accuracy : 0.9524,\t Train Loss : 9102.77360917147, \tValid Loss :  2191.925953466125, \t Time for 1000 Epochs: 0.8187887360109016\n",
      "Epoch 254999 : Train Accuracy : 0.9596, \tValid  Accuracy : 0.9551,\t Train Loss : 8377.650254372222, \tValid Loss :  2106.6570113421076, \t Time for 1000 Epochs: 0.8230110889999196\n",
      "Epoch 255999 : Train Accuracy : 0.95592, \tValid  Accuracy : 0.95,\t Train Loss : 10193.494560078057, \tValid Loss :  2587.434123449299, \t Time for 1000 Epochs: 0.8775583849928807\n",
      "Epoch 256999 : Train Accuracy : 0.95, \tValid  Accuracy : 0.9485,\t Train Loss : 11356.15106695771, \tValid Loss :  2612.7826687602037, \t Time for 1000 Epochs: 0.9259617180214263\n",
      "Epoch 257999 : Train Accuracy : 0.94372, \tValid  Accuracy : 0.9394,\t Train Loss : 11009.932794546577, \tValid Loss :  2705.937816874899, \t Time for 1000 Epochs: 0.8949254259932786\n",
      "Epoch 258999 : Train Accuracy : 0.9583, \tValid  Accuracy : 0.9507,\t Train Loss : 8666.007413210413, \tValid Loss :  2319.523320282879, \t Time for 1000 Epochs: 0.805524041003082\n",
      "Epoch 259999 : Train Accuracy : 0.9567, \tValid  Accuracy : 0.951,\t Train Loss : 8727.804925477278, \tValid Loss :  2262.3932101453443, \t Time for 1000 Epochs: 0.8016204189916607\n",
      "Epoch 260999 : Train Accuracy : 0.95578, \tValid  Accuracy : 0.9527,\t Train Loss : 8689.377590241991, \tValid Loss :  2051.0325129808625, \t Time for 1000 Epochs: 0.8166256439872086\n",
      "Epoch 261999 : Train Accuracy : 0.95872, \tValid  Accuracy : 0.9546,\t Train Loss : 9608.05989784314, \tValid Loss :  2218.5867579213705, \t Time for 1000 Epochs: 0.8646112950227689\n",
      "Epoch 262999 : Train Accuracy : 0.95716, \tValid  Accuracy : 0.9546,\t Train Loss : 9258.985314973386, \tValid Loss :  2229.098537700008, \t Time for 1000 Epochs: 0.9206633550056722\n",
      "Epoch 263999 : Train Accuracy : 0.958, \tValid  Accuracy : 0.9523,\t Train Loss : 8545.697642556737, \tValid Loss :  2147.3679079819804, \t Time for 1000 Epochs: 0.831310287991073\n",
      "Epoch 264999 : Train Accuracy : 0.9598, \tValid  Accuracy : 0.9528,\t Train Loss : 8278.148042462615, \tValid Loss :  2045.2383836495615, \t Time for 1000 Epochs: 0.8858816879801452\n",
      "Epoch 265999 : Train Accuracy : 0.96312, \tValid  Accuracy : 0.9584,\t Train Loss : 8267.156284823142, \tValid Loss :  2070.2116088653065, \t Time for 1000 Epochs: 0.8360191219835542\n",
      "Epoch 266999 : Train Accuracy : 0.96198, \tValid  Accuracy : 0.9562,\t Train Loss : 8448.547903921273, \tValid Loss :  2030.444456288755, \t Time for 1000 Epochs: 0.9387233720044605\n",
      "Epoch 267999 : Train Accuracy : 0.94686, \tValid  Accuracy : 0.9429,\t Train Loss : 11181.514504512084, \tValid Loss :  2499.43889186065, \t Time for 1000 Epochs: 0.9065440359991044\n",
      "Epoch 268999 : Train Accuracy : 0.95824, \tValid  Accuracy : 0.9525,\t Train Loss : 9415.070696402461, \tValid Loss :  2302.288842760903, \t Time for 1000 Epochs: 0.9281105139816646\n",
      "Epoch 269999 : Train Accuracy : 0.95514, \tValid  Accuracy : 0.9505,\t Train Loss : 9378.322118096941, \tValid Loss :  2268.1661515571723, \t Time for 1000 Epochs: 0.8604661780118477\n",
      "Epoch 270999 : Train Accuracy : 0.94638, \tValid  Accuracy : 0.9442,\t Train Loss : 13158.954988340836, \tValid Loss :  2944.112066266483, \t Time for 1000 Epochs: 0.8660257949959487\n",
      "Epoch 271999 : Train Accuracy : 0.95026, \tValid  Accuracy : 0.9461,\t Train Loss : 10665.522651764106, \tValid Loss :  2462.0023342586355, \t Time for 1000 Epochs: 0.8214364660088904\n",
      "Epoch 272999 : Train Accuracy : 0.95048, \tValid  Accuracy : 0.945,\t Train Loss : 9703.283598911956, \tValid Loss :  2410.9246480013894, \t Time for 1000 Epochs: 0.8658751210023183\n",
      "Epoch 273999 : Train Accuracy : 0.95448, \tValid  Accuracy : 0.9473,\t Train Loss : 10407.935055761776, \tValid Loss :  2483.386937437309, \t Time for 1000 Epochs: 0.9178452910273336\n",
      "Epoch 274999 : Train Accuracy : 0.95716, \tValid  Accuracy : 0.9514,\t Train Loss : 9486.499714319865, \tValid Loss :  2396.1636231260404, \t Time for 1000 Epochs: 0.9991493900015485\n",
      "Epoch 275999 : Train Accuracy : 0.95216, \tValid  Accuracy : 0.9443,\t Train Loss : 10288.097475098035, \tValid Loss :  2514.918112676387, \t Time for 1000 Epochs: 1.0015174630098045\n",
      "Epoch 276999 : Train Accuracy : 0.95988, \tValid  Accuracy : 0.9517,\t Train Loss : 8454.305658402362, \tValid Loss :  2175.3801341762096, \t Time for 1000 Epochs: 0.8908010800078046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277999 : Train Accuracy : 0.95684, \tValid  Accuracy : 0.9487,\t Train Loss : 8649.987652960494, \tValid Loss :  2163.381861994418, \t Time for 1000 Epochs: 0.86158919200534\n",
      "Epoch 278999 : Train Accuracy : 0.95154, \tValid  Accuracy : 0.9478,\t Train Loss : 10425.594644551547, \tValid Loss :  2419.9925263511664, \t Time for 1000 Epochs: 0.8850876490178052\n",
      "Epoch 279999 : Train Accuracy : 0.95254, \tValid  Accuracy : 0.9454,\t Train Loss : 9768.874985223123, \tValid Loss :  2267.217727734443, \t Time for 1000 Epochs: 0.9481731610139832\n",
      "Epoch 280999 : Train Accuracy : 0.95184, \tValid  Accuracy : 0.944,\t Train Loss : 9604.337543918151, \tValid Loss :  2344.3763431372704, \t Time for 1000 Epochs: 0.81615482000052\n",
      "Epoch 281999 : Train Accuracy : 0.95202, \tValid  Accuracy : 0.9449,\t Train Loss : 10816.43328155297, \tValid Loss :  2704.849784368597, \t Time for 1000 Epochs: 0.8395334579981863\n",
      "Epoch 282999 : Train Accuracy : 0.95974, \tValid  Accuracy : 0.9527,\t Train Loss : 8364.31252482191, \tValid Loss :  2162.2487266272683, \t Time for 1000 Epochs: 0.8775236810033675\n",
      "Epoch 283999 : Train Accuracy : 0.9489, \tValid  Accuracy : 0.9393,\t Train Loss : 10324.044130225902, \tValid Loss :  2625.759890050733, \t Time for 1000 Epochs: 0.8640315959928557\n",
      "Epoch 284999 : Train Accuracy : 0.94694, \tValid  Accuracy : 0.9365,\t Train Loss : 10743.612969824022, \tValid Loss :  2648.1791899179907, \t Time for 1000 Epochs: 0.8366639839950949\n",
      "Epoch 285999 : Train Accuracy : 0.95056, \tValid  Accuracy : 0.9428,\t Train Loss : 11021.760386079282, \tValid Loss :  2886.5771691178134, \t Time for 1000 Epochs: 0.8429258620017208\n",
      "Epoch 286999 : Train Accuracy : 0.9532, \tValid  Accuracy : 0.9453,\t Train Loss : 8998.455575852588, \tValid Loss :  2275.9300038396605, \t Time for 1000 Epochs: 0.8805712250177749\n",
      "Epoch 287999 : Train Accuracy : 0.95186, \tValid  Accuracy : 0.9453,\t Train Loss : 10422.61719247533, \tValid Loss :  2570.001711419248, \t Time for 1000 Epochs: 0.8727034970070235\n",
      "Epoch 288999 : Train Accuracy : 0.95152, \tValid  Accuracy : 0.9462,\t Train Loss : 9209.20068655795, \tValid Loss :  2251.4875832185917, \t Time for 1000 Epochs: 1.0617232939985115\n",
      "Epoch 289999 : Train Accuracy : 0.94698, \tValid  Accuracy : 0.9439,\t Train Loss : 10774.082380386351, \tValid Loss :  2423.6675930628253, \t Time for 1000 Epochs: 0.9290323029854335\n",
      "Epoch 290999 : Train Accuracy : 0.9538, \tValid  Accuracy : 0.9481,\t Train Loss : 9166.734423084092, \tValid Loss :  2270.233745210703, \t Time for 1000 Epochs: 0.947948068002006\n",
      "Epoch 291999 : Train Accuracy : 0.95966, \tValid  Accuracy : 0.9515,\t Train Loss : 8945.506743380469, \tValid Loss :  2433.008955445373, \t Time for 1000 Epochs: 0.9308478040038608\n",
      "Epoch 292999 : Train Accuracy : 0.94614, \tValid  Accuracy : 0.939,\t Train Loss : 11323.701829371097, \tValid Loss :  2858.1170788041513, \t Time for 1000 Epochs: 0.9740064659854397\n",
      "Epoch 293999 : Train Accuracy : 0.95288, \tValid  Accuracy : 0.9464,\t Train Loss : 9891.571124747294, \tValid Loss :  2527.7246906268065, \t Time for 1000 Epochs: 0.8760152239992749\n",
      "Epoch 294999 : Train Accuracy : 0.94688, \tValid  Accuracy : 0.9419,\t Train Loss : 10273.665968200297, \tValid Loss :  2660.9690269848024, \t Time for 1000 Epochs: 0.9796229809871875\n",
      "Epoch 295999 : Train Accuracy : 0.93408, \tValid  Accuracy : 0.9336,\t Train Loss : 13089.292784895733, \tValid Loss :  2995.2797743966535, \t Time for 1000 Epochs: 0.8523322719847783\n",
      "Epoch 296999 : Train Accuracy : 0.95134, \tValid  Accuracy : 0.9463,\t Train Loss : 9821.719346443911, \tValid Loss :  2372.3625117289666, \t Time for 1000 Epochs: 0.9674101620039437\n",
      "Epoch 297999 : Train Accuracy : 0.95524, \tValid  Accuracy : 0.9505,\t Train Loss : 9555.144358669124, \tValid Loss :  2351.5863685515624, \t Time for 1000 Epochs: 0.8515721430012491\n",
      "Epoch 298999 : Train Accuracy : 0.96148, \tValid  Accuracy : 0.9546,\t Train Loss : 7740.214144674965, \tValid Loss :  2106.9200967580327, \t Time for 1000 Epochs: 0.9940864029922523\n",
      "Epoch 299999 : Train Accuracy : 0.95454, \tValid  Accuracy : 0.9475,\t Train Loss : 9909.258149809091, \tValid Loss :  2591.3806479600394, \t Time for 1000 Epochs: 1.004461011994863\n",
      "Epoch 300999 : Train Accuracy : 0.92124, \tValid  Accuracy : 0.9191,\t Train Loss : 16840.304557708037, \tValid Loss :  3680.3909214393034, \t Time for 1000 Epochs: 0.9259605100087356\n",
      "Epoch 301999 : Train Accuracy : 0.95684, \tValid  Accuracy : 0.948,\t Train Loss : 9360.666147929342, \tValid Loss :  2415.2197838057614, \t Time for 1000 Epochs: 0.8869587119843345\n",
      "Epoch 302999 : Train Accuracy : 0.9325, \tValid  Accuracy : 0.9275,\t Train Loss : 16564.003888947434, \tValid Loss :  3810.77129282843, \t Time for 1000 Epochs: 1.1808899760071654\n",
      "Epoch 303999 : Train Accuracy : 0.95136, \tValid  Accuracy : 0.9479,\t Train Loss : 10027.50352489603, \tValid Loss :  2425.3923715740775, \t Time for 1000 Epochs: 1.0552943140210118\n",
      "Epoch 304999 : Train Accuracy : 0.95774, \tValid  Accuracy : 0.9521,\t Train Loss : 8328.453587799106, \tValid Loss :  2085.33843992008, \t Time for 1000 Epochs: 0.9686943299893755\n",
      "Epoch 305999 : Train Accuracy : 0.95988, \tValid  Accuracy : 0.9549,\t Train Loss : 8783.516318636643, \tValid Loss :  2308.712319836037, \t Time for 1000 Epochs: 1.3894474139960948\n",
      "Epoch 306999 : Train Accuracy : 0.95522, \tValid  Accuracy : 0.9496,\t Train Loss : 10365.041059877525, \tValid Loss :  2442.57380747666, \t Time for 1000 Epochs: 1.336400728992885\n",
      "Epoch 307999 : Train Accuracy : 0.9546, \tValid  Accuracy : 0.9506,\t Train Loss : 9605.82454826116, \tValid Loss :  2230.0784510678636, \t Time for 1000 Epochs: 0.9611256819916889\n",
      "Epoch 308999 : Train Accuracy : 0.96178, \tValid  Accuracy : 0.9542,\t Train Loss : 7469.426366881986, \tValid Loss :  1884.229520889073, \t Time for 1000 Epochs: 1.1457157969998661\n",
      "Epoch 309999 : Train Accuracy : 0.95436, \tValid  Accuracy : 0.9513,\t Train Loss : 8853.746739848113, \tValid Loss :  2146.1314896735453, \t Time for 1000 Epochs: 0.9202090070175473\n",
      "Epoch 310999 : Train Accuracy : 0.96004, \tValid  Accuracy : 0.9558,\t Train Loss : 7733.270252759215, \tValid Loss :  1798.8627561823382, \t Time for 1000 Epochs: 0.8935497569909785\n",
      "Epoch 311999 : Train Accuracy : 0.96368, \tValid  Accuracy : 0.9564,\t Train Loss : 7675.155367338254, \tValid Loss :  1968.3634553615507, \t Time for 1000 Epochs: 0.8745798329764511\n",
      "Epoch 312999 : Train Accuracy : 0.95882, \tValid  Accuracy : 0.9537,\t Train Loss : 7968.597010640022, \tValid Loss :  2033.4365923185949, \t Time for 1000 Epochs: 1.1218883499968797\n",
      "Epoch 313999 : Train Accuracy : 0.95442, \tValid  Accuracy : 0.9464,\t Train Loss : 10021.133780640417, \tValid Loss :  2612.1543905687895, \t Time for 1000 Epochs: 1.255581773002632\n",
      "Epoch 314999 : Train Accuracy : 0.9399, \tValid  Accuracy : 0.9344,\t Train Loss : 12007.693839540525, \tValid Loss :  2749.127530846152, \t Time for 1000 Epochs: 1.20427864199155\n",
      "Epoch 315999 : Train Accuracy : 0.95764, \tValid  Accuracy : 0.953,\t Train Loss : 8913.400592746942, \tValid Loss :  2203.694636817993, \t Time for 1000 Epochs: 1.2850262389983982\n",
      "Epoch 316999 : Train Accuracy : 0.9517, \tValid  Accuracy : 0.9468,\t Train Loss : 10104.971110660448, \tValid Loss :  2373.363497787631, \t Time for 1000 Epochs: 1.238250059017446\n",
      "Epoch 317999 : Train Accuracy : 0.9245, \tValid  Accuracy : 0.921,\t Train Loss : 12781.359577868363, \tValid Loss :  2934.41074018382, \t Time for 1000 Epochs: 1.2370616830012295\n",
      "Epoch 318999 : Train Accuracy : 0.9536, \tValid  Accuracy : 0.9474,\t Train Loss : 9467.165363886448, \tValid Loss :  2235.061575858982, \t Time for 1000 Epochs: 1.193115025991574\n",
      "Epoch 319999 : Train Accuracy : 0.95896, \tValid  Accuracy : 0.9525,\t Train Loss : 8557.401040436927, \tValid Loss :  2250.5376703001048, \t Time for 1000 Epochs: 1.421260186994914\n",
      "Epoch 320999 : Train Accuracy : 0.95484, \tValid  Accuracy : 0.9453,\t Train Loss : 10553.61121462462, \tValid Loss :  2616.2630925335293, \t Time for 1000 Epochs: 1.4117619849857874\n",
      "Epoch 321999 : Train Accuracy : 0.95466, \tValid  Accuracy : 0.9483,\t Train Loss : 10078.64398779647, \tValid Loss :  2522.0607043135437, \t Time for 1000 Epochs: 1.118895399995381\n",
      "Epoch 322999 : Train Accuracy : 0.95646, \tValid  Accuracy : 0.9491,\t Train Loss : 9623.13763648242, \tValid Loss :  2650.877188685332, \t Time for 1000 Epochs: 1.0415036289778072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323999 : Train Accuracy : 0.952, \tValid  Accuracy : 0.9464,\t Train Loss : 10961.363330290005, \tValid Loss :  2754.747933127178, \t Time for 1000 Epochs: 1.1274701640068088\n",
      "Epoch 324999 : Train Accuracy : 0.9508, \tValid  Accuracy : 0.947,\t Train Loss : 11357.394429922584, \tValid Loss :  2634.7688817705416, \t Time for 1000 Epochs: 1.0540679520054255\n",
      "Epoch 325999 : Train Accuracy : 0.95484, \tValid  Accuracy : 0.9532,\t Train Loss : 9576.498182825, \tValid Loss :  2337.611038242786, \t Time for 1000 Epochs: 1.0290883840061724\n",
      "Epoch 326999 : Train Accuracy : 0.95764, \tValid  Accuracy : 0.9507,\t Train Loss : 9350.083710831661, \tValid Loss :  2422.507962306944, \t Time for 1000 Epochs: 0.880432286998257\n",
      "Epoch 327999 : Train Accuracy : 0.9588, \tValid  Accuracy : 0.9532,\t Train Loss : 8729.910753389162, \tValid Loss :  2179.212599732251, \t Time for 1000 Epochs: 0.9636808629729785\n",
      "Epoch 328999 : Train Accuracy : 0.94836, \tValid  Accuracy : 0.9412,\t Train Loss : 9921.179645660231, \tValid Loss :  2577.57502604166, \t Time for 1000 Epochs: 0.9513063020131085\n",
      "Epoch 329999 : Train Accuracy : 0.95716, \tValid  Accuracy : 0.9494,\t Train Loss : 8373.737522723643, \tValid Loss :  2111.2185240666686, \t Time for 1000 Epochs: 0.8625332129886374\n",
      "Epoch 330999 : Train Accuracy : 0.95582, \tValid  Accuracy : 0.9495,\t Train Loss : 9021.116663817522, \tValid Loss :  2194.9487727072355, \t Time for 1000 Epochs: 0.8227677530085202\n",
      "Epoch 331999 : Train Accuracy : 0.95194, \tValid  Accuracy : 0.943,\t Train Loss : 11413.670684390436, \tValid Loss :  2942.995909112621, \t Time for 1000 Epochs: 0.927262380020693\n",
      "Epoch 332999 : Train Accuracy : 0.96302, \tValid  Accuracy : 0.9545,\t Train Loss : 7928.474059675887, \tValid Loss :  2249.2217480674267, \t Time for 1000 Epochs: 0.871377481991658\n",
      "Epoch 333999 : Train Accuracy : 0.96468, \tValid  Accuracy : 0.9571,\t Train Loss : 7814.200717794538, \tValid Loss :  2287.40054475903, \t Time for 1000 Epochs: 0.8549520060187206\n",
      "Epoch 334999 : Train Accuracy : 0.9612, \tValid  Accuracy : 0.9552,\t Train Loss : 8243.074680407255, \tValid Loss :  2276.0583118086156, \t Time for 1000 Epochs: 0.8406405440182425\n",
      "Epoch 335999 : Train Accuracy : 0.95716, \tValid  Accuracy : 0.9513,\t Train Loss : 9400.069579059957, \tValid Loss :  2451.8615455805184, \t Time for 1000 Epochs: 0.7498268409981392\n",
      "Epoch 336999 : Train Accuracy : 0.9532, \tValid  Accuracy : 0.9474,\t Train Loss : 9487.493048099057, \tValid Loss :  2414.835964334973, \t Time for 1000 Epochs: 0.7598250579903834\n",
      "Epoch 337999 : Train Accuracy : 0.95312, \tValid  Accuracy : 0.9494,\t Train Loss : 9783.711680721328, \tValid Loss :  2429.2496547993514, \t Time for 1000 Epochs: 0.8487476549926214\n",
      "Epoch 338999 : Train Accuracy : 0.95624, \tValid  Accuracy : 0.9498,\t Train Loss : 9080.87540004738, \tValid Loss :  2253.450423008133, \t Time for 1000 Epochs: 0.8504756719921716\n",
      "Epoch 339999 : Train Accuracy : 0.96266, \tValid  Accuracy : 0.9564,\t Train Loss : 8056.499910732569, \tValid Loss :  2180.4345428790625, \t Time for 1000 Epochs: 0.8680406659841537\n",
      "Epoch 340999 : Train Accuracy : 0.94582, \tValid  Accuracy : 0.9412,\t Train Loss : 10399.883310294852, \tValid Loss :  2574.8565227286413, \t Time for 1000 Epochs: 0.8828145769948605\n",
      "Epoch 341999 : Train Accuracy : 0.96282, \tValid  Accuracy : 0.9534,\t Train Loss : 7638.709197058976, \tValid Loss :  2161.429987399412, \t Time for 1000 Epochs: 0.8308226160006598\n",
      "Epoch 342999 : Train Accuracy : 0.96066, \tValid  Accuracy : 0.9538,\t Train Loss : 8383.885408505674, \tValid Loss :  2275.77690276501, \t Time for 1000 Epochs: 0.7981859460123815\n",
      "Epoch 343999 : Train Accuracy : 0.95866, \tValid  Accuracy : 0.9523,\t Train Loss : 9004.6769814386, \tValid Loss :  2408.6960961424766, \t Time for 1000 Epochs: 0.7847820449969731\n",
      "Epoch 344999 : Train Accuracy : 0.9631, \tValid  Accuracy : 0.9551,\t Train Loss : 7454.859287296109, \tValid Loss :  2081.021739079475, \t Time for 1000 Epochs: 0.7712338230048772\n",
      "Epoch 345999 : Train Accuracy : 0.95992, \tValid  Accuracy : 0.9521,\t Train Loss : 7812.422488958525, \tValid Loss :  2067.0919040467747, \t Time for 1000 Epochs: 0.8499469899979886\n",
      "Epoch 346999 : Train Accuracy : 0.9552, \tValid  Accuracy : 0.949,\t Train Loss : 9559.82467199507, \tValid Loss :  2359.5143842567663, \t Time for 1000 Epochs: 0.7528677950031124\n",
      "Epoch 347999 : Train Accuracy : 0.96034, \tValid  Accuracy : 0.9544,\t Train Loss : 8588.786911799405, \tValid Loss :  2286.331041424995, \t Time for 1000 Epochs: 0.764183730003424\n",
      "Epoch 348999 : Train Accuracy : 0.96176, \tValid  Accuracy : 0.9555,\t Train Loss : 8251.805409613724, \tValid Loss :  2203.956621656714, \t Time for 1000 Epochs: 0.8473210480005946\n",
      "Epoch 349999 : Train Accuracy : 0.9587, \tValid  Accuracy : 0.9519,\t Train Loss : 9474.489528759908, \tValid Loss :  2312.6836019280454, \t Time for 1000 Epochs: 0.8531227979983669\n",
      "Epoch 350999 : Train Accuracy : 0.96618, \tValid  Accuracy : 0.9577,\t Train Loss : 7314.617749982451, \tValid Loss :  2051.5179000069356, \t Time for 1000 Epochs: 0.8544723749801051\n",
      "Epoch 351999 : Train Accuracy : 0.96274, \tValid  Accuracy : 0.9533,\t Train Loss : 7614.993085284775, \tValid Loss :  2055.7436926869414, \t Time for 1000 Epochs: 0.8969491630268749\n",
      "Epoch 352999 : Train Accuracy : 0.96524, \tValid  Accuracy : 0.9563,\t Train Loss : 7865.106007513549, \tValid Loss :  2120.7344030723875, \t Time for 1000 Epochs: 0.8488743980124127\n",
      "Epoch 353999 : Train Accuracy : 0.9648, \tValid  Accuracy : 0.9569,\t Train Loss : 7356.534227485469, \tValid Loss :  1998.290290964441, \t Time for 1000 Epochs: 0.8839441739837639\n",
      "Epoch 354999 : Train Accuracy : 0.94598, \tValid  Accuracy : 0.941,\t Train Loss : 12194.976598636606, \tValid Loss :  2827.110151230471, \t Time for 1000 Epochs: 0.8985082750150468\n",
      "Epoch 355999 : Train Accuracy : 0.94838, \tValid  Accuracy : 0.9424,\t Train Loss : 9868.428109801582, \tValid Loss :  2536.2196836987678, \t Time for 1000 Epochs: 0.8013820439809933\n",
      "Epoch 356999 : Train Accuracy : 0.96164, \tValid  Accuracy : 0.9536,\t Train Loss : 7779.841710733646, \tValid Loss :  2151.2267031825113, \t Time for 1000 Epochs: 0.7803074679977726\n",
      "Epoch 357999 : Train Accuracy : 0.95174, \tValid  Accuracy : 0.9435,\t Train Loss : 10268.633271951423, \tValid Loss :  2775.7366064694356, \t Time for 1000 Epochs: 0.7620278120157309\n",
      "Epoch 358999 : Train Accuracy : 0.96132, \tValid  Accuracy : 0.9497,\t Train Loss : 8953.731924772987, \tValid Loss :  2481.8547931153003, \t Time for 1000 Epochs: 0.8512424360087607\n",
      "Epoch 359999 : Train Accuracy : 0.95332, \tValid  Accuracy : 0.9446,\t Train Loss : 9709.283288459781, \tValid Loss :  2398.243546752697, \t Time for 1000 Epochs: 0.8443776369967964\n",
      "Epoch 360999 : Train Accuracy : 0.96146, \tValid  Accuracy : 0.9536,\t Train Loss : 8035.600168695483, \tValid Loss :  2187.409313909936, \t Time for 1000 Epochs: 0.7564232290023938\n",
      "Epoch 361999 : Train Accuracy : 0.96092, \tValid  Accuracy : 0.954,\t Train Loss : 8654.456533574768, \tValid Loss :  2349.7320916880317, \t Time for 1000 Epochs: 0.7561302940011956\n",
      "Epoch 362999 : Train Accuracy : 0.94692, \tValid  Accuracy : 0.9428,\t Train Loss : 12048.554783939271, \tValid Loss :  2937.003225296971, \t Time for 1000 Epochs: 0.9297096990048885\n",
      "Epoch 363999 : Train Accuracy : 0.9569, \tValid  Accuracy : 0.9475,\t Train Loss : 9686.19148988079, \tValid Loss :  2607.0142621604446, \t Time for 1000 Epochs: 1.1420011289883405\n",
      "Epoch 364999 : Train Accuracy : 0.9418, \tValid  Accuracy : 0.9413,\t Train Loss : 13200.215200672188, \tValid Loss :  2941.8222451414968, \t Time for 1000 Epochs: 1.4014977240003645\n",
      "Epoch 365999 : Train Accuracy : 0.95178, \tValid  Accuracy : 0.9461,\t Train Loss : 11228.137143191974, \tValid Loss :  2799.255474311881, \t Time for 1000 Epochs: 1.358306352980435\n",
      "Epoch 366999 : Train Accuracy : 0.94868, \tValid  Accuracy : 0.9405,\t Train Loss : 10283.980911864875, \tValid Loss :  2533.4382622844523, \t Time for 1000 Epochs: 1.489966706983978\n",
      "Epoch 367999 : Train Accuracy : 0.9426, \tValid  Accuracy : 0.9365,\t Train Loss : 11314.06814082414, \tValid Loss :  2705.944424037188, \t Time for 1000 Epochs: 0.8522031660249922\n",
      "Epoch 368999 : Train Accuracy : 0.9605, \tValid  Accuracy : 0.9538,\t Train Loss : 7948.301609634983, \tValid Loss :  2067.007526102376, \t Time for 1000 Epochs: 0.9588373430015054\n",
      "Epoch 369999 : Train Accuracy : 0.95464, \tValid  Accuracy : 0.9471,\t Train Loss : 8911.574197640835, \tValid Loss :  2320.947039616861, \t Time for 1000 Epochs: 0.8849625469883904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370999 : Train Accuracy : 0.95656, \tValid  Accuracy : 0.9482,\t Train Loss : 9499.174228653486, \tValid Loss :  2442.5649321493247, \t Time for 1000 Epochs: 1.1875060989987105\n",
      "Epoch 371999 : Train Accuracy : 0.96058, \tValid  Accuracy : 0.9541,\t Train Loss : 8299.355229889454, \tValid Loss :  1980.1000761425432, \t Time for 1000 Epochs: 1.021348071983084\n",
      "Epoch 372999 : Train Accuracy : 0.95588, \tValid  Accuracy : 0.9484,\t Train Loss : 9323.936444809216, \tValid Loss :  2452.0060360191937, \t Time for 1000 Epochs: 0.9363126539974473\n",
      "Epoch 373999 : Train Accuracy : 0.96024, \tValid  Accuracy : 0.9541,\t Train Loss : 8362.983179706855, \tValid Loss :  2045.9137828099356, \t Time for 1000 Epochs: 0.7987117989978287\n",
      "Epoch 374999 : Train Accuracy : 0.92956, \tValid  Accuracy : 0.9258,\t Train Loss : 24247.967536835808, \tValid Loss :  5306.025477554058, \t Time for 1000 Epochs: 0.8787638600042555\n",
      "Epoch 375999 : Train Accuracy : 0.94596, \tValid  Accuracy : 0.937,\t Train Loss : 11793.504947291789, \tValid Loss :  2946.5148063104575, \t Time for 1000 Epochs: 1.0541124810115434\n",
      "Epoch 376999 : Train Accuracy : 0.94166, \tValid  Accuracy : 0.9382,\t Train Loss : 12329.984317426412, \tValid Loss :  2905.048160458181, \t Time for 1000 Epochs: 0.9587151689920574\n",
      "Epoch 377999 : Train Accuracy : 0.94298, \tValid  Accuracy : 0.9389,\t Train Loss : 12451.425531729126, \tValid Loss :  2976.735721711168, \t Time for 1000 Epochs: 0.9133062379842158\n",
      "Epoch 378999 : Train Accuracy : 0.9569, \tValid  Accuracy : 0.9481,\t Train Loss : 8937.801167843743, \tValid Loss :  2501.592708314703, \t Time for 1000 Epochs: 0.9136173779843375\n",
      "Epoch 379999 : Train Accuracy : 0.9576, \tValid  Accuracy : 0.9478,\t Train Loss : 8279.888256975555, \tValid Loss :  2227.4940767124117, \t Time for 1000 Epochs: 0.843739130999893\n",
      "Epoch 380999 : Train Accuracy : 0.95338, \tValid  Accuracy : 0.9459,\t Train Loss : 10704.435147525464, \tValid Loss :  2776.2480802998844, \t Time for 1000 Epochs: 0.8864947719848715\n",
      "Epoch 381999 : Train Accuracy : 0.95626, \tValid  Accuracy : 0.9498,\t Train Loss : 9131.804693096514, \tValid Loss :  2275.534269911867, \t Time for 1000 Epochs: 0.9464383359882049\n",
      "Epoch 382999 : Train Accuracy : 0.9469, \tValid  Accuracy : 0.9429,\t Train Loss : 11511.989603436861, \tValid Loss :  2731.400407159417, \t Time for 1000 Epochs: 0.9264308099809568\n",
      "Epoch 383999 : Train Accuracy : 0.95748, \tValid  Accuracy : 0.9504,\t Train Loss : 9407.16005554376, \tValid Loss :  2388.2395362125467, \t Time for 1000 Epochs: 0.9169335510232486\n",
      "Epoch 384999 : Train Accuracy : 0.95786, \tValid  Accuracy : 0.9501,\t Train Loss : 10161.122535890374, \tValid Loss :  2491.697713438235, \t Time for 1000 Epochs: 1.000821552996058\n",
      "Epoch 385999 : Train Accuracy : 0.95594, \tValid  Accuracy : 0.95,\t Train Loss : 10647.600181158949, \tValid Loss :  2461.48678511038, \t Time for 1000 Epochs: 0.9742162049806211\n",
      "Epoch 386999 : Train Accuracy : 0.9506, \tValid  Accuracy : 0.9452,\t Train Loss : 10236.462378308492, \tValid Loss :  2472.63478002749, \t Time for 1000 Epochs: 1.1272307260078378\n",
      "Epoch 387999 : Train Accuracy : 0.9573, \tValid  Accuracy : 0.9519,\t Train Loss : 10254.913371072713, \tValid Loss :  2554.6099111509775, \t Time for 1000 Epochs: 1.2331221389758866\n",
      "Epoch 388999 : Train Accuracy : 0.91846, \tValid  Accuracy : 0.9126,\t Train Loss : 19529.72139820172, \tValid Loss :  4038.4203193099593, \t Time for 1000 Epochs: 1.0254863630107138\n",
      "Epoch 389999 : Train Accuracy : 0.95342, \tValid  Accuracy : 0.9487,\t Train Loss : 10876.165741533772, \tValid Loss :  2534.773377485933, \t Time for 1000 Epochs: 0.85166965200915\n",
      "Epoch 390999 : Train Accuracy : 0.95214, \tValid  Accuracy : 0.9437,\t Train Loss : 10702.2698547078, \tValid Loss :  2525.819368051397, \t Time for 1000 Epochs: 0.8500363400089554\n",
      "Epoch 391999 : Train Accuracy : 0.95656, \tValid  Accuracy : 0.9492,\t Train Loss : 10205.762924028932, \tValid Loss :  2407.0093595130784, \t Time for 1000 Epochs: 1.0211442909785546\n",
      "Epoch 392999 : Train Accuracy : 0.95772, \tValid  Accuracy : 0.95,\t Train Loss : 9674.753638610564, \tValid Loss :  2489.8030383208375, \t Time for 1000 Epochs: 0.9129224520002026\n",
      "Epoch 393999 : Train Accuracy : 0.95438, \tValid  Accuracy : 0.9485,\t Train Loss : 9754.66313657451, \tValid Loss :  2382.338275505745, \t Time for 1000 Epochs: 0.9029963400098495\n",
      "Epoch 394999 : Train Accuracy : 0.93228, \tValid  Accuracy : 0.9282,\t Train Loss : 13539.905592968425, \tValid Loss :  3056.5914944408814, \t Time for 1000 Epochs: 1.0207124029984698\n",
      "Epoch 395999 : Train Accuracy : 0.9592, \tValid  Accuracy : 0.9482,\t Train Loss : 8232.976455052853, \tValid Loss :  2191.2160913969556, \t Time for 1000 Epochs: 0.7684180469950661\n",
      "Epoch 396999 : Train Accuracy : 0.9431, \tValid  Accuracy : 0.9357,\t Train Loss : 10725.82288015446, \tValid Loss :  2555.7930876970877, \t Time for 1000 Epochs: 0.897924538992811\n",
      "Epoch 397999 : Train Accuracy : 0.95996, \tValid  Accuracy : 0.9531,\t Train Loss : 8059.722006582, \tValid Loss :  2187.05086294763, \t Time for 1000 Epochs: 0.8734982440073509\n",
      "Epoch 398999 : Train Accuracy : 0.9606, \tValid  Accuracy : 0.9528,\t Train Loss : 8851.838799139934, \tValid Loss :  2318.4553346978287, \t Time for 1000 Epochs: 1.006243577983696\n",
      "Epoch 399999 : Train Accuracy : 0.95444, \tValid  Accuracy : 0.9476,\t Train Loss : 9590.58081846403, \tValid Loss :  2453.1910822457094, \t Time for 1000 Epochs: 1.1172092219931073\n",
      "Epoch 400999 : Train Accuracy : 0.92796, \tValid  Accuracy : 0.9203,\t Train Loss : 12980.572743980085, \tValid Loss :  3126.2178052402905, \t Time for 1000 Epochs: 1.025680383987492\n",
      "Epoch 401999 : Train Accuracy : 0.96182, \tValid  Accuracy : 0.9542,\t Train Loss : 8166.819726762816, \tValid Loss :  2229.0603290377176, \t Time for 1000 Epochs: 1.049846777023049\n",
      "Epoch 402999 : Train Accuracy : 0.9549, \tValid  Accuracy : 0.9467,\t Train Loss : 9546.792856564423, \tValid Loss :  2510.6769588734214, \t Time for 1000 Epochs: 1.2725929589942098\n",
      "Epoch 403999 : Train Accuracy : 0.95858, \tValid  Accuracy : 0.9519,\t Train Loss : 8249.43952406119, \tValid Loss :  2126.1130854291428, \t Time for 1000 Epochs: 1.1289245589869097\n",
      "Epoch 404999 : Train Accuracy : 0.9604, \tValid  Accuracy : 0.9522,\t Train Loss : 8086.44976357172, \tValid Loss :  2115.238830562581, \t Time for 1000 Epochs: 0.9247259700205177\n",
      "Epoch 405999 : Train Accuracy : 0.96398, \tValid  Accuracy : 0.9547,\t Train Loss : 7485.42356373147, \tValid Loss :  2136.9547346430027, \t Time for 1000 Epochs: 0.9260729159868788\n",
      "Epoch 406999 : Train Accuracy : 0.95296, \tValid  Accuracy : 0.9473,\t Train Loss : 9661.259010902315, \tValid Loss :  2426.767804058803, \t Time for 1000 Epochs: 0.9235725339967757\n",
      "Epoch 407999 : Train Accuracy : 0.95654, \tValid  Accuracy : 0.9504,\t Train Loss : 9748.942667992162, \tValid Loss :  2426.262392493902, \t Time for 1000 Epochs: 0.9006823529780377\n",
      "Epoch 408999 : Train Accuracy : 0.95572, \tValid  Accuracy : 0.95,\t Train Loss : 9625.222827121868, \tValid Loss :  2351.3037824353337, \t Time for 1000 Epochs: 0.9396154099958949\n",
      "Epoch 409999 : Train Accuracy : 0.9529, \tValid  Accuracy : 0.9473,\t Train Loss : 9660.537660732556, \tValid Loss :  2382.5904283519762, \t Time for 1000 Epochs: 1.0035431449941825\n",
      "Epoch 410999 : Train Accuracy : 0.92144, \tValid  Accuracy : 0.9181,\t Train Loss : 18081.819258889, \tValid Loss :  3980.1899575709886, \t Time for 1000 Epochs: 0.9734959429770242\n",
      "Epoch 411999 : Train Accuracy : 0.95476, \tValid  Accuracy : 0.9502,\t Train Loss : 9679.46335636262, \tValid Loss :  2349.6493470919545, \t Time for 1000 Epochs: 0.8612179979973007\n",
      "Epoch 412999 : Train Accuracy : 0.94442, \tValid  Accuracy : 0.9374,\t Train Loss : 11365.931501614778, \tValid Loss :  2667.359483737549, \t Time for 1000 Epochs: 0.9168461399967782\n",
      "Epoch 413999 : Train Accuracy : 0.94494, \tValid  Accuracy : 0.9405,\t Train Loss : 11973.915687956642, \tValid Loss :  2846.3618174009944, \t Time for 1000 Epochs: 0.8539199490041938\n",
      "Epoch 414999 : Train Accuracy : 0.94866, \tValid  Accuracy : 0.9385,\t Train Loss : 11948.591552966012, \tValid Loss :  3067.530805874255, \t Time for 1000 Epochs: 0.9258666980022099\n",
      "Epoch 415999 : Train Accuracy : 0.9557, \tValid  Accuracy : 0.9499,\t Train Loss : 10327.514941602345, \tValid Loss :  2740.8294313370334, \t Time for 1000 Epochs: 0.8856266270158812\n",
      "Epoch 416999 : Train Accuracy : 0.95578, \tValid  Accuracy : 0.9482,\t Train Loss : 9399.612138402737, \tValid Loss :  2645.625182445866, \t Time for 1000 Epochs: 0.8680155000183731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417999 : Train Accuracy : 0.94648, \tValid  Accuracy : 0.9377,\t Train Loss : 10358.7594480948, \tValid Loss :  2682.2764805099005, \t Time for 1000 Epochs: 0.8705298890126869\n",
      "Epoch 418999 : Train Accuracy : 0.94412, \tValid  Accuracy : 0.941,\t Train Loss : 11435.94608573623, \tValid Loss :  2744.876212695825, \t Time for 1000 Epochs: 0.8769318809791002\n",
      "Epoch 419999 : Train Accuracy : 0.95114, \tValid  Accuracy : 0.9435,\t Train Loss : 9765.072828386124, \tValid Loss :  2607.6308249369904, \t Time for 1000 Epochs: 0.8814767040021252\n",
      "Epoch 420999 : Train Accuracy : 0.94838, \tValid  Accuracy : 0.9379,\t Train Loss : 12037.899485465467, \tValid Loss :  3267.6770553930637, \t Time for 1000 Epochs: 0.913056924007833\n",
      "Epoch 421999 : Train Accuracy : 0.9456, \tValid  Accuracy : 0.9376,\t Train Loss : 11886.866033031582, \tValid Loss :  2940.966157646464, \t Time for 1000 Epochs: 0.9358991259941831\n",
      "Epoch 422999 : Train Accuracy : 0.94962, \tValid  Accuracy : 0.9418,\t Train Loss : 10430.597485620354, \tValid Loss :  2675.282664709937, \t Time for 1000 Epochs: 0.8855596270004753\n",
      "Epoch 423999 : Train Accuracy : 0.95332, \tValid  Accuracy : 0.9458,\t Train Loss : 9471.287030574815, \tValid Loss :  2507.942832218079, \t Time for 1000 Epochs: 0.8146245430107228\n",
      "Epoch 424999 : Train Accuracy : 0.95712, \tValid  Accuracy : 0.9486,\t Train Loss : 9808.859671696977, \tValid Loss :  2515.398746954103, \t Time for 1000 Epochs: 0.8354151179955807\n",
      "Epoch 425999 : Train Accuracy : 0.96442, \tValid  Accuracy : 0.9543,\t Train Loss : 8151.606984050857, \tValid Loss :  2394.866941092148, \t Time for 1000 Epochs: 0.8320938399992883\n",
      "Epoch 426999 : Train Accuracy : 0.95538, \tValid  Accuracy : 0.9486,\t Train Loss : 10625.036808054785, \tValid Loss :  2841.8326472366684, \t Time for 1000 Epochs: 0.8367166890238877\n",
      "Epoch 427999 : Train Accuracy : 0.95036, \tValid  Accuracy : 0.9432,\t Train Loss : 12800.326407839915, \tValid Loss :  3106.82746574906, \t Time for 1000 Epochs: 0.831690343999071\n",
      "Epoch 428999 : Train Accuracy : 0.95488, \tValid  Accuracy : 0.9477,\t Train Loss : 9329.059419051122, \tValid Loss :  2333.088136385926, \t Time for 1000 Epochs: 0.8398922329943161\n",
      "Epoch 429999 : Train Accuracy : 0.95852, \tValid  Accuracy : 0.9517,\t Train Loss : 8732.027619175558, \tValid Loss :  2371.515105532892, \t Time for 1000 Epochs: 0.8338752160198055\n",
      "Epoch 430999 : Train Accuracy : 0.95792, \tValid  Accuracy : 0.95,\t Train Loss : 9148.111140758267, \tValid Loss :  2462.624010604536, \t Time for 1000 Epochs: 0.835914422001224\n",
      "Epoch 431999 : Train Accuracy : 0.96314, \tValid  Accuracy : 0.9546,\t Train Loss : 7971.26207659122, \tValid Loss :  2215.036827694359, \t Time for 1000 Epochs: 0.8343430070090108\n",
      "Epoch 432999 : Train Accuracy : 0.93284, \tValid  Accuracy : 0.9277,\t Train Loss : 17665.91290450089, \tValid Loss :  3792.189943605529, \t Time for 1000 Epochs: 0.8429066629905719\n",
      "Epoch 433999 : Train Accuracy : 0.93466, \tValid  Accuracy : 0.9285,\t Train Loss : 15415.494516268522, \tValid Loss :  3536.456369050326, \t Time for 1000 Epochs: 0.908604807977099\n",
      "Epoch 434999 : Train Accuracy : 0.93766, \tValid  Accuracy : 0.9294,\t Train Loss : 12559.953172613326, \tValid Loss :  3152.565988469745, \t Time for 1000 Epochs: 0.8825967200100422\n",
      "Epoch 435999 : Train Accuracy : 0.95348, \tValid  Accuracy : 0.9449,\t Train Loss : 10601.27463983183, \tValid Loss :  2695.1522692810154, \t Time for 1000 Epochs: 0.765021467988845\n",
      "Epoch 436999 : Train Accuracy : 0.95822, \tValid  Accuracy : 0.9524,\t Train Loss : 9582.003669161126, \tValid Loss :  2485.1541148504034, \t Time for 1000 Epochs: 0.8501752520096488\n",
      "Epoch 437999 : Train Accuracy : 0.95366, \tValid  Accuracy : 0.9468,\t Train Loss : 9900.346666926842, \tValid Loss :  2544.8696854099203, \t Time for 1000 Epochs: 0.8334530629799701\n",
      "Epoch 438999 : Train Accuracy : 0.95554, \tValid  Accuracy : 0.9465,\t Train Loss : 9097.150723242246, \tValid Loss :  2410.531960543175, \t Time for 1000 Epochs: 0.7513516460021492\n",
      "Epoch 439999 : Train Accuracy : 0.95892, \tValid  Accuracy : 0.9541,\t Train Loss : 8425.244218758751, \tValid Loss :  2248.5857036443726, \t Time for 1000 Epochs: 0.8372594440006651\n",
      "Epoch 440999 : Train Accuracy : 0.94386, \tValid  Accuracy : 0.9401,\t Train Loss : 13152.216685321648, \tValid Loss :  3103.8333943036146, \t Time for 1000 Epochs: 0.7471063470002264\n",
      "Epoch 441999 : Train Accuracy : 0.9483, \tValid  Accuracy : 0.9418,\t Train Loss : 10315.77713775383, \tValid Loss :  2644.9157235238736, \t Time for 1000 Epochs: 0.8544886329909787\n",
      "Epoch 442999 : Train Accuracy : 0.94396, \tValid  Accuracy : 0.9368,\t Train Loss : 14077.863237637299, \tValid Loss :  3472.8326779119516, \t Time for 1000 Epochs: 0.8537547910236754\n",
      "Epoch 443999 : Train Accuracy : 0.95326, \tValid  Accuracy : 0.9454,\t Train Loss : 11206.924736232999, \tValid Loss :  2788.8227719256984, \t Time for 1000 Epochs: 0.852350467001088\n",
      "Epoch 444999 : Train Accuracy : 0.9479, \tValid  Accuracy : 0.9403,\t Train Loss : 10173.184061011982, \tValid Loss :  2671.974419641096, \t Time for 1000 Epochs: 0.8625102689838968\n",
      "Epoch 445999 : Train Accuracy : 0.95304, \tValid  Accuracy : 0.946,\t Train Loss : 9685.177838075819, \tValid Loss :  2555.602083779725, \t Time for 1000 Epochs: 0.7665083440078888\n",
      "Epoch 446999 : Train Accuracy : 0.96172, \tValid  Accuracy : 0.9531,\t Train Loss : 8504.720583942477, \tValid Loss :  2427.445560091211, \t Time for 1000 Epochs: 0.8925039610185195\n",
      "Epoch 447999 : Train Accuracy : 0.9497, \tValid  Accuracy : 0.9445,\t Train Loss : 12098.531449951986, \tValid Loss :  2905.052004800383, \t Time for 1000 Epochs: 0.8685405750002246\n",
      "Epoch 448999 : Train Accuracy : 0.9535, \tValid  Accuracy : 0.949,\t Train Loss : 9782.310760577013, \tValid Loss :  2623.172071607027, \t Time for 1000 Epochs: 0.8481708189938217\n",
      "Epoch 449999 : Train Accuracy : 0.95578, \tValid  Accuracy : 0.9493,\t Train Loss : 8662.098954075873, \tValid Loss :  2408.490495016059, \t Time for 1000 Epochs: 0.8507330199936405\n",
      "Epoch 450999 : Train Accuracy : 0.936, \tValid  Accuracy : 0.931,\t Train Loss : 12249.100322094302, \tValid Loss :  3005.919553132846, \t Time for 1000 Epochs: 0.8350315690040588\n",
      "Epoch 451999 : Train Accuracy : 0.9565, \tValid  Accuracy : 0.9479,\t Train Loss : 9879.692987462378, \tValid Loss :  2704.805904986821, \t Time for 1000 Epochs: 0.7490697620087303\n",
      "Epoch 452999 : Train Accuracy : 0.9511, \tValid  Accuracy : 0.9469,\t Train Loss : 10901.622872464837, \tValid Loss :  2734.8142230544036, \t Time for 1000 Epochs: 0.8362085589906201\n",
      "Epoch 453999 : Train Accuracy : 0.9212, \tValid  Accuracy : 0.9183,\t Train Loss : 15790.435542571606, \tValid Loss :  3646.131338346853, \t Time for 1000 Epochs: 0.8364254749903921\n",
      "Epoch 454999 : Train Accuracy : 0.95438, \tValid  Accuracy : 0.9471,\t Train Loss : 9516.731224612902, \tValid Loss :  2532.3661612154383, \t Time for 1000 Epochs: 0.7505230480164755\n",
      "Epoch 455999 : Train Accuracy : 0.95686, \tValid  Accuracy : 0.9501,\t Train Loss : 9066.359998248614, \tValid Loss :  2525.103278643953, \t Time for 1000 Epochs: 0.8394614479911979\n",
      "Epoch 456999 : Train Accuracy : 0.96018, \tValid  Accuracy : 0.9503,\t Train Loss : 9645.797363990889, \tValid Loss :  2764.2192585614716, \t Time for 1000 Epochs: 0.8349001189926639\n",
      "Epoch 457999 : Train Accuracy : 0.95582, \tValid  Accuracy : 0.9489,\t Train Loss : 9309.88178806669, \tValid Loss :  2513.323886568111, \t Time for 1000 Epochs: 0.8370152789866552\n",
      "Epoch 458999 : Train Accuracy : 0.95674, \tValid  Accuracy : 0.9486,\t Train Loss : 9631.921057902468, \tValid Loss :  2564.615930882791, \t Time for 1000 Epochs: 0.8770497069926932\n",
      "Epoch 459999 : Train Accuracy : 0.96404, \tValid  Accuracy : 0.957,\t Train Loss : 8023.622231980697, \tValid Loss :  2238.1679026803877, \t Time for 1000 Epochs: 0.8833411349914968\n",
      "Epoch 460999 : Train Accuracy : 0.94188, \tValid  Accuracy : 0.9339,\t Train Loss : 12206.601993625567, \tValid Loss :  3114.101541539725, \t Time for 1000 Epochs: 0.8660141790169291\n",
      "Epoch 461999 : Train Accuracy : 0.95748, \tValid  Accuracy : 0.9497,\t Train Loss : 9585.19634919992, \tValid Loss :  2523.6556749295733, \t Time for 1000 Epochs: 0.8450717899831943\n",
      "Epoch 462999 : Train Accuracy : 0.95712, \tValid  Accuracy : 0.9492,\t Train Loss : 10376.146865757342, \tValid Loss :  2705.0565993880487, \t Time for 1000 Epochs: 0.7532078929943964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463999 : Train Accuracy : 0.93982, \tValid  Accuracy : 0.9326,\t Train Loss : 16052.648631938338, \tValid Loss :  3813.932650466158, \t Time for 1000 Epochs: 0.838086381991161\n",
      "Epoch 464999 : Train Accuracy : 0.95328, \tValid  Accuracy : 0.9448,\t Train Loss : 10544.024738199852, \tValid Loss :  2999.7772336509065, \t Time for 1000 Epochs: 0.8423548809951171\n",
      "Epoch 465999 : Train Accuracy : 0.94818, \tValid  Accuracy : 0.9429,\t Train Loss : 10306.255587048425, \tValid Loss :  2712.2191634065134, \t Time for 1000 Epochs: 0.8397570129891392\n",
      "Epoch 466999 : Train Accuracy : 0.94866, \tValid  Accuracy : 0.9398,\t Train Loss : 11847.36523468025, \tValid Loss :  3037.050061461053, \t Time for 1000 Epochs: 0.8328860930050723\n",
      "Epoch 467999 : Train Accuracy : 0.9393, \tValid  Accuracy : 0.9354,\t Train Loss : 13406.467393931316, \tValid Loss :  3014.594519640146, \t Time for 1000 Epochs: 0.8384563639992848\n",
      "Epoch 468999 : Train Accuracy : 0.94534, \tValid  Accuracy : 0.9384,\t Train Loss : 10913.698922747619, \tValid Loss :  2852.5351604283023, \t Time for 1000 Epochs: 0.8354812560137361\n",
      "Epoch 469999 : Train Accuracy : 0.95316, \tValid  Accuracy : 0.948,\t Train Loss : 9254.642969553597, \tValid Loss :  2392.928428095758, \t Time for 1000 Epochs: 0.7448685829876922\n",
      "Epoch 470999 : Train Accuracy : 0.96066, \tValid  Accuracy : 0.9533,\t Train Loss : 8384.14298514253, \tValid Loss :  2318.8676255136556, \t Time for 1000 Epochs: 0.8496651719906367\n",
      "Epoch 471999 : Train Accuracy : 0.9523, \tValid  Accuracy : 0.9481,\t Train Loss : 10450.01385613305, \tValid Loss :  2717.42659347905, \t Time for 1000 Epochs: 0.918723342998419\n",
      "Epoch 472999 : Train Accuracy : 0.95446, \tValid  Accuracy : 0.9466,\t Train Loss : 9293.854978278323, \tValid Loss :  2370.365623007948, \t Time for 1000 Epochs: 0.9215085250034463\n",
      "Epoch 473999 : Train Accuracy : 0.95734, \tValid  Accuracy : 0.9518,\t Train Loss : 9608.422252370197, \tValid Loss :  2530.622725202957, \t Time for 1000 Epochs: 0.8248338169942144\n",
      "Epoch 474999 : Train Accuracy : 0.9503, \tValid  Accuracy : 0.9422,\t Train Loss : 9712.385826036114, \tValid Loss :  2458.5112620340487, \t Time for 1000 Epochs: 0.8825600800046232\n",
      "Epoch 475999 : Train Accuracy : 0.95052, \tValid  Accuracy : 0.9438,\t Train Loss : 9791.441214875233, \tValid Loss :  2454.037409131089, \t Time for 1000 Epochs: 0.7955143690051045\n",
      "Epoch 476999 : Train Accuracy : 0.95018, \tValid  Accuracy : 0.9456,\t Train Loss : 10457.266534131333, \tValid Loss :  2597.780419825259, \t Time for 1000 Epochs: 0.7959319170040544\n",
      "Epoch 477999 : Train Accuracy : 0.96216, \tValid  Accuracy : 0.9554,\t Train Loss : 8213.865610571938, \tValid Loss :  2266.4376436790017, \t Time for 1000 Epochs: 0.8838183220068458\n",
      "Epoch 478999 : Train Accuracy : 0.95764, \tValid  Accuracy : 0.9508,\t Train Loss : 9194.231546943733, \tValid Loss :  2484.806216133584, \t Time for 1000 Epochs: 0.8770389659912325\n",
      "Epoch 479999 : Train Accuracy : 0.91976, \tValid  Accuracy : 0.9147,\t Train Loss : 15024.421048315638, \tValid Loss :  3531.2834665905966, \t Time for 1000 Epochs: 0.8827967089891899\n",
      "Epoch 480999 : Train Accuracy : 0.95942, \tValid  Accuracy : 0.9526,\t Train Loss : 9471.80766353871, \tValid Loss :  2446.7284944595103, \t Time for 1000 Epochs: 0.8739236640103627\n",
      "Epoch 481999 : Train Accuracy : 0.9517, \tValid  Accuracy : 0.9491,\t Train Loss : 10134.772260081676, \tValid Loss :  2491.9052157036695, \t Time for 1000 Epochs: 0.8733064039843157\n",
      "Epoch 482999 : Train Accuracy : 0.94904, \tValid  Accuracy : 0.9432,\t Train Loss : 10616.309172904093, \tValid Loss :  2883.432255173694, \t Time for 1000 Epochs: 0.879130196000915\n",
      "Epoch 483999 : Train Accuracy : 0.9602, \tValid  Accuracy : 0.9538,\t Train Loss : 8314.266776509958, \tValid Loss :  2297.81269600726, \t Time for 1000 Epochs: 0.9388524040114135\n",
      "Epoch 484999 : Train Accuracy : 0.95134, \tValid  Accuracy : 0.9451,\t Train Loss : 10260.967399682946, \tValid Loss :  2654.532082845542, \t Time for 1000 Epochs: 0.940580135997152\n",
      "Epoch 485999 : Train Accuracy : 0.92974, \tValid  Accuracy : 0.9234,\t Train Loss : 15218.827172292771, \tValid Loss :  3860.84398274685, \t Time for 1000 Epochs: 0.920884195016697\n",
      "Epoch 486999 : Train Accuracy : 0.95288, \tValid  Accuracy : 0.9445,\t Train Loss : 12989.125337690444, \tValid Loss :  3353.4786052145264, \t Time for 1000 Epochs: 0.879573866026476\n",
      "Epoch 487999 : Train Accuracy : 0.95632, \tValid  Accuracy : 0.9476,\t Train Loss : 9790.321492638077, \tValid Loss :  2814.182286122937, \t Time for 1000 Epochs: 0.8849250560160726\n",
      "Epoch 488999 : Train Accuracy : 0.9455, \tValid  Accuracy : 0.9394,\t Train Loss : 11629.963658901874, \tValid Loss :  2974.2555629396043, \t Time for 1000 Epochs: 0.8808545270003378\n",
      "Epoch 489999 : Train Accuracy : 0.88426, \tValid  Accuracy : 0.8833,\t Train Loss : 19587.788686936667, \tValid Loss :  4472.7165485344385, \t Time for 1000 Epochs: 0.8715113470098004\n",
      "Epoch 490999 : Train Accuracy : 0.9493, \tValid  Accuracy : 0.9425,\t Train Loss : 11438.370755430915, \tValid Loss :  2972.8428534702493, \t Time for 1000 Epochs: 0.8862368620175403\n",
      "Epoch 491999 : Train Accuracy : 0.94562, \tValid  Accuracy : 0.9393,\t Train Loss : 12743.852865907014, \tValid Loss :  3344.6193931071134, \t Time for 1000 Epochs: 0.8777325559931342\n",
      "Epoch 492999 : Train Accuracy : 0.95154, \tValid  Accuracy : 0.9456,\t Train Loss : 9212.07806545101, \tValid Loss :  2428.80839016452, \t Time for 1000 Epochs: 0.8856070920010097\n",
      "Epoch 493999 : Train Accuracy : 0.95072, \tValid  Accuracy : 0.945,\t Train Loss : 10545.15788436643, \tValid Loss :  2639.759420505892, \t Time for 1000 Epochs: 0.8906386680027936\n",
      "Epoch 494999 : Train Accuracy : 0.93984, \tValid  Accuracy : 0.9341,\t Train Loss : 11930.13945312657, \tValid Loss :  2854.87157368942, \t Time for 1000 Epochs: 0.8871487709984649\n",
      "Epoch 495999 : Train Accuracy : 0.95144, \tValid  Accuracy : 0.9452,\t Train Loss : 10206.583664713755, \tValid Loss :  2646.3427614383604, \t Time for 1000 Epochs: 0.9760394139739219\n",
      "Epoch 496999 : Train Accuracy : 0.94532, \tValid  Accuracy : 0.9361,\t Train Loss : 10903.417152326487, \tValid Loss :  2739.353129079489, \t Time for 1000 Epochs: 0.925067783013219\n",
      "Epoch 497999 : Train Accuracy : 0.9547, \tValid  Accuracy : 0.9452,\t Train Loss : 10432.343788862981, \tValid Loss :  2692.5134569087845, \t Time for 1000 Epochs: 0.9245572760119103\n",
      "Epoch 498999 : Train Accuracy : 0.91654, \tValid  Accuracy : 0.9127,\t Train Loss : 13041.176924403739, \tValid Loss :  3079.3522144223457, \t Time for 1000 Epochs: 0.876615439017769\n",
      "Epoch 499999 : Train Accuracy : 0.95004, \tValid  Accuracy : 0.9407,\t Train Loss : 9465.096104970042, \tValid Loss :  2456.343337747064, \t Time for 1000 Epochs: 0.8758968450129032\n",
      "Epoch 500999 : Train Accuracy : 0.94552, \tValid  Accuracy : 0.9371,\t Train Loss : 10647.253948453605, \tValid Loss :  2657.465802548256, \t Time for 1000 Epochs: 0.8825282139878254\n",
      "Epoch 501999 : Train Accuracy : 0.9416, \tValid  Accuracy : 0.9352,\t Train Loss : 11448.651120780269, \tValid Loss :  2693.2931551287784, \t Time for 1000 Epochs: 0.8786899769911543\n",
      "Epoch 502999 : Train Accuracy : 0.9412, \tValid  Accuracy : 0.9345,\t Train Loss : 13159.922643773649, \tValid Loss :  3115.991172909753, \t Time for 1000 Epochs: 0.8688363510009367\n",
      "Epoch 503999 : Train Accuracy : 0.93888, \tValid  Accuracy : 0.9327,\t Train Loss : 13523.699316803199, \tValid Loss :  3000.2238541799466, \t Time for 1000 Epochs: 0.8847716480086092\n",
      "Epoch 504999 : Train Accuracy : 0.95754, \tValid  Accuracy : 0.9498,\t Train Loss : 9169.180092760265, \tValid Loss :  2424.8203950014927, \t Time for 1000 Epochs: 0.8780272830044851\n",
      "Epoch 505999 : Train Accuracy : 0.93962, \tValid  Accuracy : 0.9309,\t Train Loss : 10982.893129964554, \tValid Loss :  2713.5494014189344, \t Time for 1000 Epochs: 0.8755666039942298\n",
      "Epoch 506999 : Train Accuracy : 0.95422, \tValid  Accuracy : 0.945,\t Train Loss : 8754.995804102631, \tValid Loss :  2429.7677759681537, \t Time for 1000 Epochs: 0.7824590530071873\n",
      "Epoch 507999 : Train Accuracy : 0.9466, \tValid  Accuracy : 0.9414,\t Train Loss : 10658.099982071584, \tValid Loss :  2674.2657343387127, \t Time for 1000 Epochs: 0.9421864530013409\n",
      "Epoch 508999 : Train Accuracy : 0.94104, \tValid  Accuracy : 0.9363,\t Train Loss : 12694.445926436707, \tValid Loss :  2947.6093097942044, \t Time for 1000 Epochs: 0.9174155429936945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 509999 : Train Accuracy : 0.94508, \tValid  Accuracy : 0.9382,\t Train Loss : 10419.364556756744, \tValid Loss :  2589.884972954655, \t Time for 1000 Epochs: 0.8067757569951937\n",
      "Epoch 510999 : Train Accuracy : 0.95464, \tValid  Accuracy : 0.947,\t Train Loss : 9814.119376320472, \tValid Loss :  2432.8127528171676, \t Time for 1000 Epochs: 0.8809628849849105\n",
      "Epoch 511999 : Train Accuracy : 0.95614, \tValid  Accuracy : 0.9473,\t Train Loss : 9295.682253437335, \tValid Loss :  2373.2112412813003, \t Time for 1000 Epochs: 0.8804934280051384\n",
      "Epoch 512999 : Train Accuracy : 0.9599, \tValid  Accuracy : 0.9534,\t Train Loss : 8347.695709806605, \tValid Loss :  2127.943199977264, \t Time for 1000 Epochs: 0.8813052640180103\n",
      "Epoch 513999 : Train Accuracy : 0.96136, \tValid  Accuracy : 0.9548,\t Train Loss : 8475.670385156916, \tValid Loss :  2205.187055649014, \t Time for 1000 Epochs: 0.8748537869832944\n",
      "Epoch 514999 : Train Accuracy : 0.94668, \tValid  Accuracy : 0.9431,\t Train Loss : 13554.222843792433, \tValid Loss :  3353.7139899563863, \t Time for 1000 Epochs: 0.8768107540090568\n",
      "Epoch 515999 : Train Accuracy : 0.95032, \tValid  Accuracy : 0.9445,\t Train Loss : 11386.024190341564, \tValid Loss :  2687.446096160949, \t Time for 1000 Epochs: 0.8704047049977817\n",
      "Epoch 516999 : Train Accuracy : 0.95532, \tValid  Accuracy : 0.9494,\t Train Loss : 9459.20530120285, \tValid Loss :  2321.1470999514177, \t Time for 1000 Epochs: 0.8804700860055164\n",
      "Epoch 517999 : Train Accuracy : 0.96078, \tValid  Accuracy : 0.9523,\t Train Loss : 9564.332748455572, \tValid Loss :  2559.0979128680333, \t Time for 1000 Epochs: 0.8769308050104883\n",
      "Epoch 518999 : Train Accuracy : 0.94516, \tValid  Accuracy : 0.9381,\t Train Loss : 12260.853107911717, \tValid Loss :  3031.800323869591, \t Time for 1000 Epochs: 0.9070323969935998\n",
      "Epoch 519999 : Train Accuracy : 0.94314, \tValid  Accuracy : 0.9359,\t Train Loss : 11840.594930369341, \tValid Loss :  2779.130160884384, \t Time for 1000 Epochs: 0.9472897649975494\n",
      "Epoch 520999 : Train Accuracy : 0.95314, \tValid  Accuracy : 0.945,\t Train Loss : 11178.864612072715, \tValid Loss :  2804.087766280902, \t Time for 1000 Epochs: 0.9206296310003381\n",
      "Epoch 521999 : Train Accuracy : 0.9544, \tValid  Accuracy : 0.9499,\t Train Loss : 10109.170279509948, \tValid Loss :  2614.4901795405526, \t Time for 1000 Epochs: 0.9016338970104698\n",
      "Epoch 522999 : Train Accuracy : 0.9576, \tValid  Accuracy : 0.9498,\t Train Loss : 9561.379463650315, \tValid Loss :  2393.8196219484407, \t Time for 1000 Epochs: 0.8771726090053562\n",
      "Epoch 523999 : Train Accuracy : 0.95844, \tValid  Accuracy : 0.9528,\t Train Loss : 11610.255405516984, \tValid Loss :  2863.0320516376596, \t Time for 1000 Epochs: 0.8780865730077494\n",
      "Epoch 524999 : Train Accuracy : 0.95582, \tValid  Accuracy : 0.9477,\t Train Loss : 9899.959947770298, \tValid Loss :  2485.0371282496344, \t Time for 1000 Epochs: 0.8730447629932314\n",
      "Epoch 525999 : Train Accuracy : 0.95234, \tValid  Accuracy : 0.9462,\t Train Loss : 10512.225028717254, \tValid Loss :  2591.925547290516, \t Time for 1000 Epochs: 0.8740405660064425\n",
      "Epoch 526999 : Train Accuracy : 0.94494, \tValid  Accuracy : 0.937,\t Train Loss : 11207.080829133285, \tValid Loss :  2701.1915828365677, \t Time for 1000 Epochs: 0.877045180008281\n",
      "Epoch 527999 : Train Accuracy : 0.94768, \tValid  Accuracy : 0.9407,\t Train Loss : 13561.199294816372, \tValid Loss :  3247.685918406435, \t Time for 1000 Epochs: 0.873398301017005\n",
      "Epoch 528999 : Train Accuracy : 0.92304, \tValid  Accuracy : 0.9189,\t Train Loss : 14559.973271333409, \tValid Loss :  3380.921549996121, \t Time for 1000 Epochs: 0.8757334619876929\n",
      "Epoch 529999 : Train Accuracy : 0.94622, \tValid  Accuracy : 0.939,\t Train Loss : 11107.859840655938, \tValid Loss :  2767.863969404848, \t Time for 1000 Epochs: 0.8858091850124765\n",
      "Epoch 530999 : Train Accuracy : 0.95062, \tValid  Accuracy : 0.947,\t Train Loss : 11873.979369126111, \tValid Loss :  2882.3510913627533, \t Time for 1000 Epochs: 0.8778122240037192\n",
      "Epoch 531999 : Train Accuracy : 0.9589, \tValid  Accuracy : 0.9528,\t Train Loss : 9541.584541455804, \tValid Loss :  2394.637456473524, \t Time for 1000 Epochs: 0.854882892977912\n",
      "Epoch 532999 : Train Accuracy : 0.95666, \tValid  Accuracy : 0.9485,\t Train Loss : 9697.085640573157, \tValid Loss :  2504.920422042053, \t Time for 1000 Epochs: 0.9215384739800356\n",
      "Epoch 533999 : Train Accuracy : 0.95322, \tValid  Accuracy : 0.949,\t Train Loss : 9883.390750970808, \tValid Loss :  2596.0790463578305, \t Time for 1000 Epochs: 0.8895524600229692\n",
      "Epoch 534999 : Train Accuracy : 0.95636, \tValid  Accuracy : 0.9508,\t Train Loss : 9061.356450986392, \tValid Loss :  2336.1414880306343, \t Time for 1000 Epochs: 0.8728321420203429\n",
      "Epoch 535999 : Train Accuracy : 0.94528, \tValid  Accuracy : 0.9393,\t Train Loss : 10510.897216544887, \tValid Loss :  2677.7643942844634, \t Time for 1000 Epochs: 0.8811053309764247\n",
      "Epoch 536999 : Train Accuracy : 0.94552, \tValid  Accuracy : 0.9451,\t Train Loss : 12318.880484186308, \tValid Loss :  2856.863981891413, \t Time for 1000 Epochs: 0.8801392939931247\n",
      "Epoch 537999 : Train Accuracy : 0.94744, \tValid  Accuracy : 0.9414,\t Train Loss : 10372.991372726465, \tValid Loss :  2625.9462557222223, \t Time for 1000 Epochs: 0.7873563220200595\n",
      "Epoch 538999 : Train Accuracy : 0.9508, \tValid  Accuracy : 0.9434,\t Train Loss : 13682.11903468036, \tValid Loss :  3268.068122636316, \t Time for 1000 Epochs: 0.8693511580058839\n",
      "Epoch 539999 : Train Accuracy : 0.9487, \tValid  Accuracy : 0.9428,\t Train Loss : 10548.501351363358, \tValid Loss :  2595.7219301944424, \t Time for 1000 Epochs: 0.8772177350183483\n",
      "Epoch 540999 : Train Accuracy : 0.956, \tValid  Accuracy : 0.9498,\t Train Loss : 10054.718016630217, \tValid Loss :  2557.8418510979195, \t Time for 1000 Epochs: 0.7812596670119092\n",
      "Epoch 541999 : Train Accuracy : 0.9563, \tValid  Accuracy : 0.9526,\t Train Loss : 9619.47085794294, \tValid Loss :  2336.3199495259137, \t Time for 1000 Epochs: 0.882094592001522\n",
      "Epoch 542999 : Train Accuracy : 0.95308, \tValid  Accuracy : 0.9478,\t Train Loss : 11280.962573974262, \tValid Loss :  2801.0789664094073, \t Time for 1000 Epochs: 0.7949198750138748\n",
      "Epoch 543999 : Train Accuracy : 0.94892, \tValid  Accuracy : 0.9439,\t Train Loss : 11258.029850772127, \tValid Loss :  2707.2285205884496, \t Time for 1000 Epochs: 0.8442083820118569\n",
      "Epoch 544999 : Train Accuracy : 0.9573, \tValid  Accuracy : 0.9512,\t Train Loss : 9557.823669385949, \tValid Loss :  2447.5426415035968, \t Time for 1000 Epochs: 0.9133151069981977\n",
      "Epoch 545999 : Train Accuracy : 0.94864, \tValid  Accuracy : 0.9428,\t Train Loss : 13058.733971880532, \tValid Loss :  3193.0011373914026, \t Time for 1000 Epochs: 0.897188235016074\n",
      "Epoch 546999 : Train Accuracy : 0.9548, \tValid  Accuracy : 0.9503,\t Train Loss : 10244.93539581141, \tValid Loss :  2398.427030244091, \t Time for 1000 Epochs: 0.818372872978216\n",
      "Epoch 547999 : Train Accuracy : 0.91992, \tValid  Accuracy : 0.9153,\t Train Loss : 16475.00631670496, \tValid Loss :  3760.222702943673, \t Time for 1000 Epochs: 0.8740424810093828\n",
      "Epoch 548999 : Train Accuracy : 0.945, \tValid  Accuracy : 0.9364,\t Train Loss : 10991.274660726676, \tValid Loss :  2939.835780876891, \t Time for 1000 Epochs: 0.8809967740089633\n",
      "Epoch 549999 : Train Accuracy : 0.95226, \tValid  Accuracy : 0.9442,\t Train Loss : 9722.345772225994, \tValid Loss :  2510.213933878335, \t Time for 1000 Epochs: 0.7833970100036822\n",
      "Epoch 550999 : Train Accuracy : 0.95652, \tValid  Accuracy : 0.9483,\t Train Loss : 9105.058125385205, \tValid Loss :  2376.5877815746794, \t Time for 1000 Epochs: 0.8767558980034664\n",
      "Epoch 551999 : Train Accuracy : 0.95016, \tValid  Accuracy : 0.9412,\t Train Loss : 9583.968516247736, \tValid Loss :  2502.4703636967606, \t Time for 1000 Epochs: 0.8778954070003238\n",
      "Epoch 552999 : Train Accuracy : 0.94834, \tValid  Accuracy : 0.9424,\t Train Loss : 10893.417588168842, \tValid Loss :  2710.627361142297, \t Time for 1000 Epochs: 0.9014205989951733\n",
      "Epoch 553999 : Train Accuracy : 0.96108, \tValid  Accuracy : 0.9544,\t Train Loss : 7680.273927385905, \tValid Loss :  2005.9898854694582, \t Time for 1000 Epochs: 0.8894902169995476\n",
      "Epoch 554999 : Train Accuracy : 0.96006, \tValid  Accuracy : 0.9524,\t Train Loss : 8212.90637356356, \tValid Loss :  2291.891526495491, \t Time for 1000 Epochs: 0.8747053980187047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555999 : Train Accuracy : 0.94348, \tValid  Accuracy : 0.9422,\t Train Loss : 11177.00773437777, \tValid Loss :  2806.5808618355277, \t Time for 1000 Epochs: 0.9114923449815251\n",
      "Epoch 556999 : Train Accuracy : 0.96174, \tValid  Accuracy : 0.9541,\t Train Loss : 8235.255889983107, \tValid Loss :  2266.5588668782575, \t Time for 1000 Epochs: 0.9279505849990528\n",
      "Epoch 557999 : Train Accuracy : 0.95366, \tValid  Accuracy : 0.9482,\t Train Loss : 9754.8875696587, \tValid Loss :  2441.6907731724873, \t Time for 1000 Epochs: 0.8165212169988081\n",
      "Epoch 558999 : Train Accuracy : 0.95768, \tValid  Accuracy : 0.9511,\t Train Loss : 8256.817560820933, \tValid Loss :  2199.2538350096347, \t Time for 1000 Epochs: 0.9007713710016105\n",
      "Epoch 559999 : Train Accuracy : 0.95838, \tValid  Accuracy : 0.9518,\t Train Loss : 8184.228204612513, \tValid Loss :  2167.1698463174325, \t Time for 1000 Epochs: 0.8990522970270831\n",
      "Epoch 560999 : Train Accuracy : 0.94598, \tValid  Accuracy : 0.9428,\t Train Loss : 12665.377548638686, \tValid Loss :  2999.7911583283235, \t Time for 1000 Epochs: 0.7923286660225131\n",
      "Epoch 561999 : Train Accuracy : 0.95278, \tValid  Accuracy : 0.9478,\t Train Loss : 10155.26258464789, \tValid Loss :  2622.9464141039434, \t Time for 1000 Epochs: 0.7883741020050365\n",
      "Epoch 562999 : Train Accuracy : 0.94296, \tValid  Accuracy : 0.938,\t Train Loss : 10220.707805671917, \tValid Loss :  2581.8006840729686, \t Time for 1000 Epochs: 0.8769798360008281\n",
      "Epoch 563999 : Train Accuracy : 0.96006, \tValid  Accuracy : 0.9531,\t Train Loss : 8233.226896523001, \tValid Loss :  2257.89968537541, \t Time for 1000 Epochs: 0.8786769750004169\n",
      "Epoch 564999 : Train Accuracy : 0.962, \tValid  Accuracy : 0.9532,\t Train Loss : 8371.364077097322, \tValid Loss :  2323.7307064321635, \t Time for 1000 Epochs: 0.7883960609906353\n",
      "Epoch 565999 : Train Accuracy : 0.96378, \tValid  Accuracy : 0.9578,\t Train Loss : 7874.32248357928, \tValid Loss :  2221.302388897026, \t Time for 1000 Epochs: 0.8777543129981495\n",
      "Epoch 566999 : Train Accuracy : 0.95224, \tValid  Accuracy : 0.9457,\t Train Loss : 9488.548237424324, \tValid Loss :  2427.3215908162924, \t Time for 1000 Epochs: 0.8736848810222\n",
      "Epoch 567999 : Train Accuracy : 0.95236, \tValid  Accuracy : 0.9428,\t Train Loss : 9373.21134511142, \tValid Loss :  2399.0435543092813, \t Time for 1000 Epochs: 0.9063082759967074\n",
      "Epoch 568999 : Train Accuracy : 0.95312, \tValid  Accuracy : 0.9453,\t Train Loss : 9664.222390005434, \tValid Loss :  2599.348468115989, \t Time for 1000 Epochs: 0.9393773729971144\n",
      "Epoch 569999 : Train Accuracy : 0.94684, \tValid  Accuracy : 0.9371,\t Train Loss : 10698.351098807047, \tValid Loss :  2818.9635295299636, \t Time for 1000 Epochs: 0.8167676870070864\n",
      "Epoch 570999 : Train Accuracy : 0.95948, \tValid  Accuracy : 0.9523,\t Train Loss : 9369.546372627277, \tValid Loss :  2741.1614766678217, \t Time for 1000 Epochs: 0.8971987160039134\n",
      "Epoch 571999 : Train Accuracy : 0.95674, \tValid  Accuracy : 0.9518,\t Train Loss : 10773.60369950431, \tValid Loss :  2766.5756174915414, \t Time for 1000 Epochs: 0.7943977909744717\n",
      "Epoch 572999 : Train Accuracy : 0.9503, \tValid  Accuracy : 0.9429,\t Train Loss : 9853.340934231923, \tValid Loss :  2667.7588362755373, \t Time for 1000 Epochs: 0.7899786439957097\n",
      "Epoch 573999 : Train Accuracy : 0.94176, \tValid  Accuracy : 0.9362,\t Train Loss : 11184.87225777059, \tValid Loss :  2836.3184432907915, \t Time for 1000 Epochs: 0.7870905119925737\n",
      "Epoch 574999 : Train Accuracy : 0.95326, \tValid  Accuracy : 0.9464,\t Train Loss : 9448.719858888824, \tValid Loss :  2547.4818398942357, \t Time for 1000 Epochs: 0.8786629420064855\n",
      "Epoch 575999 : Train Accuracy : 0.9591, \tValid  Accuracy : 0.9534,\t Train Loss : 9542.786338221089, \tValid Loss :  2477.6398990304856, \t Time for 1000 Epochs: 0.8826644039945677\n",
      "Epoch 576999 : Train Accuracy : 0.95882, \tValid  Accuracy : 0.9531,\t Train Loss : 8749.869194924047, \tValid Loss :  2274.7046679242503, \t Time for 1000 Epochs: 0.7948590820014942\n",
      "Epoch 577999 : Train Accuracy : 0.91674, \tValid  Accuracy : 0.9106,\t Train Loss : 15510.890800404506, \tValid Loss :  3735.2329145028957, \t Time for 1000 Epochs: 0.7897007209830917\n",
      "Epoch 578999 : Train Accuracy : 0.93392, \tValid  Accuracy : 0.9281,\t Train Loss : 12777.643797853152, \tValid Loss :  3135.507836500179, \t Time for 1000 Epochs: 0.881497316993773\n",
      "Epoch 579999 : Train Accuracy : 0.95442, \tValid  Accuracy : 0.9488,\t Train Loss : 8954.223417534417, \tValid Loss :  2340.056151553465, \t Time for 1000 Epochs: 0.8874304310011212\n",
      "Epoch 580999 : Train Accuracy : 0.95902, \tValid  Accuracy : 0.9494,\t Train Loss : 8643.373112215608, \tValid Loss :  2435.014280586586, \t Time for 1000 Epochs: 0.8828701479942538\n",
      "Epoch 581999 : Train Accuracy : 0.95776, \tValid  Accuracy : 0.9501,\t Train Loss : 9371.910988935513, \tValid Loss :  2456.694756543622, \t Time for 1000 Epochs: 0.9537214739830233\n",
      "Epoch 582999 : Train Accuracy : 0.95678, \tValid  Accuracy : 0.947,\t Train Loss : 10030.390000845238, \tValid Loss :  2831.01859497747, \t Time for 1000 Epochs: 0.9228828100021929\n",
      "Epoch 583999 : Train Accuracy : 0.9179, \tValid  Accuracy : 0.9175,\t Train Loss : 15729.52534727084, \tValid Loss :  3540.1816993614684, \t Time for 1000 Epochs: 0.9190670390089508\n",
      "Epoch 584999 : Train Accuracy : 0.9402, \tValid  Accuracy : 0.9346,\t Train Loss : 11740.264592907337, \tValid Loss :  2927.1125674389205, \t Time for 1000 Epochs: 0.7747560020070523\n",
      "Epoch 585999 : Train Accuracy : 0.9447, \tValid  Accuracy : 0.9366,\t Train Loss : 14254.716205814164, \tValid Loss :  3359.41712261625, \t Time for 1000 Epochs: 0.7927702169981785\n",
      "Epoch 586999 : Train Accuracy : 0.9553, \tValid  Accuracy : 0.9499,\t Train Loss : 10277.785152827215, \tValid Loss :  2746.3657714876526, \t Time for 1000 Epochs: 0.8861636290093884\n",
      "Epoch 587999 : Train Accuracy : 0.95522, \tValid  Accuracy : 0.9485,\t Train Loss : 8546.967356352327, \tValid Loss :  2305.7712564411777, \t Time for 1000 Epochs: 0.8987207130121533\n",
      "Epoch 588999 : Train Accuracy : 0.96026, \tValid  Accuracy : 0.9536,\t Train Loss : 7951.647434417401, \tValid Loss :  2147.190349175513, \t Time for 1000 Epochs: 0.8748678400006611\n",
      "Epoch 589999 : Train Accuracy : 0.95676, \tValid  Accuracy : 0.9519,\t Train Loss : 9258.4169694794, \tValid Loss :  2540.1653513158235, \t Time for 1000 Epochs: 0.8811327310104389\n",
      "Epoch 590999 : Train Accuracy : 0.96216, \tValid  Accuracy : 0.9539,\t Train Loss : 8714.754666251893, \tValid Loss :  2579.3813436243577, \t Time for 1000 Epochs: 0.7883404969761614\n",
      "Epoch 591999 : Train Accuracy : 0.95066, \tValid  Accuracy : 0.9414,\t Train Loss : 10618.043849509017, \tValid Loss :  3024.08000361461, \t Time for 1000 Epochs: 0.7872826189850457\n",
      "Epoch 592999 : Train Accuracy : 0.88158, \tValid  Accuracy : 0.8697,\t Train Loss : 30834.231485442204, \tValid Loss :  7123.323025381397, \t Time for 1000 Epochs: 0.9083648530067876\n",
      "Epoch 593999 : Train Accuracy : 0.95868, \tValid  Accuracy : 0.9489,\t Train Loss : 8389.747266810866, \tValid Loss :  2474.68430957708, \t Time for 1000 Epochs: 0.9419078599894419\n",
      "Epoch 594999 : Train Accuracy : 0.95412, \tValid  Accuracy : 0.9467,\t Train Loss : 10814.217153466474, \tValid Loss :  2852.1283340531136, \t Time for 1000 Epochs: 0.9074093659874052\n",
      "Epoch 595999 : Train Accuracy : 0.96214, \tValid  Accuracy : 0.9534,\t Train Loss : 7885.0200441307525, \tValid Loss :  2348.5139226640717, \t Time for 1000 Epochs: 0.8982233370188624\n",
      "Epoch 596999 : Train Accuracy : 0.96312, \tValid  Accuracy : 0.9514,\t Train Loss : 7971.539774074341, \tValid Loss :  2461.736953478948, \t Time for 1000 Epochs: 0.8819721610052511\n",
      "Epoch 597999 : Train Accuracy : 0.96302, \tValid  Accuracy : 0.9534,\t Train Loss : 7579.5794161305985, \tValid Loss :  2285.9494160583163, \t Time for 1000 Epochs: 0.8763969889841974\n",
      "Epoch 598999 : Train Accuracy : 0.93354, \tValid  Accuracy : 0.9271,\t Train Loss : 13441.383177799362, \tValid Loss :  3420.906848209133, \t Time for 1000 Epochs: 0.8827840839803685\n",
      "Epoch 599999 : Train Accuracy : 0.96302, \tValid  Accuracy : 0.9546,\t Train Loss : 8398.797360814931, \tValid Loss :  2457.0033631170377, \t Time for 1000 Epochs: 0.7910544490150642\n",
      "Epoch 600999 : Train Accuracy : 0.94754, \tValid  Accuracy : 0.9443,\t Train Loss : 9557.160473018868, \tValid Loss :  2499.2842144912775, \t Time for 1000 Epochs: 0.8760806329955813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601999 : Train Accuracy : 0.95696, \tValid  Accuracy : 0.9499,\t Train Loss : 9624.933247695526, \tValid Loss :  2517.121633107778, \t Time for 1000 Epochs: 0.8736707640055101\n",
      "Epoch 602999 : Train Accuracy : 0.95814, \tValid  Accuracy : 0.9524,\t Train Loss : 8738.589267378522, \tValid Loss :  2397.1495495534878, \t Time for 1000 Epochs: 0.8797145950084087\n",
      "Epoch 603999 : Train Accuracy : 0.96338, \tValid  Accuracy : 0.9563,\t Train Loss : 7823.7159258162055, \tValid Loss :  2316.7040242609514, \t Time for 1000 Epochs: 0.8909784969873726\n",
      "Epoch 604999 : Train Accuracy : 0.95336, \tValid  Accuracy : 0.9457,\t Train Loss : 9357.764782061691, \tValid Loss :  2635.9664032065675, \t Time for 1000 Epochs: 0.8031419370090589\n",
      "Epoch 605999 : Train Accuracy : 0.96422, \tValid  Accuracy : 0.9576,\t Train Loss : 7986.923319864788, \tValid Loss :  2363.4061078770515, \t Time for 1000 Epochs: 0.8549805879883934\n",
      "Epoch 606999 : Train Accuracy : 0.95844, \tValid  Accuracy : 0.9522,\t Train Loss : 8289.02575832366, \tValid Loss :  2182.5847913358, \t Time for 1000 Epochs: 0.8215992779878434\n",
      "Epoch 607999 : Train Accuracy : 0.94806, \tValid  Accuracy : 0.9392,\t Train Loss : 11209.00614425883, \tValid Loss :  2773.688247682465, \t Time for 1000 Epochs: 0.8910550089785829\n",
      "Epoch 608999 : Train Accuracy : 0.94806, \tValid  Accuracy : 0.943,\t Train Loss : 12055.033451000509, \tValid Loss :  2936.634582078463, \t Time for 1000 Epochs: 0.7860049479932059\n",
      "Epoch 609999 : Train Accuracy : 0.94814, \tValid  Accuracy : 0.9431,\t Train Loss : 10456.271524409087, \tValid Loss :  2686.118106312143, \t Time for 1000 Epochs: 0.7862405250198208\n",
      "Epoch 610999 : Train Accuracy : 0.94294, \tValid  Accuracy : 0.9375,\t Train Loss : 13844.933520731904, \tValid Loss :  3336.7991644844583, \t Time for 1000 Epochs: 0.7895545139908791\n",
      "Epoch 611999 : Train Accuracy : 0.94896, \tValid  Accuracy : 0.9424,\t Train Loss : 11269.823460231608, \tValid Loss :  3034.779247150257, \t Time for 1000 Epochs: 0.8842262660036795\n",
      "Epoch 612999 : Train Accuracy : 0.957, \tValid  Accuracy : 0.9498,\t Train Loss : 9258.112029615895, \tValid Loss :  2570.7554065348027, \t Time for 1000 Epochs: 0.7830924759909976\n",
      "Epoch 613999 : Train Accuracy : 0.95914, \tValid  Accuracy : 0.9535,\t Train Loss : 8576.76644967185, \tValid Loss :  2461.278154625421, \t Time for 1000 Epochs: 0.7926990760024637\n",
      "Epoch 614999 : Train Accuracy : 0.95982, \tValid  Accuracy : 0.9507,\t Train Loss : 8738.071016363965, \tValid Loss :  2486.16847802362, \t Time for 1000 Epochs: 0.874173869000515\n",
      "Epoch 615999 : Train Accuracy : 0.95982, \tValid  Accuracy : 0.9508,\t Train Loss : 9593.008158817105, \tValid Loss :  2673.3290646200703, \t Time for 1000 Epochs: 0.8901321750017814\n",
      "Epoch 616999 : Train Accuracy : 0.94778, \tValid  Accuracy : 0.9395,\t Train Loss : 10816.966876146611, \tValid Loss :  2779.0879680647236, \t Time for 1000 Epochs: 0.7848366560065188\n",
      "Epoch 617999 : Train Accuracy : 0.96076, \tValid  Accuracy : 0.9537,\t Train Loss : 9797.749020963298, \tValid Loss :  2711.9610316372805, \t Time for 1000 Epochs: 0.8061889680102468\n",
      "Epoch 618999 : Train Accuracy : 0.9516, \tValid  Accuracy : 0.944,\t Train Loss : 11412.10887333613, \tValid Loss :  2780.636006498029, \t Time for 1000 Epochs: 0.8484404660121072\n",
      "Epoch 619999 : Train Accuracy : 0.9514, \tValid  Accuracy : 0.9461,\t Train Loss : 11509.895598369754, \tValid Loss :  2825.5840977194553, \t Time for 1000 Epochs: 0.9024846639949828\n",
      "Epoch 620999 : Train Accuracy : 0.94864, \tValid  Accuracy : 0.9403,\t Train Loss : 11027.462928050885, \tValid Loss :  2810.911805000398, \t Time for 1000 Epochs: 0.8850301959901117\n",
      "Epoch 621999 : Train Accuracy : 0.93658, \tValid  Accuracy : 0.9291,\t Train Loss : 12695.338671566646, \tValid Loss :  3107.453724071881, \t Time for 1000 Epochs: 0.8719764099805616\n",
      "Epoch 622999 : Train Accuracy : 0.9405, \tValid  Accuracy : 0.9337,\t Train Loss : 13720.457836652004, \tValid Loss :  3428.7773037160614, \t Time for 1000 Epochs: 0.9016914000094403\n",
      "Epoch 623999 : Train Accuracy : 0.95028, \tValid  Accuracy : 0.9443,\t Train Loss : 11482.269277432584, \tValid Loss :  2928.6130413498686, \t Time for 1000 Epochs: 0.7816992180014495\n",
      "Epoch 624999 : Train Accuracy : 0.93414, \tValid  Accuracy : 0.9284,\t Train Loss : 13021.706490074544, \tValid Loss :  3168.186233673295, \t Time for 1000 Epochs: 0.7797461099980865\n",
      "Epoch 625999 : Train Accuracy : 0.95348, \tValid  Accuracy : 0.9458,\t Train Loss : 9609.77832122997, \tValid Loss :  2562.4510529671043, \t Time for 1000 Epochs: 0.8684558859968092\n",
      "Epoch 626999 : Train Accuracy : 0.93298, \tValid  Accuracy : 0.9269,\t Train Loss : 14798.846009026696, \tValid Loss :  3600.2148262259275, \t Time for 1000 Epochs: 0.8823691019788384\n",
      "Epoch 627999 : Train Accuracy : 0.9529, \tValid  Accuracy : 0.9427,\t Train Loss : 9718.69552481502, \tValid Loss :  2607.2667299851, \t Time for 1000 Epochs: 0.8776124159921892\n",
      "Epoch 628999 : Train Accuracy : 0.8988, \tValid  Accuracy : 0.897,\t Train Loss : 24674.21088135003, \tValid Loss :  5223.380509224595, \t Time for 1000 Epochs: 0.8781229339947458\n",
      "Epoch 629999 : Train Accuracy : 0.93794, \tValid  Accuracy : 0.9332,\t Train Loss : 13814.633505181533, \tValid Loss :  3368.4740727922, \t Time for 1000 Epochs: 0.87753862599493\n",
      "Epoch 630999 : Train Accuracy : 0.94952, \tValid  Accuracy : 0.9411,\t Train Loss : 9811.935471749604, \tValid Loss :  2661.6899897409785, \t Time for 1000 Epochs: 0.9253213219926693\n",
      "Epoch 631999 : Train Accuracy : 0.93648, \tValid  Accuracy : 0.9316,\t Train Loss : 11884.988277038428, \tValid Loss :  2935.606923151191, \t Time for 1000 Epochs: 0.8277570060163271\n",
      "Epoch 632999 : Train Accuracy : 0.92094, \tValid  Accuracy : 0.9172,\t Train Loss : 14369.136342548658, \tValid Loss :  3454.3083276815264, \t Time for 1000 Epochs: 0.802587782003684\n",
      "Epoch 633999 : Train Accuracy : 0.93458, \tValid  Accuracy : 0.9315,\t Train Loss : 12466.281614195552, \tValid Loss :  3171.4981327358705, \t Time for 1000 Epochs: 0.887799610994989\n",
      "Epoch 634999 : Train Accuracy : 0.93012, \tValid  Accuracy : 0.9245,\t Train Loss : 12268.399073306908, \tValid Loss :  3075.579782184723, \t Time for 1000 Epochs: 0.7904599220200907\n",
      "Epoch 635999 : Train Accuracy : 0.95348, \tValid  Accuracy : 0.9439,\t Train Loss : 10060.166770405203, \tValid Loss :  2687.0492276616424, \t Time for 1000 Epochs: 0.8707462179881986\n",
      "Epoch 636999 : Train Accuracy : 0.95404, \tValid  Accuracy : 0.9461,\t Train Loss : 10612.730882559094, \tValid Loss :  2869.291880553841, \t Time for 1000 Epochs: 0.7897000750235748\n",
      "Epoch 637999 : Train Accuracy : 0.91336, \tValid  Accuracy : 0.9078,\t Train Loss : 17561.906786893334, \tValid Loss :  3976.1973233008393, \t Time for 1000 Epochs: 0.7852003110165242\n",
      "Epoch 638999 : Train Accuracy : 0.93848, \tValid  Accuracy : 0.934,\t Train Loss : 13211.151564149372, \tValid Loss :  3148.490790760207, \t Time for 1000 Epochs: 0.8789489759947173\n",
      "Epoch 639999 : Train Accuracy : 0.93726, \tValid  Accuracy : 0.9331,\t Train Loss : 13225.568506341602, \tValid Loss :  3196.2355189566574, \t Time for 1000 Epochs: 0.8734003979770932\n",
      "Epoch 640999 : Train Accuracy : 0.91464, \tValid  Accuracy : 0.9144,\t Train Loss : 16948.50512239338, \tValid Loss :  3821.4938541588026, \t Time for 1000 Epochs: 0.8748665140010417\n",
      "Epoch 641999 : Train Accuracy : 0.94498, \tValid  Accuracy : 0.9424,\t Train Loss : 12320.09914092076, \tValid Loss :  3105.0822409437883, \t Time for 1000 Epochs: 0.8776728960219771\n",
      "Epoch 642999 : Train Accuracy : 0.91694, \tValid  Accuracy : 0.9087,\t Train Loss : 16974.31417888954, \tValid Loss :  4113.66241821634, \t Time for 1000 Epochs: 0.8358299809915479\n",
      "Epoch 643999 : Train Accuracy : 0.93148, \tValid  Accuracy : 0.9226,\t Train Loss : 15491.016413883515, \tValid Loss :  3761.9836416392936, \t Time for 1000 Epochs: 0.9331734380102716\n",
      "Epoch 644999 : Train Accuracy : 0.93762, \tValid  Accuracy : 0.9326,\t Train Loss : 11104.127012697936, \tValid Loss :  2805.8613562889154, \t Time for 1000 Epochs: 0.9057051409909036\n",
      "Epoch 645999 : Train Accuracy : 0.94776, \tValid  Accuracy : 0.9408,\t Train Loss : 11117.355403760595, \tValid Loss :  2800.8984526526046, \t Time for 1000 Epochs: 0.8135754219838418\n",
      "Epoch 646999 : Train Accuracy : 0.92742, \tValid  Accuracy : 0.9217,\t Train Loss : 13049.29748554298, \tValid Loss :  3072.7699928671204, \t Time for 1000 Epochs: 0.7857397079933435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 647999 : Train Accuracy : 0.95116, \tValid  Accuracy : 0.9437,\t Train Loss : 11728.078895596653, \tValid Loss :  2950.9842034566686, \t Time for 1000 Epochs: 0.8783041489950847\n",
      "Epoch 648999 : Train Accuracy : 0.9528, \tValid  Accuracy : 0.9442,\t Train Loss : 12764.39870615974, \tValid Loss :  3307.9945026069113, \t Time for 1000 Epochs: 0.8799794469960034\n",
      "Epoch 649999 : Train Accuracy : 0.95076, \tValid  Accuracy : 0.944,\t Train Loss : 10853.588258971296, \tValid Loss :  2956.9504713915835, \t Time for 1000 Epochs: 0.7958089449966792\n",
      "Epoch 650999 : Train Accuracy : 0.93966, \tValid  Accuracy : 0.9308,\t Train Loss : 11004.845829171303, \tValid Loss :  2940.9367601558743, \t Time for 1000 Epochs: 0.7929653180181049\n",
      "Epoch 651999 : Train Accuracy : 0.95286, \tValid  Accuracy : 0.9455,\t Train Loss : 9698.141598405597, \tValid Loss :  2742.2256407405534, \t Time for 1000 Epochs: 0.8854051099915523\n",
      "Epoch 652999 : Train Accuracy : 0.94946, \tValid  Accuracy : 0.9424,\t Train Loss : 11129.087894164082, \tValid Loss :  2856.7478531132065, \t Time for 1000 Epochs: 0.7813198670046404\n",
      "Epoch 653999 : Train Accuracy : 0.95304, \tValid  Accuracy : 0.9429,\t Train Loss : 10246.29652281121, \tValid Loss :  2702.4711619136465, \t Time for 1000 Epochs: 0.8704231309820898\n",
      "Epoch 654999 : Train Accuracy : 0.95264, \tValid  Accuracy : 0.9418,\t Train Loss : 10011.798065750208, \tValid Loss :  2747.5162344680853, \t Time for 1000 Epochs: 0.9065347670111805\n",
      "Epoch 655999 : Train Accuracy : 0.9389, \tValid  Accuracy : 0.9348,\t Train Loss : 12702.702885625087, \tValid Loss :  2977.1867769537484, \t Time for 1000 Epochs: 0.8474895679973997\n",
      "Epoch 656999 : Train Accuracy : 0.95178, \tValid  Accuracy : 0.9454,\t Train Loss : 9383.65390695476, \tValid Loss :  2501.9026066837414, \t Time for 1000 Epochs: 0.925566271005664\n",
      "Epoch 657999 : Train Accuracy : 0.94708, \tValid  Accuracy : 0.9395,\t Train Loss : 11867.75243562935, \tValid Loss :  3050.7174529880213, \t Time for 1000 Epochs: 0.9495866389770526\n",
      "Epoch 658999 : Train Accuracy : 0.95734, \tValid  Accuracy : 0.9502,\t Train Loss : 8964.701465585555, \tValid Loss :  2484.8025843661167, \t Time for 1000 Epochs: 0.7795762570167426\n",
      "Epoch 659999 : Train Accuracy : 0.91388, \tValid  Accuracy : 0.9094,\t Train Loss : 20698.784894498553, \tValid Loss :  4808.54314794222, \t Time for 1000 Epochs: 0.7837183870142326\n",
      "Epoch 660999 : Train Accuracy : 0.9453, \tValid  Accuracy : 0.9424,\t Train Loss : 12387.205984887216, \tValid Loss :  2886.476329631693, \t Time for 1000 Epochs: 0.8707390560011845\n",
      "Epoch 661999 : Train Accuracy : 0.88714, \tValid  Accuracy : 0.8856,\t Train Loss : 22437.496128510895, \tValid Loss :  4946.409154117305, \t Time for 1000 Epochs: 0.8709543209988624\n",
      "Epoch 662999 : Train Accuracy : 0.90732, \tValid  Accuracy : 0.8992,\t Train Loss : 14126.89787425641, \tValid Loss :  3377.736244959311, \t Time for 1000 Epochs: 0.8719503449974582\n",
      "Epoch 663999 : Train Accuracy : 0.95184, \tValid  Accuracy : 0.9478,\t Train Loss : 10341.379136262944, \tValid Loss :  2649.351076333875, \t Time for 1000 Epochs: 0.8800043090013787\n",
      "Epoch 664999 : Train Accuracy : 0.94912, \tValid  Accuracy : 0.9406,\t Train Loss : 10115.506191705199, \tValid Loss :  2732.8797543535525, \t Time for 1000 Epochs: 0.7802027300058398\n",
      "Epoch 665999 : Train Accuracy : 0.95364, \tValid  Accuracy : 0.9439,\t Train Loss : 9304.517971852398, \tValid Loss :  2663.151326902635, \t Time for 1000 Epochs: 0.8788453679881059\n",
      "Epoch 666999 : Train Accuracy : 0.93634, \tValid  Accuracy : 0.9294,\t Train Loss : 12430.91320232295, \tValid Loss :  3231.539079556603, \t Time for 1000 Epochs: 0.7837631079892162\n",
      "Epoch 667999 : Train Accuracy : 0.9432, \tValid  Accuracy : 0.9367,\t Train Loss : 11987.756953396425, \tValid Loss :  2868.6447701352445, \t Time for 1000 Epochs: 0.8297504970105365\n",
      "Epoch 668999 : Train Accuracy : 0.94762, \tValid  Accuracy : 0.9412,\t Train Loss : 10481.129698186884, \tValid Loss :  2678.038944249494, \t Time for 1000 Epochs: 0.9359742389933672\n",
      "Epoch 669999 : Train Accuracy : 0.94872, \tValid  Accuracy : 0.9417,\t Train Loss : 11218.16240163946, \tValid Loss :  2980.0118501546604, \t Time for 1000 Epochs: 0.9015249819785822\n",
      "Epoch 670999 : Train Accuracy : 0.9436, \tValid  Accuracy : 0.9376,\t Train Loss : 10856.972866763808, \tValid Loss :  2716.865561252683, \t Time for 1000 Epochs: 0.8065436000179034\n",
      "Epoch 671999 : Train Accuracy : 0.94878, \tValid  Accuracy : 0.9412,\t Train Loss : 10632.18004100248, \tValid Loss :  2653.4881114249497, \t Time for 1000 Epochs: 0.7816085510130506\n",
      "Epoch 672999 : Train Accuracy : 0.90806, \tValid  Accuracy : 0.904,\t Train Loss : 16089.491351043602, \tValid Loss :  3535.6344062161406, \t Time for 1000 Epochs: 0.8691243210050743\n",
      "Epoch 673999 : Train Accuracy : 0.94886, \tValid  Accuracy : 0.9412,\t Train Loss : 10681.010943537985, \tValid Loss :  2645.3862555120572, \t Time for 1000 Epochs: 0.8732325790042523\n",
      "Epoch 674999 : Train Accuracy : 0.93714, \tValid  Accuracy : 0.9312,\t Train Loss : 15031.706064272386, \tValid Loss :  3551.5875224698398, \t Time for 1000 Epochs: 0.7905033110000659\n",
      "Epoch 675999 : Train Accuracy : 0.94832, \tValid  Accuracy : 0.9433,\t Train Loss : 12785.27306976642, \tValid Loss :  3222.284211739304, \t Time for 1000 Epochs: 0.7876048749894835\n",
      "Epoch 676999 : Train Accuracy : 0.94588, \tValid  Accuracy : 0.9416,\t Train Loss : 12033.2485346474, \tValid Loss :  3058.6669005307676, \t Time for 1000 Epochs: 0.7828271010075696\n",
      "Epoch 677999 : Train Accuracy : 0.94292, \tValid  Accuracy : 0.9392,\t Train Loss : 13118.40200161451, \tValid Loss :  3131.8657629493114, \t Time for 1000 Epochs: 0.7832189199980348\n",
      "Epoch 678999 : Train Accuracy : 0.92342, \tValid  Accuracy : 0.9208,\t Train Loss : 17317.261858422633, \tValid Loss :  3825.88400499255, \t Time for 1000 Epochs: 0.8743524110177532\n",
      "Epoch 679999 : Train Accuracy : 0.92724, \tValid  Accuracy : 0.9258,\t Train Loss : 13731.379660951472, \tValid Loss :  3067.99840834903, \t Time for 1000 Epochs: 0.8782170439953916\n",
      "Epoch 680999 : Train Accuracy : 0.93378, \tValid  Accuracy : 0.9342,\t Train Loss : 15001.12264563851, \tValid Loss :  3421.437845421276, \t Time for 1000 Epochs: 0.9295570229878649\n",
      "Epoch 681999 : Train Accuracy : 0.93616, \tValid  Accuracy : 0.9351,\t Train Loss : 13816.879864314502, \tValid Loss :  3312.2788697038845, \t Time for 1000 Epochs: 0.8307843859947752\n",
      "Epoch 682999 : Train Accuracy : 0.94832, \tValid  Accuracy : 0.9446,\t Train Loss : 11443.374850172591, \tValid Loss :  2878.569341408141, \t Time for 1000 Epochs: 0.8159101130149793\n",
      "Epoch 683999 : Train Accuracy : 0.94906, \tValid  Accuracy : 0.9423,\t Train Loss : 10912.833240007945, \tValid Loss :  2837.1994504785343, \t Time for 1000 Epochs: 0.8146165130019654\n",
      "Epoch 684999 : Train Accuracy : 0.95382, \tValid  Accuracy : 0.9456,\t Train Loss : 10668.412326529866, \tValid Loss :  2907.6233605661337, \t Time for 1000 Epochs: 0.792691338021541\n",
      "Epoch 685999 : Train Accuracy : 0.94258, \tValid  Accuracy : 0.9358,\t Train Loss : 11276.290877388918, \tValid Loss :  2853.7930616380345, \t Time for 1000 Epochs: 0.7814435869804583\n",
      "Epoch 686999 : Train Accuracy : 0.94902, \tValid  Accuracy : 0.9436,\t Train Loss : 9702.597223692619, \tValid Loss :  2482.521933364965, \t Time for 1000 Epochs: 0.8690532020118553\n",
      "Epoch 687999 : Train Accuracy : 0.92418, \tValid  Accuracy : 0.9242,\t Train Loss : 13444.16502824514, \tValid Loss :  2916.051144946313, \t Time for 1000 Epochs: 0.8724210729997139\n",
      "Epoch 688999 : Train Accuracy : 0.94452, \tValid  Accuracy : 0.9361,\t Train Loss : 11176.200630836252, \tValid Loss :  2832.723201775804, \t Time for 1000 Epochs: 0.8909543370245956\n",
      "Epoch 689999 : Train Accuracy : 0.86872, \tValid  Accuracy : 0.8632,\t Train Loss : 20369.245299809587, \tValid Loss :  4631.068261668905, \t Time for 1000 Epochs: 0.8002154490095563\n",
      "Epoch 690999 : Train Accuracy : 0.92782, \tValid  Accuracy : 0.9215,\t Train Loss : 16326.614003161374, \tValid Loss :  3800.2149887522164, \t Time for 1000 Epochs: 0.7817530140164308\n",
      "Epoch 691999 : Train Accuracy : 0.91142, \tValid  Accuracy : 0.9013,\t Train Loss : 23771.180030765812, \tValid Loss :  5271.887688671931, \t Time for 1000 Epochs: 0.876678239001194\n",
      "Epoch 692999 : Train Accuracy : 0.93366, \tValid  Accuracy : 0.9291,\t Train Loss : 12433.216966311205, \tValid Loss :  2835.2267103304625, \t Time for 1000 Epochs: 0.7909592089999933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 693999 : Train Accuracy : 0.92134, \tValid  Accuracy : 0.9157,\t Train Loss : 15463.079430812184, \tValid Loss :  3621.789747937344, \t Time for 1000 Epochs: 0.972516069014091\n",
      "Epoch 694999 : Train Accuracy : 0.94474, \tValid  Accuracy : 0.9361,\t Train Loss : 11717.109299109463, \tValid Loss :  3020.7775729082396, \t Time for 1000 Epochs: 0.9203296139894519\n",
      "Epoch 695999 : Train Accuracy : 0.94322, \tValid  Accuracy : 0.9339,\t Train Loss : 11135.664009921013, \tValid Loss :  2813.4703419137995, \t Time for 1000 Epochs: 0.8040505549870431\n",
      "Epoch 696999 : Train Accuracy : 0.94316, \tValid  Accuracy : 0.9377,\t Train Loss : 10974.896236282832, \tValid Loss :  2715.5396021399547, \t Time for 1000 Epochs: 0.8753931589890271\n",
      "Epoch 697999 : Train Accuracy : 0.94852, \tValid  Accuracy : 0.9407,\t Train Loss : 10142.428718882393, \tValid Loss :  2631.910380413501, \t Time for 1000 Epochs: 0.8746150880178902\n",
      "Epoch 698999 : Train Accuracy : 0.94666, \tValid  Accuracy : 0.9394,\t Train Loss : 10809.495455379247, \tValid Loss :  2767.270134944641, \t Time for 1000 Epochs: 0.8771929549984634\n",
      "Epoch 699999 : Train Accuracy : 0.95174, \tValid  Accuracy : 0.9435,\t Train Loss : 10023.32857089743, \tValid Loss :  2580.2135541913353, \t Time for 1000 Epochs: 0.8863338089722674\n",
      "Epoch 700999 : Train Accuracy : 0.95064, \tValid  Accuracy : 0.9421,\t Train Loss : 10656.710934049137, \tValid Loss :  2849.140785367424, \t Time for 1000 Epochs: 0.8062264549953397\n",
      "Epoch 701999 : Train Accuracy : 0.95212, \tValid  Accuracy : 0.9409,\t Train Loss : 9950.530276338639, \tValid Loss :  2774.1245902606142, \t Time for 1000 Epochs: 0.8745638800028246\n",
      "Epoch 702999 : Train Accuracy : 0.95042, \tValid  Accuracy : 0.942,\t Train Loss : 9633.005685497288, \tValid Loss :  2668.745172831242, \t Time for 1000 Epochs: 0.8788961470127106\n",
      "Epoch 703999 : Train Accuracy : 0.94774, \tValid  Accuracy : 0.9424,\t Train Loss : 10278.728400402266, \tValid Loss :  2827.0955508891875, \t Time for 1000 Epochs: 0.7893595689965878\n",
      "Epoch 704999 : Train Accuracy : 0.94804, \tValid  Accuracy : 0.9406,\t Train Loss : 10087.23130956459, \tValid Loss :  2702.267713317013, \t Time for 1000 Epochs: 0.787989053002093\n",
      "Epoch 705999 : Train Accuracy : 0.9515, \tValid  Accuracy : 0.9451,\t Train Loss : 9038.818008864031, \tValid Loss :  2457.6642049044094, \t Time for 1000 Epochs: 0.9286558019812219\n",
      "Epoch 706999 : Train Accuracy : 0.95488, \tValid  Accuracy : 0.9445,\t Train Loss : 9474.749134576401, \tValid Loss :  2622.082517935275, \t Time for 1000 Epochs: 0.9487502980045974\n",
      "Epoch 707999 : Train Accuracy : 0.9584, \tValid  Accuracy : 0.9518,\t Train Loss : 8421.12016926063, \tValid Loss :  2413.78151381116, \t Time for 1000 Epochs: 0.9475224509951659\n",
      "Epoch 708999 : Train Accuracy : 0.95722, \tValid  Accuracy : 0.9497,\t Train Loss : 9475.720275664384, \tValid Loss :  2591.4623575020423, \t Time for 1000 Epochs: 1.0271889480063692\n",
      "Epoch 709999 : Train Accuracy : 0.9549, \tValid  Accuracy : 0.947,\t Train Loss : 9559.872191996947, \tValid Loss :  2474.214667720082, \t Time for 1000 Epochs: 0.947391694993712\n",
      "Epoch 710999 : Train Accuracy : 0.9508, \tValid  Accuracy : 0.9414,\t Train Loss : 10209.011217040397, \tValid Loss :  2738.4667564203337, \t Time for 1000 Epochs: 0.8340535360039212\n",
      "Epoch 711999 : Train Accuracy : 0.94768, \tValid  Accuracy : 0.9432,\t Train Loss : 10368.238805854975, \tValid Loss :  2702.2429663758494, \t Time for 1000 Epochs: 0.8510036830266472\n",
      "Epoch 712999 : Train Accuracy : 0.94268, \tValid  Accuracy : 0.9333,\t Train Loss : 10783.352296255269, \tValid Loss :  2867.125187458372, \t Time for 1000 Epochs: 0.8364387890032958\n",
      "Epoch 713999 : Train Accuracy : 0.94132, \tValid  Accuracy : 0.9355,\t Train Loss : 14986.103633814064, \tValid Loss :  3508.879055054058, \t Time for 1000 Epochs: 0.8414608759921975\n",
      "Epoch 714999 : Train Accuracy : 0.94142, \tValid  Accuracy : 0.9328,\t Train Loss : 11859.60727511357, \tValid Loss :  3082.2946141428197, \t Time for 1000 Epochs: 0.7451283150003292\n",
      "Epoch 715999 : Train Accuracy : 0.94502, \tValid  Accuracy : 0.9369,\t Train Loss : 10518.775175839575, \tValid Loss :  2701.621392012307, \t Time for 1000 Epochs: 0.8429156780184712\n",
      "Epoch 716999 : Train Accuracy : 0.95504, \tValid  Accuracy : 0.9457,\t Train Loss : 9240.730438099707, \tValid Loss :  2563.3132193953215, \t Time for 1000 Epochs: 0.8631686989974696\n",
      "Epoch 717999 : Train Accuracy : 0.95294, \tValid  Accuracy : 0.9427,\t Train Loss : 8876.26821087239, \tValid Loss :  2500.206901630533, \t Time for 1000 Epochs: 0.8077533949981444\n",
      "Epoch 718999 : Train Accuracy : 0.94308, \tValid  Accuracy : 0.9347,\t Train Loss : 13688.58137305943, \tValid Loss :  3313.2370292459664, \t Time for 1000 Epochs: 0.794357199978549\n",
      "Epoch 719999 : Train Accuracy : 0.95068, \tValid  Accuracy : 0.945,\t Train Loss : 9092.761045998262, \tValid Loss :  2385.1997565659876, \t Time for 1000 Epochs: 0.7760961439926177\n",
      "Epoch 720999 : Train Accuracy : 0.95762, \tValid  Accuracy : 0.95,\t Train Loss : 8808.119770630845, \tValid Loss :  2445.2823504199805, \t Time for 1000 Epochs: 0.8529552980035078\n",
      "Epoch 721999 : Train Accuracy : 0.95682, \tValid  Accuracy : 0.9468,\t Train Loss : 8470.773864902038, \tValid Loss :  2459.5672603921344, \t Time for 1000 Epochs: 0.8182868600124493\n",
      "Epoch 722999 : Train Accuracy : 0.95156, \tValid  Accuracy : 0.9423,\t Train Loss : 9713.367133089187, \tValid Loss :  2642.5627964261143, \t Time for 1000 Epochs: 0.765937722986564\n",
      "Epoch 723999 : Train Accuracy : 0.95722, \tValid  Accuracy : 0.9475,\t Train Loss : 8014.4999387134, \tValid Loss :  2360.415694406779, \t Time for 1000 Epochs: 0.8577195690013468\n",
      "Epoch 724999 : Train Accuracy : 0.9589, \tValid  Accuracy : 0.9484,\t Train Loss : 7914.795113295482, \tValid Loss :  2259.969024712618, \t Time for 1000 Epochs: 0.8677317279798444\n",
      "Epoch 725999 : Train Accuracy : 0.9575, \tValid  Accuracy : 0.948,\t Train Loss : 9131.163953417627, \tValid Loss :  2543.4939973375954, \t Time for 1000 Epochs: 0.8496677039947826\n",
      "Epoch 726999 : Train Accuracy : 0.95526, \tValid  Accuracy : 0.9481,\t Train Loss : 9174.57825364498, \tValid Loss :  2566.497303247475, \t Time for 1000 Epochs: 0.7824942309816834\n",
      "Epoch 727999 : Train Accuracy : 0.95834, \tValid  Accuracy : 0.9473,\t Train Loss : 8259.039647960211, \tValid Loss :  2426.3283577235507, \t Time for 1000 Epochs: 0.7539115920080803\n",
      "Epoch 728999 : Train Accuracy : 0.95068, \tValid  Accuracy : 0.9441,\t Train Loss : 10316.008697986754, \tValid Loss :  2732.214567290687, \t Time for 1000 Epochs: 0.8620682689943351\n",
      "Epoch 729999 : Train Accuracy : 0.95138, \tValid  Accuracy : 0.9464,\t Train Loss : 11062.329256500303, \tValid Loss :  3083.6137196219493, \t Time for 1000 Epochs: 0.7785703240078874\n",
      "Epoch 730999 : Train Accuracy : 0.95968, \tValid  Accuracy : 0.9505,\t Train Loss : 8692.701676901374, \tValid Loss :  2540.9746406376016, \t Time for 1000 Epochs: 0.9106281649728771\n",
      "Epoch 731999 : Train Accuracy : 0.95752, \tValid  Accuracy : 0.9501,\t Train Loss : 9315.887773994322, \tValid Loss :  2439.5964546880177, \t Time for 1000 Epochs: 0.8240575249947142\n",
      "Epoch 732999 : Train Accuracy : 0.93826, \tValid  Accuracy : 0.9301,\t Train Loss : 11690.211260210248, \tValid Loss :  2945.5308527282436, \t Time for 1000 Epochs: 0.8029088659968693\n",
      "Epoch 733999 : Train Accuracy : 0.95256, \tValid  Accuracy : 0.9432,\t Train Loss : 10103.911542325099, \tValid Loss :  2874.9918604670975, \t Time for 1000 Epochs: 0.9298425590095576\n",
      "Epoch 734999 : Train Accuracy : 0.9275, \tValid  Accuracy : 0.9157,\t Train Loss : 14321.71652991467, \tValid Loss :  3644.1843495344883, \t Time for 1000 Epochs: 0.817231933993753\n",
      "Epoch 735999 : Train Accuracy : 0.9519, \tValid  Accuracy : 0.9416,\t Train Loss : 11199.379798052381, \tValid Loss :  2867.202624886452, \t Time for 1000 Epochs: 0.8534048000001349\n",
      "Epoch 736999 : Train Accuracy : 0.95548, \tValid  Accuracy : 0.9461,\t Train Loss : 9061.366222320474, \tValid Loss :  2514.3366929034078, \t Time for 1000 Epochs: 0.8592560550023336\n",
      "Epoch 737999 : Train Accuracy : 0.95264, \tValid  Accuracy : 0.9415,\t Train Loss : 9819.100465894866, \tValid Loss :  2789.523106373743, \t Time for 1000 Epochs: 0.7330932889890391\n",
      "Epoch 738999 : Train Accuracy : 0.95804, \tValid  Accuracy : 0.9472,\t Train Loss : 8842.296735976204, \tValid Loss :  2516.2871266166403, \t Time for 1000 Epochs: 0.8228059880202636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 739999 : Train Accuracy : 0.95696, \tValid  Accuracy : 0.9458,\t Train Loss : 8796.414651595735, \tValid Loss :  2497.6227360138714, \t Time for 1000 Epochs: 0.7313190279819537\n",
      "Epoch 740999 : Train Accuracy : 0.9561, \tValid  Accuracy : 0.9463,\t Train Loss : 8646.920068044581, \tValid Loss :  2667.1627730137593, \t Time for 1000 Epochs: 0.8194669669901486\n",
      "Epoch 741999 : Train Accuracy : 0.9309, \tValid  Accuracy : 0.9223,\t Train Loss : 13803.108491830224, \tValid Loss :  3594.5610603226846, \t Time for 1000 Epochs: 0.7340654059953522\n",
      "Epoch 742999 : Train Accuracy : 0.9476, \tValid  Accuracy : 0.9376,\t Train Loss : 13251.690688101262, \tValid Loss :  3591.640910224047, \t Time for 1000 Epochs: 0.7436310570046771\n",
      "Epoch 743999 : Train Accuracy : 0.93622, \tValid  Accuracy : 0.9278,\t Train Loss : 14663.78185802121, \tValid Loss :  3641.5946099742746, \t Time for 1000 Epochs: 0.8326155380054843\n",
      "Epoch 744999 : Train Accuracy : 0.92504, \tValid  Accuracy : 0.9231,\t Train Loss : 15914.288623847518, \tValid Loss :  3631.7688098958292, \t Time for 1000 Epochs: 0.9128218760015443\n",
      "Epoch 745999 : Train Accuracy : 0.9545, \tValid  Accuracy : 0.9468,\t Train Loss : 10026.784425747668, \tValid Loss :  2797.730231735106, \t Time for 1000 Epochs: 0.8903391610074323\n",
      "Epoch 746999 : Train Accuracy : 0.95436, \tValid  Accuracy : 0.9455,\t Train Loss : 9271.893718950378, \tValid Loss :  2462.2436049924477, \t Time for 1000 Epochs: 0.7663303560111672\n",
      "Epoch 747999 : Train Accuracy : 0.95514, \tValid  Accuracy : 0.9469,\t Train Loss : 9190.25761698937, \tValid Loss :  2481.264869735589, \t Time for 1000 Epochs: 0.8556879700045101\n",
      "Epoch 748999 : Train Accuracy : 0.9584, \tValid  Accuracy : 0.9492,\t Train Loss : 8764.554501550185, \tValid Loss :  2590.369427243523, \t Time for 1000 Epochs: 0.8611860680102836\n",
      "Epoch 749999 : Train Accuracy : 0.95916, \tValid  Accuracy : 0.9487,\t Train Loss : 8098.172291925817, \tValid Loss :  2514.0036016152635, \t Time for 1000 Epochs: 0.7847565269912593\n",
      "Epoch 750999 : Train Accuracy : 0.957, \tValid  Accuracy : 0.9473,\t Train Loss : 8844.519933808544, \tValid Loss :  2658.56826881248, \t Time for 1000 Epochs: 0.7701861370005645\n",
      "Epoch 751999 : Train Accuracy : 0.9592, \tValid  Accuracy : 0.9493,\t Train Loss : 8788.258184691611, \tValid Loss :  2638.503593290074, \t Time for 1000 Epochs: 0.7790816370106768\n",
      "Epoch 752999 : Train Accuracy : 0.95694, \tValid  Accuracy : 0.9456,\t Train Loss : 8187.778603022214, \tValid Loss :  2399.564940630988, \t Time for 1000 Epochs: 0.7626371789956465\n",
      "Epoch 753999 : Train Accuracy : 0.93546, \tValid  Accuracy : 0.9263,\t Train Loss : 11739.734405122743, \tValid Loss :  3172.519694067433, \t Time for 1000 Epochs: 0.8519977010146249\n",
      "Epoch 754999 : Train Accuracy : 0.92558, \tValid  Accuracy : 0.919,\t Train Loss : 11920.293417834388, \tValid Loss :  3232.0609637225934, \t Time for 1000 Epochs: 0.8519388819986489\n",
      "Epoch 755999 : Train Accuracy : 0.94826, \tValid  Accuracy : 0.9416,\t Train Loss : 11661.258285084446, \tValid Loss :  3010.332200974085, \t Time for 1000 Epochs: 0.8655088300001808\n",
      "Epoch 756999 : Train Accuracy : 0.93914, \tValid  Accuracy : 0.9296,\t Train Loss : 13418.924321745311, \tValid Loss :  3590.1183823185265, \t Time for 1000 Epochs: 0.9292612999852281\n",
      "Epoch 757999 : Train Accuracy : 0.956, \tValid  Accuracy : 0.9467,\t Train Loss : 9697.486775837342, \tValid Loss :  2827.025404242016, \t Time for 1000 Epochs: 0.9095833800092805\n",
      "Epoch 758999 : Train Accuracy : 0.95788, \tValid  Accuracy : 0.9496,\t Train Loss : 9632.417075616071, \tValid Loss :  2796.8997894844765, \t Time for 1000 Epochs: 0.8856761429924518\n",
      "Epoch 759999 : Train Accuracy : 0.95586, \tValid  Accuracy : 0.9479,\t Train Loss : 10922.248921754963, \tValid Loss :  3101.3240915448528, \t Time for 1000 Epochs: 0.8550097409752198\n",
      "Epoch 760999 : Train Accuracy : 0.93822, \tValid  Accuracy : 0.929,\t Train Loss : 14223.296477327835, \tValid Loss :  3732.353667786192, \t Time for 1000 Epochs: 0.8567639540124219\n",
      "Epoch 761999 : Train Accuracy : 0.9588, \tValid  Accuracy : 0.9483,\t Train Loss : 9202.917661794707, \tValid Loss :  2738.2220198407877, \t Time for 1000 Epochs: 0.7704100229893811\n",
      "Epoch 762999 : Train Accuracy : 0.95808, \tValid  Accuracy : 0.9472,\t Train Loss : 10018.251404868277, \tValid Loss :  2888.9916209267953, \t Time for 1000 Epochs: 0.7739887160132639\n",
      "Epoch 763999 : Train Accuracy : 0.94238, \tValid  Accuracy : 0.9306,\t Train Loss : 12271.75701727892, \tValid Loss :  3420.7316939160028, \t Time for 1000 Epochs: 0.7720510200015269\n",
      "Epoch 764999 : Train Accuracy : 0.94096, \tValid  Accuracy : 0.9329,\t Train Loss : 12269.416995070913, \tValid Loss :  3258.3567344654152, \t Time for 1000 Epochs: 0.759411122999154\n",
      "Epoch 765999 : Train Accuracy : 0.95454, \tValid  Accuracy : 0.9442,\t Train Loss : 10241.399762098265, \tValid Loss :  2831.8767914921223, \t Time for 1000 Epochs: 0.8790533300198149\n",
      "Epoch 766999 : Train Accuracy : 0.94562, \tValid  Accuracy : 0.9367,\t Train Loss : 11268.081957819873, \tValid Loss :  3016.2649143647695, \t Time for 1000 Epochs: 0.7648655540251639\n",
      "Epoch 767999 : Train Accuracy : 0.946, \tValid  Accuracy : 0.9356,\t Train Loss : 11415.702478669164, \tValid Loss :  3197.7628070182595, \t Time for 1000 Epochs: 0.7616981230094098\n",
      "Epoch 768999 : Train Accuracy : 0.94422, \tValid  Accuracy : 0.9359,\t Train Loss : 11729.682288681604, \tValid Loss :  3140.152926780078, \t Time for 1000 Epochs: 0.8683167709968984\n",
      "Epoch 769999 : Train Accuracy : 0.95596, \tValid  Accuracy : 0.9441,\t Train Loss : 9939.98252341028, \tValid Loss :  3057.0277526982104, \t Time for 1000 Epochs: 0.9164293359790463\n",
      "Epoch 770999 : Train Accuracy : 0.94566, \tValid  Accuracy : 0.9362,\t Train Loss : 11769.21423246932, \tValid Loss :  3191.7283618984934, \t Time for 1000 Epochs: 0.8113169299904257\n",
      "Epoch 771999 : Train Accuracy : 0.94944, \tValid  Accuracy : 0.939,\t Train Loss : 11227.153538336304, \tValid Loss :  3120.0656386286814, \t Time for 1000 Epochs: 0.8981617650133558\n",
      "Epoch 772999 : Train Accuracy : 0.93382, \tValid  Accuracy : 0.9251,\t Train Loss : 12721.950257814442, \tValid Loss :  3336.2563289138666, \t Time for 1000 Epochs: 0.7462673879927024\n",
      "Epoch 773999 : Train Accuracy : 0.94296, \tValid  Accuracy : 0.9351,\t Train Loss : 11136.45159442396, \tValid Loss :  2834.1302083286178, \t Time for 1000 Epochs: 0.8123076989722904\n",
      "Epoch 774999 : Train Accuracy : 0.95108, \tValid  Accuracy : 0.9423,\t Train Loss : 9435.438828174456, \tValid Loss :  2586.8124873320803, \t Time for 1000 Epochs: 0.8159379359858576\n",
      "Epoch 775999 : Train Accuracy : 0.94066, \tValid  Accuracy : 0.9339,\t Train Loss : 11572.581799170666, \tValid Loss :  3005.673021953866, \t Time for 1000 Epochs: 0.729179360991111\n",
      "Epoch 776999 : Train Accuracy : 0.9383, \tValid  Accuracy : 0.9348,\t Train Loss : 11006.349188039316, \tValid Loss :  2833.6144228312464, \t Time for 1000 Epochs: 0.7251658070017584\n",
      "Epoch 777999 : Train Accuracy : 0.94768, \tValid  Accuracy : 0.943,\t Train Loss : 9933.57725004573, \tValid Loss :  2561.9245592170773, \t Time for 1000 Epochs: 0.8143612039857544\n",
      "Epoch 778999 : Train Accuracy : 0.95316, \tValid  Accuracy : 0.9454,\t Train Loss : 9772.366581217884, \tValid Loss :  2664.079867123675, \t Time for 1000 Epochs: 0.7290877290070057\n",
      "Epoch 779999 : Train Accuracy : 0.94492, \tValid  Accuracy : 0.9378,\t Train Loss : 11823.217570200313, \tValid Loss :  3070.2838530663457, \t Time for 1000 Epochs: 0.7320753560052253\n",
      "Epoch 780999 : Train Accuracy : 0.94622, \tValid  Accuracy : 0.9388,\t Train Loss : 10239.430404118673, \tValid Loss :  2709.2253529724903, \t Time for 1000 Epochs: 0.724240980023751\n",
      "Epoch 781999 : Train Accuracy : 0.9495, \tValid  Accuracy : 0.9424,\t Train Loss : 10079.775256985193, \tValid Loss :  2813.1123087474875, \t Time for 1000 Epochs: 0.7279216659953818\n",
      "Epoch 782999 : Train Accuracy : 0.95594, \tValid  Accuracy : 0.9491,\t Train Loss : 9589.74139504287, \tValid Loss :  2712.5047261137024, \t Time for 1000 Epochs: 0.7643347150005866\n",
      "Epoch 783999 : Train Accuracy : 0.94676, \tValid  Accuracy : 0.9386,\t Train Loss : 10168.553629979911, \tValid Loss :  2713.288070211355, \t Time for 1000 Epochs: 0.7940922920242883\n",
      "Epoch 784999 : Train Accuracy : 0.95218, \tValid  Accuracy : 0.9437,\t Train Loss : 11459.574236916706, \tValid Loss :  3182.75770901491, \t Time for 1000 Epochs: 0.9075942630006466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785999 : Train Accuracy : 0.95128, \tValid  Accuracy : 0.9432,\t Train Loss : 9781.754443555736, \tValid Loss :  2743.057742218616, \t Time for 1000 Epochs: 0.7953827960009221\n",
      "Epoch 786999 : Train Accuracy : 0.9478, \tValid  Accuracy : 0.9392,\t Train Loss : 10963.976419656949, \tValid Loss :  2965.26617749021, \t Time for 1000 Epochs: 0.8568761839997023\n",
      "Epoch 787999 : Train Accuracy : 0.9554, \tValid  Accuracy : 0.9477,\t Train Loss : 10124.59305931284, \tValid Loss :  2866.3267728493706, \t Time for 1000 Epochs: 0.8580642990127672\n",
      "Epoch 788999 : Train Accuracy : 0.95054, \tValid  Accuracy : 0.9415,\t Train Loss : 13693.931101627004, \tValid Loss :  3569.6459735979597, \t Time for 1000 Epochs: 0.7590566900034901\n",
      "Epoch 789999 : Train Accuracy : 0.941, \tValid  Accuracy : 0.9342,\t Train Loss : 12215.494215467717, \tValid Loss :  3214.3169030887466, \t Time for 1000 Epochs: 0.7621318520104978\n",
      "Epoch 790999 : Train Accuracy : 0.8905, \tValid  Accuracy : 0.8794,\t Train Loss : 26394.470888438587, \tValid Loss :  6355.377972125001, \t Time for 1000 Epochs: 0.772021507989848\n",
      "Epoch 791999 : Train Accuracy : 0.94628, \tValid  Accuracy : 0.9389,\t Train Loss : 11530.41097373548, \tValid Loss :  3049.200137280132, \t Time for 1000 Epochs: 0.8590558330179192\n",
      "Epoch 792999 : Train Accuracy : 0.94628, \tValid  Accuracy : 0.9393,\t Train Loss : 11797.540664296572, \tValid Loss :  3075.8255265652165, \t Time for 1000 Epochs: 0.8532678429910447\n",
      "Epoch 793999 : Train Accuracy : 0.94488, \tValid  Accuracy : 0.9379,\t Train Loss : 12664.43706918434, \tValid Loss :  3263.6658895700134, \t Time for 1000 Epochs: 0.8482677239808254\n",
      "Epoch 794999 : Train Accuracy : 0.94428, \tValid  Accuracy : 0.9368,\t Train Loss : 11172.391946352556, \tValid Loss :  2767.329937485417, \t Time for 1000 Epochs: 0.8509949279832654\n",
      "Epoch 795999 : Train Accuracy : 0.94646, \tValid  Accuracy : 0.9374,\t Train Loss : 11323.95847705978, \tValid Loss :  2942.5259289729966, \t Time for 1000 Epochs: 0.7913103149912786\n",
      "Epoch 796999 : Train Accuracy : 0.95134, \tValid  Accuracy : 0.9419,\t Train Loss : 10071.963375020801, \tValid Loss :  2729.5173473187992, \t Time for 1000 Epochs: 0.8347820320050232\n",
      "Epoch 797999 : Train Accuracy : 0.95254, \tValid  Accuracy : 0.9417,\t Train Loss : 10330.156676084296, \tValid Loss :  2724.5248962276028, \t Time for 1000 Epochs: 0.9044801109994296\n",
      "Epoch 798999 : Train Accuracy : 0.94732, \tValid  Accuracy : 0.9388,\t Train Loss : 11129.368865586435, \tValid Loss :  2800.1991979438217, \t Time for 1000 Epochs: 0.8072886829904746\n",
      "Epoch 799999 : Train Accuracy : 0.87068, \tValid  Accuracy : 0.8693,\t Train Loss : 39383.27256206286, \tValid Loss :  8256.587248074391, \t Time for 1000 Epochs: 0.771781771996757\n",
      "Epoch 800999 : Train Accuracy : 0.9545, \tValid  Accuracy : 0.9456,\t Train Loss : 9799.414721037601, \tValid Loss :  2663.744461837286, \t Time for 1000 Epochs: 0.7681108580145519\n",
      "Epoch 801999 : Train Accuracy : 0.94912, \tValid  Accuracy : 0.9419,\t Train Loss : 10596.272918203711, \tValid Loss :  2986.4952823790527, \t Time for 1000 Epochs: 0.7711946709896438\n",
      "Epoch 802999 : Train Accuracy : 0.95218, \tValid  Accuracy : 0.9409,\t Train Loss : 9108.21315665661, \tValid Loss :  2664.6151735102603, \t Time for 1000 Epochs: 0.7960099339834414\n",
      "Epoch 803999 : Train Accuracy : 0.95234, \tValid  Accuracy : 0.9424,\t Train Loss : 10026.28768257812, \tValid Loss :  2737.431945939988, \t Time for 1000 Epochs: 0.7620893249986693\n",
      "Epoch 804999 : Train Accuracy : 0.95474, \tValid  Accuracy : 0.9438,\t Train Loss : 9723.251669082838, \tValid Loss :  2734.2058186576423, \t Time for 1000 Epochs: 0.7708322620019317\n",
      "Epoch 805999 : Train Accuracy : 0.95326, \tValid  Accuracy : 0.9435,\t Train Loss : 10189.363177296393, \tValid Loss :  2952.374938665422, \t Time for 1000 Epochs: 0.7630390300182626\n",
      "Epoch 806999 : Train Accuracy : 0.95276, \tValid  Accuracy : 0.9409,\t Train Loss : 9811.455535318662, \tValid Loss :  2844.231340719863, \t Time for 1000 Epochs: 0.7721035790164024\n",
      "Epoch 807999 : Train Accuracy : 0.95302, \tValid  Accuracy : 0.9432,\t Train Loss : 9496.249475096827, \tValid Loss :  2623.7889491123506, \t Time for 1000 Epochs: 0.775782877986785\n",
      "Epoch 808999 : Train Accuracy : 0.93682, \tValid  Accuracy : 0.9312,\t Train Loss : 13137.825816181818, \tValid Loss :  3264.026678831132, \t Time for 1000 Epochs: 0.7634698390029371\n",
      "Epoch 809999 : Train Accuracy : 0.951, \tValid  Accuracy : 0.9427,\t Train Loss : 10390.703375759529, \tValid Loss :  2820.3033453260828, \t Time for 1000 Epochs: 0.8295500230160542\n",
      "Epoch 810999 : Train Accuracy : 0.9329, \tValid  Accuracy : 0.9266,\t Train Loss : 12602.998774278261, \tValid Loss :  3172.436378434532, \t Time for 1000 Epochs: 0.8017397160001565\n",
      "Epoch 811999 : Train Accuracy : 0.87054, \tValid  Accuracy : 0.8719,\t Train Loss : 29956.903040655343, \tValid Loss :  5937.053120893927, \t Time for 1000 Epochs: 0.8797454960003961\n",
      "Epoch 812999 : Train Accuracy : 0.93416, \tValid  Accuracy : 0.926,\t Train Loss : 14971.21081890418, \tValid Loss :  3664.367901498043, \t Time for 1000 Epochs: 0.8680965609964915\n",
      "Epoch 813999 : Train Accuracy : 0.93514, \tValid  Accuracy : 0.9281,\t Train Loss : 14278.681299981434, \tValid Loss :  3428.545619635332, \t Time for 1000 Epochs: 0.7625813310150988\n",
      "Epoch 814999 : Train Accuracy : 0.92956, \tValid  Accuracy : 0.9265,\t Train Loss : 15397.810235469045, \tValid Loss :  3704.7043579919477, \t Time for 1000 Epochs: 0.845146873005433\n",
      "Epoch 815999 : Train Accuracy : 0.93426, \tValid  Accuracy : 0.9251,\t Train Loss : 13073.25145952502, \tValid Loss :  3207.4829046912982, \t Time for 1000 Epochs: 0.851682456996059\n",
      "Epoch 816999 : Train Accuracy : 0.92534, \tValid  Accuracy : 0.9221,\t Train Loss : 16336.687678497909, \tValid Loss :  3831.06804598502, \t Time for 1000 Epochs: 0.7721119780035224\n",
      "Epoch 817999 : Train Accuracy : 0.93582, \tValid  Accuracy : 0.9278,\t Train Loss : 12671.842213561264, \tValid Loss :  3192.9123278492516, \t Time for 1000 Epochs: 0.7647535500000231\n",
      "Epoch 818999 : Train Accuracy : 0.9357, \tValid  Accuracy : 0.9282,\t Train Loss : 12689.130913659668, \tValid Loss :  3107.9164879295067, \t Time for 1000 Epochs: 0.853146175009897\n",
      "Epoch 819999 : Train Accuracy : 0.9436, \tValid  Accuracy : 0.9371,\t Train Loss : 12660.329875443402, \tValid Loss :  3049.192526935338, \t Time for 1000 Epochs: 0.8500729110091925\n",
      "Epoch 820999 : Train Accuracy : 0.9505, \tValid  Accuracy : 0.9427,\t Train Loss : 10203.783646630627, \tValid Loss :  2646.0643050262825, \t Time for 1000 Epochs: 0.8623287130030803\n",
      "Epoch 821999 : Train Accuracy : 0.95092, \tValid  Accuracy : 0.9415,\t Train Loss : 11030.627606633845, \tValid Loss :  2864.7678631294466, \t Time for 1000 Epochs: 0.7778812830219977\n",
      "Epoch 822999 : Train Accuracy : 0.95606, \tValid  Accuracy : 0.9483,\t Train Loss : 8788.891808827815, \tValid Loss :  2474.9831730722103, \t Time for 1000 Epochs: 0.8131599540065508\n",
      "Epoch 823999 : Train Accuracy : 0.95078, \tValid  Accuracy : 0.9422,\t Train Loss : 9760.055429880365, \tValid Loss :  2738.139349970741, \t Time for 1000 Epochs: 0.8327152419951744\n",
      "Epoch 824999 : Train Accuracy : 0.95952, \tValid  Accuracy : 0.9488,\t Train Loss : 8504.828931959872, \tValid Loss :  2584.204390303655, \t Time for 1000 Epochs: 0.7908957310137339\n",
      "Epoch 825999 : Train Accuracy : 0.94012, \tValid  Accuracy : 0.932,\t Train Loss : 13233.411012343831, \tValid Loss :  3230.386547931749, \t Time for 1000 Epochs: 0.7833113780070562\n",
      "Epoch 826999 : Train Accuracy : 0.93202, \tValid  Accuracy : 0.925,\t Train Loss : 17730.479566849408, \tValid Loss :  4163.800345583597, \t Time for 1000 Epochs: 0.7628305600082967\n",
      "Epoch 827999 : Train Accuracy : 0.95684, \tValid  Accuracy : 0.9493,\t Train Loss : 9245.902555573946, \tValid Loss :  2655.5542463726083, \t Time for 1000 Epochs: 0.7681687010044698\n",
      "Epoch 828999 : Train Accuracy : 0.93182, \tValid  Accuracy : 0.9245,\t Train Loss : 13026.625532792834, \tValid Loss :  3383.1037999043656, \t Time for 1000 Epochs: 0.7699837609834503\n",
      "Epoch 829999 : Train Accuracy : 0.93976, \tValid  Accuracy : 0.9346,\t Train Loss : 17316.883566665965, \tValid Loss :  3919.749298828676, \t Time for 1000 Epochs: 0.7709565179829951\n",
      "Epoch 830999 : Train Accuracy : 0.93332, \tValid  Accuracy : 0.9311,\t Train Loss : 19954.170674468663, \tValid Loss :  4437.7668348694315, \t Time for 1000 Epochs: 0.7684834009851329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 831999 : Train Accuracy : 0.90984, \tValid  Accuracy : 0.9018,\t Train Loss : 17587.784760256865, \tValid Loss :  4387.046228438615, \t Time for 1000 Epochs: 0.7685805870278273\n",
      "Epoch 832999 : Train Accuracy : 0.9134, \tValid  Accuracy : 0.9111,\t Train Loss : 20068.087464467342, \tValid Loss :  4584.781577217251, \t Time for 1000 Epochs: 0.7734864300000481\n",
      "Epoch 833999 : Train Accuracy : 0.93012, \tValid  Accuracy : 0.9223,\t Train Loss : 19859.97593735093, \tValid Loss :  4692.296383950247, \t Time for 1000 Epochs: 0.8589680560107809\n",
      "Epoch 834999 : Train Accuracy : 0.9374, \tValid  Accuracy : 0.929,\t Train Loss : 17224.397007392552, \tValid Loss :  4210.4528160359105, \t Time for 1000 Epochs: 0.7669331269862596\n",
      "Epoch 835999 : Train Accuracy : 0.89638, \tValid  Accuracy : 0.894,\t Train Loss : 20677.586292424545, \tValid Loss :  4582.91588000629, \t Time for 1000 Epochs: 0.8736853659793269\n",
      "Epoch 836999 : Train Accuracy : 0.90694, \tValid  Accuracy : 0.9033,\t Train Loss : 18551.680779508035, \tValid Loss :  4326.485714031503, \t Time for 1000 Epochs: 0.9158017470035702\n",
      "Epoch 837999 : Train Accuracy : 0.91876, \tValid  Accuracy : 0.9112,\t Train Loss : 17453.38959067477, \tValid Loss :  4170.1428297999355, \t Time for 1000 Epochs: 0.8147115400061011\n",
      "Epoch 838999 : Train Accuracy : 0.9, \tValid  Accuracy : 0.8947,\t Train Loss : 21303.53372148952, \tValid Loss :  4629.7533818717175, \t Time for 1000 Epochs: 0.8848499580053613\n",
      "Epoch 839999 : Train Accuracy : 0.91508, \tValid  Accuracy : 0.909,\t Train Loss : 16701.673759395635, \tValid Loss :  3961.825268978736, \t Time for 1000 Epochs: 0.8915040429856163\n",
      "Epoch 840999 : Train Accuracy : 0.9163, \tValid  Accuracy : 0.9124,\t Train Loss : 16089.308913099307, \tValid Loss :  3683.054651951182, \t Time for 1000 Epochs: 0.8650991689937655\n",
      "Epoch 841999 : Train Accuracy : 0.93472, \tValid  Accuracy : 0.9291,\t Train Loss : 14030.26491727677, \tValid Loss :  3430.632332149302, \t Time for 1000 Epochs: 0.8626497210061643\n",
      "Epoch 842999 : Train Accuracy : 0.93384, \tValid  Accuracy : 0.9251,\t Train Loss : 15248.319597431211, \tValid Loss :  3630.7338364556044, \t Time for 1000 Epochs: 0.7649921819975134\n",
      "Epoch 843999 : Train Accuracy : 0.92596, \tValid  Accuracy : 0.918,\t Train Loss : 17076.76940433083, \tValid Loss :  4057.5401741697533, \t Time for 1000 Epochs: 0.7709925149974879\n",
      "Epoch 844999 : Train Accuracy : 0.927, \tValid  Accuracy : 0.9222,\t Train Loss : 14893.63799486055, \tValid Loss :  3441.0304947997142, \t Time for 1000 Epochs: 0.8658898999856319\n",
      "Epoch 845999 : Train Accuracy : 0.93196, \tValid  Accuracy : 0.9267,\t Train Loss : 13295.95972803449, \tValid Loss :  3266.1712004439178, \t Time for 1000 Epochs: 0.8545728000171948\n",
      "Epoch 846999 : Train Accuracy : 0.94762, \tValid  Accuracy : 0.944,\t Train Loss : 11029.992682060754, \tValid Loss :  2641.193029889919, \t Time for 1000 Epochs: 0.8526576579897664\n",
      "Epoch 847999 : Train Accuracy : 0.93226, \tValid  Accuracy : 0.9312,\t Train Loss : 14878.281645412546, \tValid Loss :  3379.8456606492246, \t Time for 1000 Epochs: 0.7677507549815346\n",
      "Epoch 848999 : Train Accuracy : 0.9385, \tValid  Accuracy : 0.9324,\t Train Loss : 12133.409366436688, \tValid Loss :  2968.9299628014546, \t Time for 1000 Epochs: 0.7990072130050976\n",
      "Epoch 849999 : Train Accuracy : 0.94258, \tValid  Accuracy : 0.9356,\t Train Loss : 12226.264600101076, \tValid Loss :  2943.5362317654412, \t Time for 1000 Epochs: 0.9216653650219087\n",
      "Epoch 850999 : Train Accuracy : 0.94464, \tValid  Accuracy : 0.939,\t Train Loss : 10774.078747383302, \tValid Loss :  2682.406547717005, \t Time for 1000 Epochs: 0.8993260529823601\n",
      "Epoch 851999 : Train Accuracy : 0.94488, \tValid  Accuracy : 0.9393,\t Train Loss : 10327.917444434339, \tValid Loss :  2656.4002432614593, \t Time for 1000 Epochs: 0.8777248330006842\n",
      "Epoch 852999 : Train Accuracy : 0.93994, \tValid  Accuracy : 0.9354,\t Train Loss : 10977.116943406061, \tValid Loss :  2745.555112026391, \t Time for 1000 Epochs: 0.7680933620140422\n",
      "Epoch 853999 : Train Accuracy : 0.94806, \tValid  Accuracy : 0.9419,\t Train Loss : 12005.904734748836, \tValid Loss :  2835.0101469967312, \t Time for 1000 Epochs: 0.7648653629876208\n",
      "Epoch 854999 : Train Accuracy : 0.93944, \tValid  Accuracy : 0.9317,\t Train Loss : 12467.973423979942, \tValid Loss :  2921.340887058838, \t Time for 1000 Epochs: 0.8501731200085487\n",
      "Epoch 855999 : Train Accuracy : 0.94708, \tValid  Accuracy : 0.9384,\t Train Loss : 10792.276045375807, \tValid Loss :  2807.3898991324522, \t Time for 1000 Epochs: 0.8520387449825648\n",
      "Epoch 856999 : Train Accuracy : 0.9463, \tValid  Accuracy : 0.9397,\t Train Loss : 10555.536640329588, \tValid Loss :  2550.160807318753, \t Time for 1000 Epochs: 0.8515866039961111\n",
      "Epoch 857999 : Train Accuracy : 0.94788, \tValid  Accuracy : 0.9383,\t Train Loss : 10603.033789572602, \tValid Loss :  2656.451259869943, \t Time for 1000 Epochs: 0.8539079740003217\n",
      "Epoch 858999 : Train Accuracy : 0.94832, \tValid  Accuracy : 0.9383,\t Train Loss : 11750.069261096976, \tValid Loss :  2919.8344112994037, \t Time for 1000 Epochs: 0.8513034829811659\n",
      "Epoch 859999 : Train Accuracy : 0.93716, \tValid  Accuracy : 0.9277,\t Train Loss : 12676.69357493448, \tValid Loss :  3177.7019900522405, \t Time for 1000 Epochs: 0.8870414670091122\n",
      "Epoch 860999 : Train Accuracy : 0.94554, \tValid  Accuracy : 0.9375,\t Train Loss : 11653.33097842615, \tValid Loss :  2944.60220271066, \t Time for 1000 Epochs: 0.7668994499836117\n",
      "Epoch 861999 : Train Accuracy : 0.92596, \tValid  Accuracy : 0.9198,\t Train Loss : 13107.098752647551, \tValid Loss :  3218.424778609273, \t Time for 1000 Epochs: 0.9082142559927888\n",
      "Epoch 862999 : Train Accuracy : 0.94186, \tValid  Accuracy : 0.9333,\t Train Loss : 10679.667036344556, \tValid Loss :  2893.1677250486227, \t Time for 1000 Epochs: 0.91250920901075\n",
      "Epoch 863999 : Train Accuracy : 0.95034, \tValid  Accuracy : 0.9419,\t Train Loss : 10593.876505992623, \tValid Loss :  2883.393010983953, \t Time for 1000 Epochs: 0.8067982200009283\n",
      "Epoch 864999 : Train Accuracy : 0.92226, \tValid  Accuracy : 0.919,\t Train Loss : 13961.344096141682, \tValid Loss :  3270.922479273048, \t Time for 1000 Epochs: 0.7897089980251621\n",
      "Epoch 865999 : Train Accuracy : 0.94166, \tValid  Accuracy : 0.9365,\t Train Loss : 15188.655740255315, \tValid Loss :  3741.4744640751555, \t Time for 1000 Epochs: 0.8544448979955632\n",
      "Epoch 866999 : Train Accuracy : 0.92142, \tValid  Accuracy : 0.918,\t Train Loss : 16695.25208301388, \tValid Loss :  3792.0570010412166, \t Time for 1000 Epochs: 0.856830158008961\n",
      "Epoch 867999 : Train Accuracy : 0.93406, \tValid  Accuracy : 0.9285,\t Train Loss : 11572.434759347487, \tValid Loss :  3011.7279832103527, \t Time for 1000 Epochs: 0.8534903529798612\n",
      "Epoch 868999 : Train Accuracy : 0.92358, \tValid  Accuracy : 0.9177,\t Train Loss : 14406.626849350603, \tValid Loss :  3291.5297316229876, \t Time for 1000 Epochs: 0.8244870529742911\n",
      "Epoch 869999 : Train Accuracy : 0.92148, \tValid  Accuracy : 0.9192,\t Train Loss : 14308.58186041087, \tValid Loss :  3390.3498507605696, \t Time for 1000 Epochs: 0.8720941460051108\n",
      "Epoch 870999 : Train Accuracy : 0.94744, \tValid  Accuracy : 0.9417,\t Train Loss : 11650.551350985852, \tValid Loss :  3026.5998456256566, \t Time for 1000 Epochs: 0.8064638119831216\n",
      "Epoch 871999 : Train Accuracy : 0.94016, \tValid  Accuracy : 0.9337,\t Train Loss : 11738.867011577644, \tValid Loss :  3071.7177689312925, \t Time for 1000 Epochs: 0.7785555339942221\n",
      "Epoch 872999 : Train Accuracy : 0.9532, \tValid  Accuracy : 0.9462,\t Train Loss : 10574.639574054592, \tValid Loss :  2937.379160251102, \t Time for 1000 Epochs: 0.8665850590041373\n",
      "Epoch 873999 : Train Accuracy : 0.94576, \tValid  Accuracy : 0.9371,\t Train Loss : 10268.311264193771, \tValid Loss :  2829.6562865718083, \t Time for 1000 Epochs: 0.7783866670215502\n",
      "Epoch 874999 : Train Accuracy : 0.92858, \tValid  Accuracy : 0.9236,\t Train Loss : 12484.11784374156, \tValid Loss :  3225.4796824845675, \t Time for 1000 Epochs: 0.8415823609975632\n",
      "Epoch 875999 : Train Accuracy : 0.90192, \tValid  Accuracy : 0.8997,\t Train Loss : 14820.977884266411, \tValid Loss :  3464.4895567607346, \t Time for 1000 Epochs: 0.8338208140048664\n",
      "Epoch 876999 : Train Accuracy : 0.91514, \tValid  Accuracy : 0.9108,\t Train Loss : 14753.788794424723, \tValid Loss :  3487.2434367310548, \t Time for 1000 Epochs: 0.8458060759876389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 877999 : Train Accuracy : 0.95218, \tValid  Accuracy : 0.9456,\t Train Loss : 9645.280974966963, \tValid Loss :  2540.481281902843, \t Time for 1000 Epochs: 0.7552070200035814\n",
      "Epoch 878999 : Train Accuracy : 0.9512, \tValid  Accuracy : 0.943,\t Train Loss : 10278.095648062406, \tValid Loss :  2688.4263468170393, \t Time for 1000 Epochs: 0.733785478019854\n",
      "Epoch 879999 : Train Accuracy : 0.94954, \tValid  Accuracy : 0.9428,\t Train Loss : 10673.551928405304, \tValid Loss :  2805.0489938812516, \t Time for 1000 Epochs: 0.7568223740090616\n",
      "Epoch 880999 : Train Accuracy : 0.95098, \tValid  Accuracy : 0.9422,\t Train Loss : 9730.684637714578, \tValid Loss :  2748.0464079685917, \t Time for 1000 Epochs: 0.7538294309924822\n",
      "Epoch 881999 : Train Accuracy : 0.94748, \tValid  Accuracy : 0.9421,\t Train Loss : 10783.012931668341, \tValid Loss :  2746.970168593053, \t Time for 1000 Epochs: 0.739478728006361\n",
      "Epoch 882999 : Train Accuracy : 0.95194, \tValid  Accuracy : 0.9458,\t Train Loss : 9580.860175129961, \tValid Loss :  2617.08721370299, \t Time for 1000 Epochs: 0.8449384210107382\n",
      "Epoch 883999 : Train Accuracy : 0.88558, \tValid  Accuracy : 0.8829,\t Train Loss : 17882.930355869514, \tValid Loss :  4130.967530771222, \t Time for 1000 Epochs: 0.7548910070036072\n",
      "Epoch 884999 : Train Accuracy : 0.948, \tValid  Accuracy : 0.9389,\t Train Loss : 10229.439547063304, \tValid Loss :  2864.1196789042056, \t Time for 1000 Epochs: 0.8375704459904227\n",
      "Epoch 885999 : Train Accuracy : 0.94324, \tValid  Accuracy : 0.935,\t Train Loss : 10153.774843768537, \tValid Loss :  2738.6495133745575, \t Time for 1000 Epochs: 0.7539173690020107\n",
      "Epoch 886999 : Train Accuracy : 0.94684, \tValid  Accuracy : 0.9386,\t Train Loss : 11251.863253778916, \tValid Loss :  3023.4310927295915, \t Time for 1000 Epochs: 0.8416285840212367\n",
      "Epoch 887999 : Train Accuracy : 0.93272, \tValid  Accuracy : 0.9251,\t Train Loss : 12352.099420937577, \tValid Loss :  3210.691372031093, \t Time for 1000 Epochs: 0.8635638310224749\n",
      "Epoch 888999 : Train Accuracy : 0.91106, \tValid  Accuracy : 0.905,\t Train Loss : 13720.559470850223, \tValid Loss :  3389.541821725519, \t Time for 1000 Epochs: 0.9188131720002275\n",
      "Epoch 889999 : Train Accuracy : 0.93536, \tValid  Accuracy : 0.9309,\t Train Loss : 13463.66365882403, \tValid Loss :  3277.1275999212025, \t Time for 1000 Epochs: 0.8346462109766435\n",
      "Epoch 890999 : Train Accuracy : 0.9402, \tValid  Accuracy : 0.9336,\t Train Loss : 12593.573656187686, \tValid Loss :  3255.5339180367064, \t Time for 1000 Epochs: 0.8014992130047176\n",
      "Epoch 891999 : Train Accuracy : 0.87824, \tValid  Accuracy : 0.8701,\t Train Loss : 21440.225422919826, \tValid Loss :  4920.327276631505, \t Time for 1000 Epochs: 0.7728421270148829\n",
      "Epoch 892999 : Train Accuracy : 0.94506, \tValid  Accuracy : 0.9365,\t Train Loss : 11791.412431336552, \tValid Loss :  3204.551721245753, \t Time for 1000 Epochs: 0.8673649069969542\n",
      "Epoch 893999 : Train Accuracy : 0.94846, \tValid  Accuracy : 0.9388,\t Train Loss : 9600.343639348936, \tValid Loss :  2690.158356435673, \t Time for 1000 Epochs: 0.7777750010136515\n",
      "Epoch 894999 : Train Accuracy : 0.92812, \tValid  Accuracy : 0.9239,\t Train Loss : 13425.779374606303, \tValid Loss :  3229.8221659953856, \t Time for 1000 Epochs: 0.7717462780128699\n",
      "Epoch 895999 : Train Accuracy : 0.94726, \tValid  Accuracy : 0.9381,\t Train Loss : 11322.988158367323, \tValid Loss :  2843.490116700129, \t Time for 1000 Epochs: 0.8659358469885774\n",
      "Epoch 896999 : Train Accuracy : 0.94268, \tValid  Accuracy : 0.9357,\t Train Loss : 12559.473518299355, \tValid Loss :  3198.970738311729, \t Time for 1000 Epochs: 0.7900570720084943\n",
      "Epoch 897999 : Train Accuracy : 0.92472, \tValid  Accuracy : 0.9222,\t Train Loss : 19502.712903912012, \tValid Loss :  4240.831849698799, \t Time for 1000 Epochs: 0.7739865060138982\n",
      "Epoch 898999 : Train Accuracy : 0.92704, \tValid  Accuracy : 0.9237,\t Train Loss : 17317.292718339515, \tValid Loss :  3991.9549475633416, \t Time for 1000 Epochs: 0.7749535810144152\n",
      "Epoch 899999 : Train Accuracy : 0.94158, \tValid  Accuracy : 0.9348,\t Train Loss : 11044.70025901388, \tValid Loss :  2971.9714170777484, \t Time for 1000 Epochs: 0.8680728089821059\n",
      "Epoch 900999 : Train Accuracy : 0.91294, \tValid  Accuracy : 0.9111,\t Train Loss : 15562.374129919695, \tValid Loss :  3851.541927550288, \t Time for 1000 Epochs: 0.7849678870115895\n",
      "Epoch 901999 : Train Accuracy : 0.92124, \tValid  Accuracy : 0.9175,\t Train Loss : 16783.221955403857, \tValid Loss :  3869.499849544214, \t Time for 1000 Epochs: 0.944510089000687\n",
      "Epoch 902999 : Train Accuracy : 0.9007, \tValid  Accuracy : 0.8995,\t Train Loss : 20061.777160834663, \tValid Loss :  4544.651947552184, \t Time for 1000 Epochs: 0.9177204229927156\n",
      "Epoch 903999 : Train Accuracy : 0.91852, \tValid  Accuracy : 0.9149,\t Train Loss : 14180.036634722761, \tValid Loss :  3317.0440441270393, \t Time for 1000 Epochs: 0.884693692001747\n",
      "Epoch 904999 : Train Accuracy : 0.9167, \tValid  Accuracy : 0.9126,\t Train Loss : 14963.916223982358, \tValid Loss :  3544.0235119869635, \t Time for 1000 Epochs: 0.8755715230072383\n",
      "Epoch 905999 : Train Accuracy : 0.89278, \tValid  Accuracy : 0.8872,\t Train Loss : 17999.77177382001, \tValid Loss :  4511.886371701617, \t Time for 1000 Epochs: 0.7725337060110178\n",
      "Epoch 906999 : Train Accuracy : 0.91822, \tValid  Accuracy : 0.9138,\t Train Loss : 14818.550217562346, \tValid Loss :  3522.647212130022, \t Time for 1000 Epochs: 0.8583351750276051\n",
      "Epoch 907999 : Train Accuracy : 0.92576, \tValid  Accuracy : 0.918,\t Train Loss : 14141.385133316671, \tValid Loss :  3617.9343155023703, \t Time for 1000 Epochs: 0.8706755050225183\n",
      "Epoch 908999 : Train Accuracy : 0.92112, \tValid  Accuracy : 0.9149,\t Train Loss : 14292.717818066718, \tValid Loss :  3561.3833362018504, \t Time for 1000 Epochs: 0.7806049859791528\n",
      "Epoch 909999 : Train Accuracy : 0.92998, \tValid  Accuracy : 0.9232,\t Train Loss : 13063.112304755652, \tValid Loss :  3209.866579402076, \t Time for 1000 Epochs: 0.861809219000861\n",
      "Epoch 910999 : Train Accuracy : 0.88434, \tValid  Accuracy : 0.8822,\t Train Loss : 19817.141667687447, \tValid Loss :  4396.3851728630325, \t Time for 1000 Epochs: 0.8809643640124705\n",
      "Epoch 911999 : Train Accuracy : 0.9196, \tValid  Accuracy : 0.9157,\t Train Loss : 14667.984725508584, \tValid Loss :  3355.2007991545634, \t Time for 1000 Epochs: 0.8623997770191636\n",
      "Epoch 912999 : Train Accuracy : 0.92402, \tValid  Accuracy : 0.9182,\t Train Loss : 14751.973962895789, \tValid Loss :  3544.398050010566, \t Time for 1000 Epochs: 0.8927323419775348\n",
      "Epoch 913999 : Train Accuracy : 0.94624, \tValid  Accuracy : 0.939,\t Train Loss : 12069.73518808452, \tValid Loss :  3041.9904549812054, \t Time for 1000 Epochs: 0.93363418901572\n",
      "Epoch 914999 : Train Accuracy : 0.94316, \tValid  Accuracy : 0.9371,\t Train Loss : 11261.603581855934, \tValid Loss :  2800.6043880310144, \t Time for 1000 Epochs: 0.9164097530010622\n",
      "Epoch 915999 : Train Accuracy : 0.94214, \tValid  Accuracy : 0.9378,\t Train Loss : 11535.037669676442, \tValid Loss :  2943.584508285847, \t Time for 1000 Epochs: 0.8010665740002878\n",
      "Epoch 916999 : Train Accuracy : 0.92398, \tValid  Accuracy : 0.9168,\t Train Loss : 14533.531045011357, \tValid Loss :  3380.987777774103, \t Time for 1000 Epochs: 0.798918656015303\n",
      "Epoch 917999 : Train Accuracy : 0.91366, \tValid  Accuracy : 0.9081,\t Train Loss : 16801.235028459792, \tValid Loss :  4036.5712383373566, \t Time for 1000 Epochs: 0.8602203300106339\n",
      "Epoch 918999 : Train Accuracy : 0.93184, \tValid  Accuracy : 0.9267,\t Train Loss : 13060.461087190863, \tValid Loss :  3172.141030706327, \t Time for 1000 Epochs: 0.862810103019001\n",
      "Epoch 919999 : Train Accuracy : 0.94024, \tValid  Accuracy : 0.933,\t Train Loss : 11694.146360579847, \tValid Loss :  2880.5304382088348, \t Time for 1000 Epochs: 0.7737165750004351\n",
      "Epoch 920999 : Train Accuracy : 0.9318, \tValid  Accuracy : 0.925,\t Train Loss : 14572.887157250207, \tValid Loss :  3493.558540445502, \t Time for 1000 Epochs: 0.7775889290205669\n",
      "Epoch 921999 : Train Accuracy : 0.9443, \tValid  Accuracy : 0.9358,\t Train Loss : 11590.547734063779, \tValid Loss :  3107.780934068351, \t Time for 1000 Epochs: 0.8865961160045117\n",
      "Epoch 922999 : Train Accuracy : 0.93142, \tValid  Accuracy : 0.9241,\t Train Loss : 12544.334878535634, \tValid Loss :  3237.3161958432356, \t Time for 1000 Epochs: 0.782881894003367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 923999 : Train Accuracy : 0.94744, \tValid  Accuracy : 0.9384,\t Train Loss : 11079.583171695054, \tValid Loss :  3013.3462136269563, \t Time for 1000 Epochs: 0.8676544149930123\n",
      "Epoch 924999 : Train Accuracy : 0.94914, \tValid  Accuracy : 0.9419,\t Train Loss : 10678.959915047966, \tValid Loss :  2976.268583547382, \t Time for 1000 Epochs: 0.8727397290058434\n",
      "Epoch 925999 : Train Accuracy : 0.9513, \tValid  Accuracy : 0.9426,\t Train Loss : 11992.809975451355, \tValid Loss :  3189.9252918548714, \t Time for 1000 Epochs: 0.7805725249927491\n",
      "Epoch 926999 : Train Accuracy : 0.94516, \tValid  Accuracy : 0.9381,\t Train Loss : 11502.07579222522, \tValid Loss :  3227.0153863390606, \t Time for 1000 Epochs: 0.8665875809965655\n",
      "Epoch 927999 : Train Accuracy : 0.95196, \tValid  Accuracy : 0.9427,\t Train Loss : 9573.793496206272, \tValid Loss :  2770.5758198440226, \t Time for 1000 Epochs: 0.8325533389870543\n",
      "Epoch 928999 : Train Accuracy : 0.95346, \tValid  Accuracy : 0.9431,\t Train Loss : 11561.31839406967, \tValid Loss :  3163.3777927267233, \t Time for 1000 Epochs: 0.8014710340066813\n",
      "Epoch 929999 : Train Accuracy : 0.95308, \tValid  Accuracy : 0.9422,\t Train Loss : 9393.046323391245, \tValid Loss :  2634.4904955402867, \t Time for 1000 Epochs: 0.8952159790205769\n",
      "Epoch 930999 : Train Accuracy : 0.94902, \tValid  Accuracy : 0.9411,\t Train Loss : 10495.514566307382, \tValid Loss :  2809.7630253318016, \t Time for 1000 Epochs: 0.7759834400203545\n",
      "Epoch 931999 : Train Accuracy : 0.9571, \tValid  Accuracy : 0.9493,\t Train Loss : 9341.111374412541, \tValid Loss :  2716.4897835087127, \t Time for 1000 Epochs: 0.8715606660116464\n",
      "Epoch 932999 : Train Accuracy : 0.9557, \tValid  Accuracy : 0.9493,\t Train Loss : 9216.360632991253, \tValid Loss :  2606.3875802401403, \t Time for 1000 Epochs: 0.7774538020021282\n",
      "Epoch 933999 : Train Accuracy : 0.95252, \tValid  Accuracy : 0.9449,\t Train Loss : 10398.299064726976, \tValid Loss :  2867.4187605034713, \t Time for 1000 Epochs: 0.8706515879894141\n",
      "Epoch 934999 : Train Accuracy : 0.93922, \tValid  Accuracy : 0.9329,\t Train Loss : 11042.70617658454, \tValid Loss :  2858.8820608883016, \t Time for 1000 Epochs: 0.8700186390196905\n",
      "Epoch 935999 : Train Accuracy : 0.94668, \tValid  Accuracy : 0.9373,\t Train Loss : 11501.366924896363, \tValid Loss :  3043.091709743353, \t Time for 1000 Epochs: 0.8698318859969731\n",
      "Epoch 936999 : Train Accuracy : 0.94162, \tValid  Accuracy : 0.9344,\t Train Loss : 15921.78730267552, \tValid Loss :  3838.6982804840727, \t Time for 1000 Epochs: 0.8695198759960476\n",
      "Epoch 937999 : Train Accuracy : 0.92846, \tValid  Accuracy : 0.9216,\t Train Loss : 20321.845001244263, \tValid Loss :  5130.913491995444, \t Time for 1000 Epochs: 0.7789153219782747\n",
      "Epoch 938999 : Train Accuracy : 0.92988, \tValid  Accuracy : 0.922,\t Train Loss : 12204.85695397863, \tValid Loss :  3208.0951362437713, \t Time for 1000 Epochs: 0.8866183999925852\n",
      "Epoch 939999 : Train Accuracy : 0.93554, \tValid  Accuracy : 0.9297,\t Train Loss : 15336.162751265463, \tValid Loss :  3852.3509693023566, \t Time for 1000 Epochs: 0.9332160420017317\n",
      "Epoch 940999 : Train Accuracy : 0.94954, \tValid  Accuracy : 0.9437,\t Train Loss : 12358.427856992994, \tValid Loss :  3282.0948328262057, \t Time for 1000 Epochs: 0.9084656259801704\n",
      "Epoch 941999 : Train Accuracy : 0.93258, \tValid  Accuracy : 0.9271,\t Train Loss : 12854.852096315915, \tValid Loss :  3168.0701751616357, \t Time for 1000 Epochs: 0.8883495350019075\n",
      "Epoch 942999 : Train Accuracy : 0.9381, \tValid  Accuracy : 0.9314,\t Train Loss : 11880.876570400647, \tValid Loss :  2977.213819539199, \t Time for 1000 Epochs: 0.8715819499921054\n",
      "Epoch 943999 : Train Accuracy : 0.93154, \tValid  Accuracy : 0.9257,\t Train Loss : 14288.10655875547, \tValid Loss :  3437.369891676125, \t Time for 1000 Epochs: 0.8615533229894936\n",
      "Epoch 944999 : Train Accuracy : 0.9344, \tValid  Accuracy : 0.9286,\t Train Loss : 12017.512178817791, \tValid Loss :  3009.938258566795, \t Time for 1000 Epochs: 0.8704178659827448\n",
      "Epoch 945999 : Train Accuracy : 0.94062, \tValid  Accuracy : 0.9365,\t Train Loss : 11409.430192717671, \tValid Loss :  2878.079204000272, \t Time for 1000 Epochs: 0.8685191810072865\n",
      "Epoch 946999 : Train Accuracy : 0.92168, \tValid  Accuracy : 0.9103,\t Train Loss : 12675.112885259448, \tValid Loss :  3237.30075959841, \t Time for 1000 Epochs: 0.7766459369740915\n",
      "Epoch 947999 : Train Accuracy : 0.93818, \tValid  Accuracy : 0.9317,\t Train Loss : 11107.546658670639, \tValid Loss :  3076.8168032041303, \t Time for 1000 Epochs: 0.8921425099833868\n",
      "Epoch 948999 : Train Accuracy : 0.93528, \tValid  Accuracy : 0.9295,\t Train Loss : 13020.206047034108, \tValid Loss :  3468.8457487756964, \t Time for 1000 Epochs: 0.86931540700607\n",
      "Epoch 949999 : Train Accuracy : 0.94176, \tValid  Accuracy : 0.9332,\t Train Loss : 10406.741979617342, \tValid Loss :  2894.915942823279, \t Time for 1000 Epochs: 0.7718187260034028\n",
      "Epoch 950999 : Train Accuracy : 0.94396, \tValid  Accuracy : 0.9374,\t Train Loss : 11255.135494034166, \tValid Loss :  2968.6646651481187, \t Time for 1000 Epochs: 0.7858695730101317\n",
      "Epoch 951999 : Train Accuracy : 0.91634, \tValid  Accuracy : 0.9162,\t Train Loss : 14280.233847488918, \tValid Loss :  3341.953569919482, \t Time for 1000 Epochs: 0.8162854310066905\n",
      "Epoch 952999 : Train Accuracy : 0.9051, \tValid  Accuracy : 0.905,\t Train Loss : 17383.451573240167, \tValid Loss :  3899.7776978451816, \t Time for 1000 Epochs: 0.9310899119882379\n",
      "Epoch 953999 : Train Accuracy : 0.91114, \tValid  Accuracy : 0.9055,\t Train Loss : 16530.6700063703, \tValid Loss :  3800.6065910001157, \t Time for 1000 Epochs: 0.8920347730163485\n",
      "Epoch 954999 : Train Accuracy : 0.9227, \tValid  Accuracy : 0.9165,\t Train Loss : 14026.952434851224, \tValid Loss :  3514.354505778916, \t Time for 1000 Epochs: 0.8705558349902276\n",
      "Epoch 955999 : Train Accuracy : 0.92936, \tValid  Accuracy : 0.9245,\t Train Loss : 12613.835097266689, \tValid Loss :  3125.1798425044017, \t Time for 1000 Epochs: 0.7837327460001688\n",
      "Epoch 956999 : Train Accuracy : 0.9369, \tValid  Accuracy : 0.9318,\t Train Loss : 11547.803858539937, \tValid Loss :  2957.4743871852816, \t Time for 1000 Epochs: 0.862781983014429\n",
      "Epoch 957999 : Train Accuracy : 0.9392, \tValid  Accuracy : 0.9314,\t Train Loss : 11272.829173535736, \tValid Loss :  3045.2018450721152, \t Time for 1000 Epochs: 0.8698041820025537\n",
      "Epoch 958999 : Train Accuracy : 0.94458, \tValid  Accuracy : 0.9386,\t Train Loss : 10015.395889187133, \tValid Loss :  2819.1185142153204, \t Time for 1000 Epochs: 0.7798037829925306\n",
      "Epoch 959999 : Train Accuracy : 0.93774, \tValid  Accuracy : 0.9303,\t Train Loss : 13827.016063590147, \tValid Loss :  3452.5004988454743, \t Time for 1000 Epochs: 0.7733686749998014\n",
      "Epoch 960999 : Train Accuracy : 0.9331, \tValid  Accuracy : 0.9285,\t Train Loss : 14901.490039562555, \tValid Loss :  3658.7894292425394, \t Time for 1000 Epochs: 0.8704903939797077\n",
      "Epoch 961999 : Train Accuracy : 0.9362, \tValid  Accuracy : 0.9316,\t Train Loss : 13220.10398791952, \tValid Loss :  3364.8297363671163, \t Time for 1000 Epochs: 0.8738601280201692\n",
      "Epoch 962999 : Train Accuracy : 0.92894, \tValid  Accuracy : 0.923,\t Train Loss : 15223.410348280015, \tValid Loss :  3604.662869515254, \t Time for 1000 Epochs: 0.7772684360097628\n",
      "Epoch 963999 : Train Accuracy : 0.94816, \tValid  Accuracy : 0.9398,\t Train Loss : 9953.867899991907, \tValid Loss :  2724.909269316977, \t Time for 1000 Epochs: 0.8664550349931233\n",
      "Epoch 964999 : Train Accuracy : 0.94612, \tValid  Accuracy : 0.9393,\t Train Loss : 10506.465138219235, \tValid Loss :  2781.765260006556, \t Time for 1000 Epochs: 0.9311379469872918\n",
      "Epoch 965999 : Train Accuracy : 0.93448, \tValid  Accuracy : 0.9299,\t Train Loss : 14332.292230544901, \tValid Loss :  3443.3777893964625, \t Time for 1000 Epochs: 0.8519487509911414\n",
      "Epoch 966999 : Train Accuracy : 0.95116, \tValid  Accuracy : 0.9456,\t Train Loss : 11973.87680983718, \tValid Loss :  2984.5317793423173, \t Time for 1000 Epochs: 0.8045555129938293\n",
      "Epoch 967999 : Train Accuracy : 0.9466, \tValid  Accuracy : 0.9393,\t Train Loss : 13107.52414641917, \tValid Loss :  3380.5609809916223, \t Time for 1000 Epochs: 0.8137260029907338\n",
      "Epoch 968999 : Train Accuracy : 0.94958, \tValid  Accuracy : 0.9419,\t Train Loss : 12062.031172221088, \tValid Loss :  3420.18518409027, \t Time for 1000 Epochs: 0.7919476489769295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 969999 : Train Accuracy : 0.91562, \tValid  Accuracy : 0.9071,\t Train Loss : 19681.259447727392, \tValid Loss :  5044.789106242224, \t Time for 1000 Epochs: 0.7791599570191465\n",
      "Epoch 970999 : Train Accuracy : 0.93736, \tValid  Accuracy : 0.934,\t Train Loss : 13414.425251544637, \tValid Loss :  3334.043324385448, \t Time for 1000 Epochs: 0.8729736050008796\n",
      "Epoch 971999 : Train Accuracy : 0.9073, \tValid  Accuracy : 0.9024,\t Train Loss : 15694.928701922887, \tValid Loss :  3734.6713934223367, \t Time for 1000 Epochs: 0.7760609399992973\n",
      "Epoch 972999 : Train Accuracy : 0.93838, \tValid  Accuracy : 0.9355,\t Train Loss : 11894.319719886027, \tValid Loss :  2800.662539833272, \t Time for 1000 Epochs: 0.8752044230059255\n",
      "Epoch 973999 : Train Accuracy : 0.94674, \tValid  Accuracy : 0.9408,\t Train Loss : 12084.832934490922, \tValid Loss :  3113.3468706499248, \t Time for 1000 Epochs: 0.8878025370067917\n",
      "Epoch 974999 : Train Accuracy : 0.9401, \tValid  Accuracy : 0.9328,\t Train Loss : 11969.722285482745, \tValid Loss :  3022.8869177351185, \t Time for 1000 Epochs: 0.7803874980018009\n",
      "Epoch 975999 : Train Accuracy : 0.95246, \tValid  Accuracy : 0.9441,\t Train Loss : 10086.548066908466, \tValid Loss :  2773.1448591546364, \t Time for 1000 Epochs: 0.7813832829997409\n",
      "Epoch 976999 : Train Accuracy : 0.9411, \tValid  Accuracy : 0.9345,\t Train Loss : 10866.100811114611, \tValid Loss :  2778.466989290726, \t Time for 1000 Epochs: 0.7810686980083119\n",
      "Epoch 977999 : Train Accuracy : 0.9457, \tValid  Accuracy : 0.9398,\t Train Loss : 10606.828098651413, \tValid Loss :  2918.086630936281, \t Time for 1000 Epochs: 0.8490668860031292\n",
      "Epoch 978999 : Train Accuracy : 0.9522, \tValid  Accuracy : 0.9453,\t Train Loss : 10009.579211922483, \tValid Loss :  2523.5943316222915, \t Time for 1000 Epochs: 0.8355775459785946\n",
      "Epoch 979999 : Train Accuracy : 0.94964, \tValid  Accuracy : 0.9434,\t Train Loss : 10089.901455461724, \tValid Loss :  2596.9731268226915, \t Time for 1000 Epochs: 0.8123886730172671\n",
      "Epoch 980999 : Train Accuracy : 0.94758, \tValid  Accuracy : 0.939,\t Train Loss : 10670.578922806853, \tValid Loss :  2778.5353154182603, \t Time for 1000 Epochs: 0.7923390269861557\n",
      "Epoch 981999 : Train Accuracy : 0.95096, \tValid  Accuracy : 0.9427,\t Train Loss : 10542.44986244659, \tValid Loss :  2804.8495062033503, \t Time for 1000 Epochs: 0.7803896929835901\n",
      "Epoch 982999 : Train Accuracy : 0.94892, \tValid  Accuracy : 0.9404,\t Train Loss : 10058.179554410424, \tValid Loss :  2658.011680209648, \t Time for 1000 Epochs: 0.7810576409974601\n",
      "Epoch 983999 : Train Accuracy : 0.95224, \tValid  Accuracy : 0.9458,\t Train Loss : 9629.800480540305, \tValid Loss :  2579.983318801691, \t Time for 1000 Epochs: 0.8086208289896604\n",
      "Epoch 984999 : Train Accuracy : 0.9354, \tValid  Accuracy : 0.9292,\t Train Loss : 12737.190992219574, \tValid Loss :  3200.073923932589, \t Time for 1000 Epochs: 0.7788025699846912\n",
      "Epoch 985999 : Train Accuracy : 0.86492, \tValid  Accuracy : 0.8563,\t Train Loss : 66020.97818098114, \tValid Loss :  14193.741763447273, \t Time for 1000 Epochs: 0.8699897869955748\n",
      "Epoch 986999 : Train Accuracy : 0.94108, \tValid  Accuracy : 0.9358,\t Train Loss : 12962.733536125703, \tValid Loss :  3180.066290675675, \t Time for 1000 Epochs: 0.7823727329960093\n",
      "Epoch 987999 : Train Accuracy : 0.94832, \tValid  Accuracy : 0.9411,\t Train Loss : 11035.31838452117, \tValid Loss :  2848.4630892896703, \t Time for 1000 Epochs: 0.7821971649827901\n",
      "Epoch 988999 : Train Accuracy : 0.94712, \tValid  Accuracy : 0.9398,\t Train Loss : 10682.845626843466, \tValid Loss :  2807.936085745326, \t Time for 1000 Epochs: 0.7814553859934676\n",
      "Epoch 989999 : Train Accuracy : 0.95366, \tValid  Accuracy : 0.9444,\t Train Loss : 9491.834317820083, \tValid Loss :  2635.068735075872, \t Time for 1000 Epochs: 0.8747736859950237\n",
      "Epoch 990999 : Train Accuracy : 0.91422, \tValid  Accuracy : 0.9098,\t Train Loss : 12695.837149603058, \tValid Loss :  3205.7201536647426, \t Time for 1000 Epochs: 0.7993540290044621\n",
      "Epoch 991999 : Train Accuracy : 0.92508, \tValid  Accuracy : 0.916,\t Train Loss : 13108.232066455133, \tValid Loss :  3485.1857098478145, \t Time for 1000 Epochs: 0.9255789830058347\n",
      "Epoch 992999 : Train Accuracy : 0.94218, \tValid  Accuracy : 0.9336,\t Train Loss : 11032.87947347727, \tValid Loss :  2911.868039569779, \t Time for 1000 Epochs: 0.9079626279999502\n",
      "Epoch 993999 : Train Accuracy : 0.94592, \tValid  Accuracy : 0.9391,\t Train Loss : 9200.988701554785, \tValid Loss :  2615.4330853527, \t Time for 1000 Epochs: 0.8044275349820964\n",
      "Epoch 994999 : Train Accuracy : 0.95224, \tValid  Accuracy : 0.9429,\t Train Loss : 11428.983873689564, \tValid Loss :  3224.306791610985, \t Time for 1000 Epochs: 0.7956042360165156\n",
      "Epoch 995999 : Train Accuracy : 0.95156, \tValid  Accuracy : 0.9399,\t Train Loss : 9700.811964725197, \tValid Loss :  2816.5249716919866, \t Time for 1000 Epochs: 0.7867179790046066\n",
      "Epoch 996999 : Train Accuracy : 0.95184, \tValid  Accuracy : 0.942,\t Train Loss : 9523.082199195227, \tValid Loss :  2749.094762864191, \t Time for 1000 Epochs: 0.8097666029934771\n",
      "Epoch 997999 : Train Accuracy : 0.94742, \tValid  Accuracy : 0.9396,\t Train Loss : 9820.673749016229, \tValid Loss :  2760.8326919065203, \t Time for 1000 Epochs: 0.789179568993859\n",
      "Epoch 998999 : Train Accuracy : 0.9503, \tValid  Accuracy : 0.9412,\t Train Loss : 9652.426836190896, \tValid Loss :  2708.576044240345, \t Time for 1000 Epochs: 0.7780346960062161\n",
      "Epoch 999999 : Train Accuracy : 0.94272, \tValid  Accuracy : 0.9343,\t Train Loss : 10874.033763632378, \tValid Loss :  2934.6241167084195, \t Time for 1000 Epochs: 0.7864933859964367\n"
     ]
    }
   ],
   "source": [
    "trainLogSG = train_loopSG(1000000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les modification pour le Finite Difference Algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À chaque itération, nous passons à travers toutes les paires de données de l'ensemble d'apprentissage pour calculer le gradient idéal moyen. La totalité du gradient est calculée à chaque itération avec la backpropagation et les weights (et biais) sont modifiés en fonction de ce gradient moyen après avoir passé à travers toutes les données de l'ensemble d'entrainement. Le coût d'itérations est donc en fonction de la taille de cet ensemble, $O(n)$. Le taux de convergence est cependant meilleur avec tout de même de $O(p^k)$, pour $0<p<1$, par itération (taux de convergence linéaire)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loopFD(n_epochs):\n",
    "    train_logs = {'train_accuracyFD': [], 'validation_accuracyFD': [], 'train_lossFD': [], 'validation_lossFD': [], 'time': []}\n",
    "    X_train, y_train = train\n",
    "    y_onehot = y_train\n",
    "    dims = [X_train.shape[1], y_onehot.shape[1]]\n",
    "    hidden_dims = hidden_dims = (64, 32)\n",
    "    weights = initialize_weights(dims, hidden_dims)\n",
    "    batch_size = 1\n",
    "    alpha = 0.1099\n",
    "    n_batches = 50000\n",
    "    previousLoss = 2147483647 # Le plus grand integer possible (python)\n",
    "    for epoch in range(n_epochs):\n",
    "        start = timeit.default_timer()\n",
    "        #  Selection d'un index aléatoire dépendament du nombre de donnée dans le training data.\n",
    "        gradsS = {}\n",
    "        for i in range(n_batches):  # La grosseur du training set.\n",
    "            batchX = X_train[batch_size * i:batch_size * (i + 1), :]\n",
    "            batchY = y_onehot[batch_size * i:batch_size * (i + 1), :]\n",
    "            # print(batchX.shape)\n",
    "            # print(batchY.shape)\n",
    "            cache = forward(batchX, weights, hidden_dims)\n",
    "            grads = backward(weights, cache, batchY, hidden_dims)\n",
    "\n",
    "            # Pour tous les éléments, les additionner pour pouvoir diviser et obtenir la moyenne.\n",
    "            # Si pas la première itération, additionner les nouveaux grads,\n",
    "            if i != 0:\n",
    "                gradsS['dW3'] += grads[\"dW3\"]\n",
    "                gradsS[\"dW2\"] += grads[\"dW2\"]\n",
    "                gradsS[\"dW1\"] += grads[\"dW1\"]\n",
    "                gradsS[\"db3\"] += grads[\"db3\"]\n",
    "                gradsS[\"db2\"] += grads[\"db2\"]\n",
    "                gradsS[\"db1\"] += grads[\"db1\"]\n",
    "            # Si la première itérations, initialiser les gradients avec les gradients respectifs.\n",
    "            else:\n",
    "                gradsS['dW3'] = grads[\"dW3\"]\n",
    "                gradsS[\"dW2\"] = grads[\"dW2\"]\n",
    "                gradsS[\"dW1\"] = grads[\"dW1\"]\n",
    "                gradsS[\"db3\"] = grads[\"db3\"]\n",
    "                gradsS[\"db2\"] = grads[\"db2\"]\n",
    "                gradsS[\"db1\"] = grads[\"db1\"]\n",
    "        # Diviser pour obtenir la moyenne de chaque gradients.\n",
    "        gradsS['dW3'] = gradsS[\"dW3\"] * 1 / n_batches\n",
    "        gradsS[\"dW2\"] = gradsS[\"dW2\"] * 1 / n_batches\n",
    "        gradsS[\"dW1\"] = gradsS[\"dW1\"] * 1 / n_batches\n",
    "        gradsS[\"db3\"] = gradsS[\"db3\"] * 1 / n_batches\n",
    "        gradsS[\"db2\"] = gradsS[\"db2\"] * 1 / n_batches\n",
    "        gradsS[\"db1\"] = gradsS[\"db1\"] * 1 / n_batches\n",
    "\n",
    "        # Updater les weights.\n",
    "        weights = update(gradsS, weights, hidden_dims, alpha)\n",
    "\n",
    "        X_train, y_train = train\n",
    "        train_loss, train_accuracy, _ = compute_loss_and_accuracy(X_train, y_train, weights, hidden_dims)\n",
    "        X_valid, y_valid = valid\n",
    "        valid_loss, valid_accuracy, _ = compute_loss_and_accuracy(X_valid, y_valid, weights, hidden_dims)\n",
    "\n",
    "        stop = timeit.default_timer()\n",
    "\n",
    "        # Imprimer la loss et la precision. Ça l'aide a suivre le progrès\n",
    "        print(f\"Epoch {epoch} : Train Accuracy : {train_accuracy}, \\tValid  Accuracy : {valid_accuracy},\\t Train Loss : {train_loss}, \\tValid Loss :  {valid_loss} , Time : {stop - start}\")\n",
    "        \n",
    "        # Ajuster le taux d'apprentissage si pas de déscente\n",
    "        if train_loss > previousLoss:\n",
    "            alpha  = alpha  *  .975\n",
    "        previousLoss = train_loss\n",
    "        train_logs['train_accuracyFD'].append(train_accuracy)\n",
    "        train_logs['validation_accuracyFD'].append(valid_accuracy)\n",
    "        train_logs['train_lossFD'].append(train_loss)\n",
    "        train_logs['validation_lossFD'].append(valid_loss)\n",
    "        train_logs['time'].append(stop - start)\n",
    "\n",
    "    return train_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Train Accuracy : 0.13602, \tValid  Accuracy : 0.1301,\t Train Loss : 115658.6675690525, \tValid Loss :  23131.366976003766 , Time : 13.57142488300451\n",
      "Epoch 1 : Train Accuracy : 0.17352, \tValid  Accuracy : 0.1708,\t Train Loss : 113569.04532514424, \tValid Loss :  22716.53910075077 , Time : 15.282209564989898\n",
      "Epoch 2 : Train Accuracy : 0.20442, \tValid  Accuracy : 0.2026,\t Train Loss : 111823.409157642, \tValid Loss :  22367.97846762275 , Time : 13.309911374992225\n",
      "Epoch 3 : Train Accuracy : 0.23288, \tValid  Accuracy : 0.2312,\t Train Loss : 110208.84476288529, \tValid Loss :  22044.886378383824 , Time : 12.375716127018677\n",
      "Epoch 4 : Train Accuracy : 0.2607, \tValid  Accuracy : 0.2569,\t Train Loss : 108604.88520980599, \tValid Loss :  21723.23309548002 , Time : 11.491972374002216\n",
      "Epoch 5 : Train Accuracy : 0.28388, \tValid  Accuracy : 0.2837,\t Train Loss : 106936.87651332561, \tValid Loss :  21388.54565282308 , Time : 13.270202354004141\n",
      "Epoch 6 : Train Accuracy : 0.3041, \tValid  Accuracy : 0.3049,\t Train Loss : 105159.73672948862, \tValid Loss :  21031.51378563437 , Time : 13.221261850994779\n",
      "Epoch 7 : Train Accuracy : 0.32334, \tValid  Accuracy : 0.3254,\t Train Loss : 103223.62380625351, \tValid Loss :  20642.67252946852 , Time : 14.068814956990536\n",
      "Epoch 8 : Train Accuracy : 0.3429, \tValid  Accuracy : 0.3458,\t Train Loss : 101083.9390927268, \tValid Loss :  20209.640275087375 , Time : 11.50174881098792\n",
      "Epoch 9 : Train Accuracy : 0.36372, \tValid  Accuracy : 0.369,\t Train Loss : 98780.40489679792, \tValid Loss :  19743.021201799987 , Time : 15.293973919004202\n",
      "Epoch 10 : Train Accuracy : 0.38484, \tValid  Accuracy : 0.391,\t Train Loss : 96396.24970647015, \tValid Loss :  19257.576574409824 , Time : 13.867787334980676\n",
      "Epoch 11 : Train Accuracy : 0.4029, \tValid  Accuracy : 0.4125,\t Train Loss : 93991.15396866878, \tValid Loss :  18764.749908182457 , Time : 16.628168566996465\n",
      "Epoch 12 : Train Accuracy : 0.4195, \tValid  Accuracy : 0.4294,\t Train Loss : 91582.38870025204, \tValid Loss :  18270.444943449118 , Time : 11.990939928014996\n",
      "Epoch 13 : Train Accuracy : 0.43592, \tValid  Accuracy : 0.447,\t Train Loss : 89180.23534411463, \tValid Loss :  17776.966365444885 , Time : 10.807975033007096\n",
      "Epoch 14 : Train Accuracy : 0.4548, \tValid  Accuracy : 0.4653,\t Train Loss : 86791.50456093981, \tValid Loss :  17285.70042461099 , Time : 10.774932405009167\n",
      "Epoch 15 : Train Accuracy : 0.47346, \tValid  Accuracy : 0.4881,\t Train Loss : 84417.33275202791, \tValid Loss :  16797.443080399196 , Time : 11.08413343099528\n",
      "Epoch 16 : Train Accuracy : 0.49592, \tValid  Accuracy : 0.5121,\t Train Loss : 82060.75994918808, \tValid Loss :  16313.141858507666 , Time : 10.605025619006483\n",
      "Epoch 17 : Train Accuracy : 0.51958, \tValid  Accuracy : 0.5343,\t Train Loss : 79723.74862065409, \tValid Loss :  15833.630437836582 , Time : 12.175519756012363\n",
      "Epoch 18 : Train Accuracy : 0.54486, \tValid  Accuracy : 0.5609,\t Train Loss : 77408.74400723551, \tValid Loss :  15358.907179130032 , Time : 12.954308524989756\n",
      "Epoch 19 : Train Accuracy : 0.57242, \tValid  Accuracy : 0.5894,\t Train Loss : 75119.94625377565, \tValid Loss :  14889.434485821248 , Time : 11.722677868005121\n",
      "Epoch 20 : Train Accuracy : 0.59696, \tValid  Accuracy : 0.6145,\t Train Loss : 72866.2778698466, \tValid Loss :  14426.484211644663 , Time : 12.192516857001465\n",
      "Epoch 21 : Train Accuracy : 0.61944, \tValid  Accuracy : 0.6359,\t Train Loss : 70658.47741639164, \tValid Loss :  13972.348153265459 , Time : 11.338756768003805\n",
      "Epoch 22 : Train Accuracy : 0.63972, \tValid  Accuracy : 0.6573,\t Train Loss : 68509.21991715983, \tValid Loss :  13529.827529977136 , Time : 12.609257553005591\n",
      "Epoch 23 : Train Accuracy : 0.65646, \tValid  Accuracy : 0.675,\t Train Loss : 66434.15676511121, \tValid Loss :  13101.713490717275 , Time : 12.100438151013805\n",
      "Epoch 24 : Train Accuracy : 0.6712, \tValid  Accuracy : 0.6865,\t Train Loss : 64441.97086975494, \tValid Loss :  12689.866601662761 , Time : 13.668353532004403\n",
      "Epoch 25 : Train Accuracy : 0.68346, \tValid  Accuracy : 0.6983,\t Train Loss : 62537.654167489076, \tValid Loss :  12295.71199927016 , Time : 13.004492753010709\n",
      "Epoch 26 : Train Accuracy : 0.69398, \tValid  Accuracy : 0.7094,\t Train Loss : 60726.038194410125, \tValid Loss :  11919.974853449186 , Time : 11.631808470003307\n",
      "Epoch 27 : Train Accuracy : 0.7037, \tValid  Accuracy : 0.7206,\t Train Loss : 59007.45090744128, \tValid Loss :  11563.059157894366 , Time : 11.927894060005201\n",
      "Epoch 28 : Train Accuracy : 0.71154, \tValid  Accuracy : 0.7295,\t Train Loss : 57378.49056463997, \tValid Loss :  11224.540291708814 , Time : 12.991816402995028\n",
      "Epoch 29 : Train Accuracy : 0.71874, \tValid  Accuracy : 0.7362,\t Train Loss : 55837.26531312131, \tValid Loss :  10904.237857958009 , Time : 14.346077346010134\n",
      "Epoch 30 : Train Accuracy : 0.72578, \tValid  Accuracy : 0.7444,\t Train Loss : 54377.94773445535, \tValid Loss :  10600.954199511376 , Time : 13.782440473005408\n",
      "Epoch 31 : Train Accuracy : 0.73228, \tValid  Accuracy : 0.7519,\t Train Loss : 52995.45086784151, \tValid Loss :  10313.49576823477 , Time : 12.997661514993524\n",
      "Epoch 32 : Train Accuracy : 0.73836, \tValid  Accuracy : 0.7591,\t Train Loss : 51684.24962616028, \tValid Loss :  10040.849620936617 , Time : 17.601501032011583\n",
      "Epoch 33 : Train Accuracy : 0.7445, \tValid  Accuracy : 0.7661,\t Train Loss : 50439.69754294966, \tValid Loss :  9782.035305975483 , Time : 12.278729854995618\n",
      "Epoch 34 : Train Accuracy : 0.7504, \tValid  Accuracy : 0.7734,\t Train Loss : 49257.1310835186, \tValid Loss :  9536.099795972883 , Time : 16.2697387879889\n",
      "Epoch 35 : Train Accuracy : 0.75594, \tValid  Accuracy : 0.7788,\t Train Loss : 48132.03326936943, \tValid Loss :  9302.261168028599 , Time : 20.519046191009693\n",
      "Epoch 36 : Train Accuracy : 0.76124, \tValid  Accuracy : 0.7834,\t Train Loss : 47059.87560538302, \tValid Loss :  9079.668617886815 , Time : 18.914456249010982\n",
      "Epoch 37 : Train Accuracy : 0.76688, \tValid  Accuracy : 0.7887,\t Train Loss : 46037.103979231964, \tValid Loss :  8867.522096866043 , Time : 19.3940722529951\n",
      "Epoch 38 : Train Accuracy : 0.7719, \tValid  Accuracy : 0.7937,\t Train Loss : 45060.796789740125, \tValid Loss :  8665.171657380632 , Time : 20.341146615013713\n",
      "Epoch 39 : Train Accuracy : 0.77698, \tValid  Accuracy : 0.798,\t Train Loss : 44127.27714031303, \tValid Loss :  8471.91179556546 , Time : 19.678594649012666\n",
      "Epoch 40 : Train Accuracy : 0.78166, \tValid  Accuracy : 0.8013,\t Train Loss : 43233.63876806749, \tValid Loss :  8287.13035914971 , Time : 14.17998234697734\n",
      "Epoch 41 : Train Accuracy : 0.78596, \tValid  Accuracy : 0.8065,\t Train Loss : 42377.56911271368, \tValid Loss :  8110.287919286519 , Time : 14.46883957600221\n",
      "Epoch 42 : Train Accuracy : 0.79052, \tValid  Accuracy : 0.8106,\t Train Loss : 41556.791731238205, \tValid Loss :  7940.974793189777 , Time : 13.397514009004226\n",
      "Epoch 43 : Train Accuracy : 0.7939, \tValid  Accuracy : 0.8139,\t Train Loss : 40769.420684557364, \tValid Loss :  7778.641869801914 , Time : 12.133590939978603\n",
      "Epoch 44 : Train Accuracy : 0.79822, \tValid  Accuracy : 0.8175,\t Train Loss : 40013.684291369325, \tValid Loss :  7623.033633297586 , Time : 12.506872523983475\n",
      "Epoch 45 : Train Accuracy : 0.80156, \tValid  Accuracy : 0.8211,\t Train Loss : 39287.71925719863, \tValid Loss :  7473.722719544812 , Time : 12.11409909799113\n",
      "Epoch 46 : Train Accuracy : 0.80484, \tValid  Accuracy : 0.8243,\t Train Loss : 38589.58086544369, \tValid Loss :  7330.376884101047 , Time : 12.442481552978279\n",
      "Epoch 47 : Train Accuracy : 0.80814, \tValid  Accuracy : 0.8278,\t Train Loss : 37917.84147437117, \tValid Loss :  7192.638619040161 , Time : 15.403113369975472\n",
      "Epoch 48 : Train Accuracy : 0.81126, \tValid  Accuracy : 0.8301,\t Train Loss : 37271.69758027914, \tValid Loss :  7060.286711889747 , Time : 15.802185787993949\n",
      "Epoch 49 : Train Accuracy : 0.8141, \tValid  Accuracy : 0.8324,\t Train Loss : 36649.74082914883, \tValid Loss :  6933.068203477227 , Time : 12.03881183397607\n",
      "Epoch 50 : Train Accuracy : 0.81722, \tValid  Accuracy : 0.8351,\t Train Loss : 36050.9448889911, \tValid Loss :  6810.763043716782 , Time : 13.92023753799731\n",
      "Epoch 51 : Train Accuracy : 0.82008, \tValid  Accuracy : 0.837,\t Train Loss : 35474.32417405581, \tValid Loss :  6693.236029033256 , Time : 20.738950188999297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 : Train Accuracy : 0.823, \tValid  Accuracy : 0.8394,\t Train Loss : 34919.00840385108, \tValid Loss :  6580.280714638193 , Time : 13.613609008025378\n",
      "Epoch 53 : Train Accuracy : 0.8253, \tValid  Accuracy : 0.8418,\t Train Loss : 34384.09654958367, \tValid Loss :  6471.636578517006 , Time : 13.740203066001413\n",
      "Epoch 54 : Train Accuracy : 0.8275, \tValid  Accuracy : 0.8442,\t Train Loss : 33868.7047735693, \tValid Loss :  6367.205828046052 , Time : 18.860835339000914\n",
      "Epoch 55 : Train Accuracy : 0.83036, \tValid  Accuracy : 0.8462,\t Train Loss : 33372.307983015606, \tValid Loss :  6266.736044751913 , Time : 12.27270562297781\n",
      "Epoch 56 : Train Accuracy : 0.83266, \tValid  Accuracy : 0.8482,\t Train Loss : 32893.99572013671, \tValid Loss :  6170.069683349532 , Time : 20.00651339700562\n",
      "Epoch 57 : Train Accuracy : 0.83498, \tValid  Accuracy : 0.8505,\t Train Loss : 32433.036700327495, \tValid Loss :  6077.057567627304 , Time : 33.088970690005226\n",
      "Epoch 58 : Train Accuracy : 0.83722, \tValid  Accuracy : 0.8527,\t Train Loss : 31988.661380177793, \tValid Loss :  5987.6362484045585 , Time : 25.481556679995265\n",
      "Epoch 59 : Train Accuracy : 0.8394, \tValid  Accuracy : 0.8544,\t Train Loss : 31560.06271945725, \tValid Loss :  5901.5333088963325 , Time : 19.696792420989368\n",
      "Epoch 60 : Train Accuracy : 0.84136, \tValid  Accuracy : 0.8566,\t Train Loss : 31146.70080636442, \tValid Loss :  5818.6783016806285 , Time : 12.913911767012905\n",
      "Epoch 61 : Train Accuracy : 0.84308, \tValid  Accuracy : 0.8585,\t Train Loss : 30748.091070899234, \tValid Loss :  5738.903499460472 , Time : 16.162610794999637\n",
      "Epoch 62 : Train Accuracy : 0.84508, \tValid  Accuracy : 0.8598,\t Train Loss : 30363.640308540478, \tValid Loss :  5662.173359453805 , Time : 15.445013919001212\n",
      "Epoch 63 : Train Accuracy : 0.84684, \tValid  Accuracy : 0.8611,\t Train Loss : 29992.933376711073, \tValid Loss :  5588.257566436277 , Time : 16.65673373301979\n",
      "Epoch 64 : Train Accuracy : 0.84802, \tValid  Accuracy : 0.8625,\t Train Loss : 29635.221959548635, \tValid Loss :  5517.124717111139 , Time : 15.10390879600891\n",
      "Epoch 65 : Train Accuracy : 0.84966, \tValid  Accuracy : 0.8639,\t Train Loss : 29289.898042654757, \tValid Loss :  5448.497998501479 , Time : 13.888965885998914\n",
      "Epoch 66 : Train Accuracy : 0.851, \tValid  Accuracy : 0.8654,\t Train Loss : 28956.700909023297, \tValid Loss :  5382.451125645744 , Time : 13.725477197003784\n",
      "Epoch 67 : Train Accuracy : 0.85238, \tValid  Accuracy : 0.8654,\t Train Loss : 28634.915788711325, \tValid Loss :  5318.698599376699 , Time : 12.733235002990114\n",
      "Epoch 68 : Train Accuracy : 0.85372, \tValid  Accuracy : 0.8667,\t Train Loss : 28324.043706476405, \tValid Loss :  5257.310086489268 , Time : 14.046601019013906\n",
      "Epoch 69 : Train Accuracy : 0.85472, \tValid  Accuracy : 0.8679,\t Train Loss : 28023.530177888548, \tValid Loss :  5197.959704680786 , Time : 18.207534718007082\n",
      "Epoch 70 : Train Accuracy : 0.85626, \tValid  Accuracy : 0.8686,\t Train Loss : 27732.93920215187, \tValid Loss :  5140.808300299312 , Time : 18.82352107198676\n",
      "Epoch 71 : Train Accuracy : 0.8576, \tValid  Accuracy : 0.8698,\t Train Loss : 27452.056912561, \tValid Loss :  5085.523008997534 , Time : 16.990922060009325\n",
      "Epoch 72 : Train Accuracy : 0.85856, \tValid  Accuracy : 0.8707,\t Train Loss : 27180.25420803118, \tValid Loss :  5032.269204777249 , Time : 16.410402800014708\n",
      "Epoch 73 : Train Accuracy : 0.85944, \tValid  Accuracy : 0.8717,\t Train Loss : 26917.15843211433, \tValid Loss :  4980.672687371374 , Time : 30.64684533898253\n",
      "Epoch 74 : Train Accuracy : 0.86056, \tValid  Accuracy : 0.8729,\t Train Loss : 26662.403846278816, \tValid Loss :  4930.956102643944 , Time : 28.81335404701531\n",
      "Epoch 75 : Train Accuracy : 0.86174, \tValid  Accuracy : 0.8746,\t Train Loss : 26415.5703809267, \tValid Loss :  4882.6555911544565 , Time : 20.837939260993153\n",
      "Epoch 76 : Train Accuracy : 0.86264, \tValid  Accuracy : 0.8764,\t Train Loss : 26176.393469700502, \tValid Loss :  4836.163652261438 , Time : 18.147773125005187\n",
      "Epoch 77 : Train Accuracy : 0.86358, \tValid  Accuracy : 0.8769,\t Train Loss : 25944.623914541866, \tValid Loss :  4790.924151445071 , Time : 17.045878753007855\n",
      "Epoch 78 : Train Accuracy : 0.86438, \tValid  Accuracy : 0.8779,\t Train Loss : 25720.059296437405, \tValid Loss :  4747.434159380685 , Time : 31.432181376003427\n",
      "Epoch 79 : Train Accuracy : 0.86562, \tValid  Accuracy : 0.8781,\t Train Loss : 25502.31756284596, \tValid Loss :  4705.026688347512 , Time : 25.21729532201425\n"
     ]
    }
   ],
   "source": [
    "trainLogFD = train_loopFD(80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Average Gradients "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À chaque itération, (similairement à l'algorithme du Stochastic Gradient) je choisis un indexe aléatoire entre 0 et la taille de l'ensemble d'entrainement (n) pour sélectionner une de ces paires de données pour calculer le gradient respectif à  celle-ci. Le gradient est calculé avec la backpropagation et il  est ajouté à une somme (pour ensuite calculer la moyenne) des autres gradients des itérations antérieures (aussi représentatifs de paires de données aléatoirement choisies). Le nombre d'indexes visité est donc gardé en mémoire sous la variable $k$. \n",
    "À  chaque itération, nous calculons le gradient de la paire de données sélectionnées aléatoirement, nous ajoutons le gradient à la somme des gradients et si l'index avait déjà été visité antérieurement, ont soustrait l'ancien  gradient mais nous n'ajustons pas la valeur de k puisque cette paire avait déjà été comptée. S'il n'avait pas été visité antérieurement, nous ajoutons le gradient à la somme et augmentons la valeur de $k= k+ 1$ pour calculer le gradient moyen. Les poids (weights) et  biais sont donc modifiés en fonction de la moyenne de tous les gradients calculés antérieurement. Le cout d'itérations est donc constant et indépendant de la taille de l'ensemble d'entrainement, puisque à chaque itération nous calculons qu'un seul gradient (comme dans l'algorithme du Stochastic Gradient). Le taux de convergence est cependant meilleur avec tout de même de $g^k$, pour $0<g<1$, par itération  (taux de convergence linéaire)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loopSAG(n_epochs):\n",
    "    train_logs = {'train_accuracyFD': [], 'validation_accuracyFD': [], 'train_lossFD': [], 'validation_lossFD': [],\n",
    "                  'time': []}\n",
    "    X_train, y_train = train\n",
    "    y_onehot = y_train\n",
    "    dims = [X_train.shape[1], y_onehot.shape[1]]\n",
    "    hidden_dims = hidden_dims = (64, 32)\n",
    "    weights = initialize_weights(dims, hidden_dims)\n",
    "    batch_size = 1\n",
    "    alpha = 7.9e-3\n",
    "    n_batches = 50000\n",
    "    gradsS = {}\n",
    "    gradsM = {}\n",
    "    storedGrads = {}\n",
    "    k = 0\n",
    "    previousLoss = 2147483647 # Le plus grand integer possible (python)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 1000 == 0 or epoch == 1 or epoch == 501:\n",
    "            start = timeit.default_timer()\n",
    "        #  Selection d'un index aléatoire dépendament du nombre de donnée dans le training data.\n",
    "        indexAleatoire = randint(0, n_batches)\n",
    "\n",
    "        batchX = X_train[batch_size * indexAleatoire:batch_size * (indexAleatoire + 1), :]\n",
    "        batchY = y_onehot[batch_size * indexAleatoire:batch_size * (indexAleatoire + 1), :]\n",
    "        cache = forward(batchX, weights, hidden_dims)\n",
    "        grads = backward(weights, cache, batchY, hidden_dims)\n",
    "\n",
    "        #  Si l'index n'a jamais été  tiré, garder en  mémoire les gradients.\n",
    "        #  Si il a été  tiré, enleve la différence des anciens dans le dictionnaire gradsS.\n",
    "        if indexAleatoire not in storedGrads:\n",
    "            storedGrads[indexAleatoire] = {}\n",
    "            k += 1\n",
    "            # print(\"K: \", k)\n",
    "        else:\n",
    "            # print(\"K: Already Picked\")\n",
    "            gradsS['dW3'] -= storedGrads[indexAleatoire][\"dW3\"]\n",
    "            gradsS[\"dW2\"] -= storedGrads[indexAleatoire][\"dW2\"]\n",
    "            gradsS[\"dW1\"] -= storedGrads[indexAleatoire][\"dW1\"]\n",
    "            gradsS[\"db3\"] -= storedGrads[indexAleatoire][\"db3\"]\n",
    "            gradsS[\"db2\"] -= storedGrads[indexAleatoire][\"db2\"]\n",
    "            gradsS[\"db1\"] -= storedGrads[indexAleatoire][\"db1\"]\n",
    "\n",
    "        # Garder en mémoire les anciens grads pour les enlever un fois de nouveau pigé.\n",
    "        storedGrads[indexAleatoire][\"dW3\"] = grads[\"dW3\"]\n",
    "        storedGrads[indexAleatoire][\"dW2\"] = grads[\"dW2\"]\n",
    "        storedGrads[indexAleatoire][\"dW1\"] = grads[\"dW1\"]\n",
    "        storedGrads[indexAleatoire][\"db3\"] = grads[\"db3\"]\n",
    "        storedGrads[indexAleatoire][\"db2\"] = grads[\"db2\"]\n",
    "        storedGrads[indexAleatoire][\"db1\"] = grads[\"db1\"]\n",
    "\n",
    "        # Ajouter tous les éléments pigé à la somme des gradients,  pour calculer la moyenne après.\n",
    "        if epoch != 0:\n",
    "            gradsS['dW3'] += grads[\"dW3\"]\n",
    "            gradsS[\"dW2\"] += grads[\"dW2\"]\n",
    "            gradsS[\"dW1\"] += grads[\"dW1\"]\n",
    "            gradsS[\"db3\"] += grads[\"db3\"]\n",
    "            gradsS[\"db2\"] += grads[\"db2\"]\n",
    "            gradsS[\"db1\"] += grads[\"db1\"]\n",
    "        else:\n",
    "            gradsS['dW3'] = grads[\"dW3\"]\n",
    "            gradsS[\"dW2\"] = grads[\"dW2\"]\n",
    "            gradsS[\"dW1\"] = grads[\"dW1\"]\n",
    "            gradsS[\"db3\"] = grads[\"db3\"]\n",
    "            gradsS[\"db2\"] = grads[\"db2\"]\n",
    "            gradsS[\"db1\"] = grads[\"db1\"]\n",
    "\n",
    "        # Diviser pour par k pour obtenir la moyenne.\n",
    "        gradsM['dW3'] = gradsS[\"dW3\"] * 1 / k\n",
    "        gradsM[\"dW2\"] = gradsS[\"dW2\"] * 1 / k\n",
    "        gradsM[\"dW1\"] = gradsS[\"dW1\"] * 1 / k\n",
    "        gradsM[\"db3\"] = gradsS[\"db3\"] * 1 / k\n",
    "        gradsM[\"db2\"] = gradsS[\"db2\"] * 1 / k\n",
    "        gradsM[\"db1\"] = gradsS[\"db1\"] * 1 / k\n",
    "\n",
    "        # Update les weights.\n",
    "        weights = update(gradsM, weights, hidden_dims, alpha)\n",
    "\n",
    "        if epoch % 1000 == 999 or epoch == 0 or epoch == 500:\n",
    "            # Arreter le temps puisque la computation des losses ne differe pas d'un algorithme à l'autre.\n",
    "            stop = timeit.default_timer()\n",
    "            X_train, y_train = train\n",
    "            train_loss, train_accuracy, _ = compute_loss_and_accuracy(X_train, y_train, weights, hidden_dims)\n",
    "            X_valid, y_valid = valid\n",
    "            valid_loss, valid_accuracy, _ = compute_loss_and_accuracy(X_valid, y_valid, weights, hidden_dims)\n",
    "\n",
    "            # Imprimer la loss et la precision. Ça l'aide a suivre le progrès\n",
    "            print(f\"Epoch {epoch} : Train Accuracy : {train_accuracy}, \\tValid  Accuracy : {valid_accuracy},\\t Train Loss : {train_loss}, \\tValid Loss :  {valid_loss} , Time for 1000 epochs : {stop - start}\")\n",
    "            \n",
    "            # Ajuster le taux d'apprentissage si pas de déscente\n",
    "            if train_loss > previousLoss:\n",
    "                alpha  = alpha  *  .9899999\n",
    "            previousLoss = train_loss\n",
    "            train_logs['train_accuracyFD'].append(train_accuracy)\n",
    "            train_logs['validation_accuracyFD'].append(valid_accuracy)\n",
    "            train_logs['train_lossFD'].append(train_loss)\n",
    "            train_logs['validation_lossFD'].append(valid_loss)\n",
    "            train_logs['time'].append(stop - start)\n",
    "\n",
    "    return train_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : Train Accuracy : 0.08946, \tValid  Accuracy : 0.09,\t Train Loss : 128811.62135089346, \tValid Loss :  25697.41876322002 , Time for 1000 epochs : 0.0024444779846817255\n",
      "Epoch 500 : Train Accuracy : 0.54088, \tValid  Accuracy : 0.548,\t Train Loss : 76174.9911884531, \tValid Loss :  15059.95844234767 , Time for 1000 epochs : 0.5297584350046236\n",
      "Epoch 999 : Train Accuracy : 0.6547, \tValid  Accuracy : 0.6723,\t Train Loss : 47181.21988922776, \tValid Loss :  8912.99671777594 , Time for 1000 epochs : 0.5584461120015476\n",
      "Epoch 1999 : Train Accuracy : 0.74086, \tValid  Accuracy : 0.7681,\t Train Loss : 44226.50128370527, \tValid Loss :  7893.831077768212 , Time for 1000 epochs : 1.2903144060110208\n",
      "Epoch 2999 : Train Accuracy : 0.8091, \tValid  Accuracy : 0.8256,\t Train Loss : 35378.423010021186, \tValid Loss :  6344.147156639909 , Time for 1000 epochs : 1.3081312029971741\n",
      "Epoch 3999 : Train Accuracy : 0.79594, \tValid  Accuracy : 0.8046,\t Train Loss : 33764.62514362122, \tValid Loss :  6391.854050713556 , Time for 1000 epochs : 0.9028336810006294\n",
      "Epoch 4999 : Train Accuracy : 0.80546, \tValid  Accuracy : 0.8213,\t Train Loss : 31035.231959346333, \tValid Loss :  5844.742445009008 , Time for 1000 epochs : 1.108794942003442\n",
      "Epoch 5999 : Train Accuracy : 0.82614, \tValid  Accuracy : 0.8345,\t Train Loss : 28340.937783046083, \tValid Loss :  5370.158866600688 , Time for 1000 epochs : 0.8713437209953554\n",
      "Epoch 6999 : Train Accuracy : 0.8455, \tValid  Accuracy : 0.852,\t Train Loss : 26163.93757271462, \tValid Loss :  4919.846489638585 , Time for 1000 epochs : 0.8980509999964852\n",
      "Epoch 7999 : Train Accuracy : 0.84732, \tValid  Accuracy : 0.8596,\t Train Loss : 26702.186490006574, \tValid Loss :  5036.9271828619785 , Time for 1000 epochs : 1.0312768500007223\n",
      "Epoch 8999 : Train Accuracy : 0.87594, \tValid  Accuracy : 0.8819,\t Train Loss : 23041.472782764038, \tValid Loss :  4336.69888434912 , Time for 1000 epochs : 1.1556301629752852\n",
      "Epoch 9999 : Train Accuracy : 0.86524, \tValid  Accuracy : 0.8694,\t Train Loss : 24665.94347179824, \tValid Loss :  4646.351287465749 , Time for 1000 epochs : 1.2252627150155604\n",
      "Epoch 10999 : Train Accuracy : 0.87052, \tValid  Accuracy : 0.8834,\t Train Loss : 23211.500001836637, \tValid Loss :  4239.496332442543 , Time for 1000 epochs : 1.2395404359849636\n",
      "Epoch 11999 : Train Accuracy : 0.85868, \tValid  Accuracy : 0.8719,\t Train Loss : 25251.60255617249, \tValid Loss :  4501.986786198441 , Time for 1000 epochs : 1.312886294996133\n",
      "Epoch 12999 : Train Accuracy : 0.88064, \tValid  Accuracy : 0.8898,\t Train Loss : 21627.279834983678, \tValid Loss :  3853.6211605451435 , Time for 1000 epochs : 1.139289728977019\n",
      "Epoch 13999 : Train Accuracy : 0.88774, \tValid  Accuracy : 0.8982,\t Train Loss : 20237.745742586318, \tValid Loss :  3652.9395154613194 , Time for 1000 epochs : 1.0342023510020226\n",
      "Epoch 14999 : Train Accuracy : 0.87636, \tValid  Accuracy : 0.8862,\t Train Loss : 21690.28278398652, \tValid Loss :  3971.262220863744 , Time for 1000 epochs : 1.9932353280019015\n",
      "Epoch 15999 : Train Accuracy : 0.88316, \tValid  Accuracy : 0.8951,\t Train Loss : 20345.07901900533, \tValid Loss :  3685.743493108785 , Time for 1000 epochs : 1.126333022984909\n",
      "Epoch 16999 : Train Accuracy : 0.88876, \tValid  Accuracy : 0.8994,\t Train Loss : 19736.83579698894, \tValid Loss :  3507.6383829585984 , Time for 1000 epochs : 1.1138384150108323\n",
      "Epoch 17999 : Train Accuracy : 0.89136, \tValid  Accuracy : 0.9035,\t Train Loss : 19583.86310324443, \tValid Loss :  3464.2083177064615 , Time for 1000 epochs : 1.2162556360126473\n",
      "Epoch 18999 : Train Accuracy : 0.88508, \tValid  Accuracy : 0.8976,\t Train Loss : 20231.69526602296, \tValid Loss :  3626.3443286150805 , Time for 1000 epochs : 1.1746638500189874\n",
      "Epoch 19999 : Train Accuracy : 0.88952, \tValid  Accuracy : 0.9013,\t Train Loss : 19165.207629057913, \tValid Loss :  3471.294454080999 , Time for 1000 epochs : 1.050522189005278\n",
      "Epoch 20999 : Train Accuracy : 0.89194, \tValid  Accuracy : 0.9005,\t Train Loss : 18814.671927632677, \tValid Loss :  3473.9399301772955 , Time for 1000 epochs : 1.334643721987959\n",
      "Epoch 21999 : Train Accuracy : 0.89108, \tValid  Accuracy : 0.8978,\t Train Loss : 19096.14891595456, \tValid Loss :  3568.726574844416 , Time for 1000 epochs : 1.146967014996335\n",
      "Epoch 22999 : Train Accuracy : 0.89374, \tValid  Accuracy : 0.9013,\t Train Loss : 18492.803168511553, \tValid Loss :  3473.1424716088986 , Time for 1000 epochs : 0.9910515250230674\n",
      "Epoch 23999 : Train Accuracy : 0.8985, \tValid  Accuracy : 0.9064,\t Train Loss : 17782.054341824314, \tValid Loss :  3325.9289861282386 , Time for 1000 epochs : 1.072021573985694\n",
      "Epoch 24999 : Train Accuracy : 0.89926, \tValid  Accuracy : 0.9092,\t Train Loss : 17693.04576754663, \tValid Loss :  3261.118753736083 , Time for 1000 epochs : 1.5950134849990718\n",
      "Epoch 25999 : Train Accuracy : 0.90032, \tValid  Accuracy : 0.9104,\t Train Loss : 17613.017006281716, \tValid Loss :  3206.9931060144463 , Time for 1000 epochs : 1.120982678985456\n",
      "Epoch 26999 : Train Accuracy : 0.90104, \tValid  Accuracy : 0.911,\t Train Loss : 17202.011468584154, \tValid Loss :  3183.0056089662444 , Time for 1000 epochs : 1.705397569021443\n",
      "Epoch 27999 : Train Accuracy : 0.89646, \tValid  Accuracy : 0.9032,\t Train Loss : 17734.043178216383, \tValid Loss :  3345.7292479692182 , Time for 1000 epochs : 1.2166088249941822\n",
      "Epoch 28999 : Train Accuracy : 0.90156, \tValid  Accuracy : 0.9075,\t Train Loss : 16960.850023135936, \tValid Loss :  3195.4114621748336 , Time for 1000 epochs : 1.214704357989831\n",
      "Epoch 29999 : Train Accuracy : 0.90556, \tValid  Accuracy : 0.9123,\t Train Loss : 16651.35644884088, \tValid Loss :  3114.5178840941417 , Time for 1000 epochs : 1.3738179070060141\n",
      "Epoch 30999 : Train Accuracy : 0.8999, \tValid  Accuracy : 0.9084,\t Train Loss : 17806.905617185865, \tValid Loss :  3338.6949345754206 , Time for 1000 epochs : 2.083951470995089\n",
      "Epoch 31999 : Train Accuracy : 0.89674, \tValid  Accuracy : 0.9089,\t Train Loss : 18075.97839183078, \tValid Loss :  3400.4254201611557 , Time for 1000 epochs : 4.138930451008491\n",
      "Epoch 32999 : Train Accuracy : 0.89986, \tValid  Accuracy : 0.9106,\t Train Loss : 17192.027803500165, \tValid Loss :  3233.348097853859 , Time for 1000 epochs : 3.5005358920025174\n",
      "Epoch 33999 : Train Accuracy : 0.90186, \tValid  Accuracy : 0.9104,\t Train Loss : 16632.425899294747, \tValid Loss :  3128.2544133509714 , Time for 1000 epochs : 1.761550676979823\n",
      "Epoch 34999 : Train Accuracy : 0.90302, \tValid  Accuracy : 0.9087,\t Train Loss : 16434.8962966964, \tValid Loss :  3109.4533769150735 , Time for 1000 epochs : 1.136111036001239\n",
      "Epoch 35999 : Train Accuracy : 0.90684, \tValid  Accuracy : 0.9119,\t Train Loss : 16068.602952948133, \tValid Loss :  3067.9839423639514 , Time for 1000 epochs : 1.684504097996978\n",
      "Epoch 36999 : Train Accuracy : 0.91196, \tValid  Accuracy : 0.9156,\t Train Loss : 15493.668424606662, \tValid Loss :  2984.735540039994 , Time for 1000 epochs : 2.7085410180152394\n",
      "Epoch 37999 : Train Accuracy : 0.91668, \tValid  Accuracy : 0.9186,\t Train Loss : 15140.61603711514, \tValid Loss :  2925.182348032969 , Time for 1000 epochs : 1.6577246850065421\n",
      "Epoch 38999 : Train Accuracy : 0.91902, \tValid  Accuracy : 0.9222,\t Train Loss : 14975.48690581042, \tValid Loss :  2880.649647319665 , Time for 1000 epochs : 1.8830121030041482\n",
      "Epoch 39999 : Train Accuracy : 0.9187, \tValid  Accuracy : 0.9227,\t Train Loss : 15092.979049915193, \tValid Loss :  2880.9822141146838 , Time for 1000 epochs : 1.8694527309853584\n",
      "Epoch 40999 : Train Accuracy : 0.91712, \tValid  Accuracy : 0.92,\t Train Loss : 15377.937956069465, \tValid Loss :  2905.8260040166874 , Time for 1000 epochs : 1.266726080008084\n",
      "Epoch 41999 : Train Accuracy : 0.91796, \tValid  Accuracy : 0.9204,\t Train Loss : 15318.082750749967, \tValid Loss :  2867.4795876580206 , Time for 1000 epochs : 1.424940579017857\n",
      "Epoch 42999 : Train Accuracy : 0.91936, \tValid  Accuracy : 0.9223,\t Train Loss : 15035.178799559093, \tValid Loss :  2802.715670525821 , Time for 1000 epochs : 1.2540865220071282\n",
      "Epoch 43999 : Train Accuracy : 0.92112, \tValid  Accuracy : 0.9248,\t Train Loss : 14722.072719556061, \tValid Loss :  2737.9586017179417 , Time for 1000 epochs : 1.4143499799829442\n",
      "Epoch 44999 : Train Accuracy : 0.92078, \tValid  Accuracy : 0.926,\t Train Loss : 14713.170352413781, \tValid Loss :  2739.7805928037646 , Time for 1000 epochs : 1.5268651669903193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45999 : Train Accuracy : 0.9195, \tValid  Accuracy : 0.9245,\t Train Loss : 14877.124064103547, \tValid Loss :  2766.728897965541 , Time for 1000 epochs : 1.1595352430013008\n",
      "Epoch 46999 : Train Accuracy : 0.9193, \tValid  Accuracy : 0.9249,\t Train Loss : 14865.815891437427, \tValid Loss :  2759.3401132983945 , Time for 1000 epochs : 1.1605541739845648\n",
      "Epoch 47999 : Train Accuracy : 0.92108, \tValid  Accuracy : 0.9262,\t Train Loss : 14522.050164759145, \tValid Loss :  2691.814850729472 , Time for 1000 epochs : 1.1461176029988565\n",
      "Epoch 48999 : Train Accuracy : 0.923, \tValid  Accuracy : 0.9274,\t Train Loss : 14174.689368395862, \tValid Loss :  2625.736291296159 , Time for 1000 epochs : 1.2093078549951315\n",
      "Epoch 49999 : Train Accuracy : 0.92362, \tValid  Accuracy : 0.9286,\t Train Loss : 13855.26277532596, \tValid Loss :  2577.7034101700174 , Time for 1000 epochs : 1.9880126909993123\n",
      "Epoch 50999 : Train Accuracy : 0.92376, \tValid  Accuracy : 0.928,\t Train Loss : 13639.073911889727, \tValid Loss :  2556.852931047681 , Time for 1000 epochs : 1.4187606920022517\n",
      "Epoch 51999 : Train Accuracy : 0.92426, \tValid  Accuracy : 0.928,\t Train Loss : 13430.355297919983, \tValid Loss :  2534.2928120484576 , Time for 1000 epochs : 1.5974660759966355\n",
      "Epoch 52999 : Train Accuracy : 0.92574, \tValid  Accuracy : 0.9292,\t Train Loss : 13063.856227494429, \tValid Loss :  2477.982396121318 , Time for 1000 epochs : 1.788667868997436\n",
      "Epoch 53999 : Train Accuracy : 0.92738, \tValid  Accuracy : 0.9298,\t Train Loss : 12732.51974352751, \tValid Loss :  2428.2926312147883 , Time for 1000 epochs : 1.749139951018151\n",
      "Epoch 54999 : Train Accuracy : 0.9276, \tValid  Accuracy : 0.9295,\t Train Loss : 12608.827545976841, \tValid Loss :  2416.5583820827296 , Time for 1000 epochs : 1.8211499649914913\n",
      "Epoch 55999 : Train Accuracy : 0.92688, \tValid  Accuracy : 0.9283,\t Train Loss : 12623.489022176402, \tValid Loss :  2427.5821323128316 , Time for 1000 epochs : 1.4254615909885615\n",
      "Epoch 56999 : Train Accuracy : 0.926, \tValid  Accuracy : 0.9278,\t Train Loss : 12653.197592506587, \tValid Loss :  2438.699403844182 , Time for 1000 epochs : 1.303615543001797\n",
      "Epoch 57999 : Train Accuracy : 0.92606, \tValid  Accuracy : 0.9286,\t Train Loss : 12649.363091221203, \tValid Loss :  2437.319127457349 , Time for 1000 epochs : 1.8940895319974516\n",
      "Epoch 58999 : Train Accuracy : 0.92672, \tValid  Accuracy : 0.93,\t Train Loss : 12581.466942420042, \tValid Loss :  2418.501068082695 , Time for 1000 epochs : 1.4176089130050968\n",
      "Epoch 59999 : Train Accuracy : 0.92758, \tValid  Accuracy : 0.9314,\t Train Loss : 12507.43960065246, \tValid Loss :  2389.024166487548 , Time for 1000 epochs : 1.1947399329801556\n",
      "Epoch 60999 : Train Accuracy : 0.92748, \tValid  Accuracy : 0.9307,\t Train Loss : 12525.523489815463, \tValid Loss :  2375.177111483723 , Time for 1000 epochs : 1.198958257009508\n",
      "Epoch 61999 : Train Accuracy : 0.92682, \tValid  Accuracy : 0.9305,\t Train Loss : 12560.487929573344, \tValid Loss :  2373.527647871074 , Time for 1000 epochs : 1.070594512973912\n",
      "Epoch 62999 : Train Accuracy : 0.92552, \tValid  Accuracy : 0.9288,\t Train Loss : 12587.721835949167, \tValid Loss :  2386.397899402931 , Time for 1000 epochs : 1.0247579470160417\n",
      "Epoch 63999 : Train Accuracy : 0.92546, \tValid  Accuracy : 0.9275,\t Train Loss : 12549.35400197305, \tValid Loss :  2396.588745134618 , Time for 1000 epochs : 1.5813002020004205\n",
      "Epoch 64999 : Train Accuracy : 0.9261, \tValid  Accuracy : 0.9278,\t Train Loss : 12459.126555854491, \tValid Loss :  2395.900300792859 , Time for 1000 epochs : 4.435996879008599\n",
      "Epoch 65999 : Train Accuracy : 0.92574, \tValid  Accuracy : 0.9279,\t Train Loss : 12468.186807677095, \tValid Loss :  2413.362553187681 , Time for 1000 epochs : 1.5342232219991274\n",
      "Epoch 66999 : Train Accuracy : 0.9259, \tValid  Accuracy : 0.9285,\t Train Loss : 12631.40474226004, \tValid Loss :  2457.540739080918 , Time for 1000 epochs : 1.2251532890077215\n",
      "Epoch 67999 : Train Accuracy : 0.9259, \tValid  Accuracy : 0.9294,\t Train Loss : 12700.23112136312, \tValid Loss :  2478.401648925379 , Time for 1000 epochs : 1.3144721489807125\n",
      "Epoch 68999 : Train Accuracy : 0.92704, \tValid  Accuracy : 0.9307,\t Train Loss : 12612.61335673799, \tValid Loss :  2464.0844249461306 , Time for 1000 epochs : 1.1147195030061994\n",
      "Epoch 69999 : Train Accuracy : 0.92854, \tValid  Accuracy : 0.9309,\t Train Loss : 12435.321768523303, \tValid Loss :  2431.712467272755 , Time for 1000 epochs : 1.017079957993701\n",
      "Epoch 70999 : Train Accuracy : 0.9292, \tValid  Accuracy : 0.9328,\t Train Loss : 12304.467744818625, \tValid Loss :  2402.6543666249254 , Time for 1000 epochs : 1.4812394439941272\n",
      "Epoch 71999 : Train Accuracy : 0.92872, \tValid  Accuracy : 0.9327,\t Train Loss : 12297.196994470658, \tValid Loss :  2390.114009034203 , Time for 1000 epochs : 1.4688189879816491\n",
      "Epoch 72999 : Train Accuracy : 0.92838, \tValid  Accuracy : 0.9334,\t Train Loss : 12402.224650885699, \tValid Loss :  2394.355084357152 , Time for 1000 epochs : 1.5446655429841485\n",
      "Epoch 73999 : Train Accuracy : 0.92764, \tValid  Accuracy : 0.933,\t Train Loss : 12505.633725436976, \tValid Loss :  2396.040873617432 , Time for 1000 epochs : 1.5105292149819434\n",
      "Epoch 74999 : Train Accuracy : 0.92824, \tValid  Accuracy : 0.9327,\t Train Loss : 12467.815472212496, \tValid Loss :  2376.142324971186 , Time for 1000 epochs : 1.440081360982731\n",
      "Epoch 75999 : Train Accuracy : 0.92828, \tValid  Accuracy : 0.9328,\t Train Loss : 12486.802434015044, \tValid Loss :  2368.069597719031 , Time for 1000 epochs : 1.9941284829983488\n",
      "Epoch 76999 : Train Accuracy : 0.92908, \tValid  Accuracy : 0.9331,\t Train Loss : 12601.087871959076, \tValid Loss :  2386.9292709993288 , Time for 1000 epochs : 1.5534426890080795\n",
      "Epoch 77999 : Train Accuracy : 0.92832, \tValid  Accuracy : 0.9343,\t Train Loss : 12672.470294749726, \tValid Loss :  2413.9507167901206 , Time for 1000 epochs : 1.7161803680064622\n",
      "Epoch 78999 : Train Accuracy : 0.9294, \tValid  Accuracy : 0.9334,\t Train Loss : 12592.126349442948, \tValid Loss :  2426.6730398538875 , Time for 1000 epochs : 1.8036489119986072\n",
      "Epoch 79999 : Train Accuracy : 0.93026, \tValid  Accuracy : 0.9327,\t Train Loss : 12539.648162150395, \tValid Loss :  2448.1584298831863 , Time for 1000 epochs : 1.3109274710004684\n",
      "Epoch 80999 : Train Accuracy : 0.92978, \tValid  Accuracy : 0.9321,\t Train Loss : 12495.197120861987, \tValid Loss :  2462.050481887474 , Time for 1000 epochs : 1.8316559910017531\n",
      "Epoch 81999 : Train Accuracy : 0.92964, \tValid  Accuracy : 0.9312,\t Train Loss : 12470.566430895626, \tValid Loss :  2466.2731655639136 , Time for 1000 epochs : 1.4727478100103326\n",
      "Epoch 82999 : Train Accuracy : 0.92962, \tValid  Accuracy : 0.9296,\t Train Loss : 12465.893577919443, \tValid Loss :  2458.5473649384026 , Time for 1000 epochs : 1.5409553220088128\n",
      "Epoch 83999 : Train Accuracy : 0.9299, \tValid  Accuracy : 0.9313,\t Train Loss : 12375.652349145457, \tValid Loss :  2431.87652317012 , Time for 1000 epochs : 1.7293048370047472\n",
      "Epoch 84999 : Train Accuracy : 0.9312, \tValid  Accuracy : 0.9334,\t Train Loss : 12084.670774925695, \tValid Loss :  2371.674698104658 , Time for 1000 epochs : 1.7372427789960057\n",
      "Epoch 85999 : Train Accuracy : 0.93144, \tValid  Accuracy : 0.9348,\t Train Loss : 11776.324567767542, \tValid Loss :  2310.3320248004284 , Time for 1000 epochs : 1.5899459960055538\n",
      "Epoch 86999 : Train Accuracy : 0.93082, \tValid  Accuracy : 0.9336,\t Train Loss : 11669.15170400907, \tValid Loss :  2289.305158923083 , Time for 1000 epochs : 2.145858316012891\n",
      "Epoch 87999 : Train Accuracy : 0.92852, \tValid  Accuracy : 0.9312,\t Train Loss : 11870.623819276174, \tValid Loss :  2323.7200709969384 , Time for 1000 epochs : 1.4195269710035063\n",
      "Epoch 88999 : Train Accuracy : 0.92602, \tValid  Accuracy : 0.9298,\t Train Loss : 12165.87850860205, \tValid Loss :  2373.292319949906 , Time for 1000 epochs : 2.5876117990119383\n",
      "Epoch 89999 : Train Accuracy : 0.925, \tValid  Accuracy : 0.9297,\t Train Loss : 12222.918756812767, \tValid Loss :  2385.3000863347597 , Time for 1000 epochs : 1.4849200499884319\n",
      "Epoch 90999 : Train Accuracy : 0.92678, \tValid  Accuracy : 0.9304,\t Train Loss : 11990.093777487293, \tValid Loss :  2351.9202175745595 , Time for 1000 epochs : 1.5009532239928376\n",
      "Epoch 91999 : Train Accuracy : 0.92942, \tValid  Accuracy : 0.9325,\t Train Loss : 11714.698597566878, \tValid Loss :  2312.121323378734 , Time for 1000 epochs : 1.6395563299884088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92999 : Train Accuracy : 0.92962, \tValid  Accuracy : 0.9334,\t Train Loss : 11708.44418954411, \tValid Loss :  2316.259392334541 , Time for 1000 epochs : 1.4995662980072666\n",
      "Epoch 93999 : Train Accuracy : 0.92818, \tValid  Accuracy : 0.9313,\t Train Loss : 11962.65724761316, \tValid Loss :  2360.5455498350775 , Time for 1000 epochs : 1.274018710013479\n",
      "Epoch 94999 : Train Accuracy : 0.9265, \tValid  Accuracy : 0.9292,\t Train Loss : 12321.181896589318, \tValid Loss :  2420.086492010663 , Time for 1000 epochs : 1.4855062440037727\n",
      "Epoch 95999 : Train Accuracy : 0.92592, \tValid  Accuracy : 0.9293,\t Train Loss : 12458.679029632332, \tValid Loss :  2439.8876750582676 , Time for 1000 epochs : 1.2078777849965263\n",
      "Epoch 96999 : Train Accuracy : 0.92802, \tValid  Accuracy : 0.9294,\t Train Loss : 12168.128011078838, \tValid Loss :  2385.5935747544395 , Time for 1000 epochs : 2.047276060009608\n",
      "Epoch 97999 : Train Accuracy : 0.93094, \tValid  Accuracy : 0.9318,\t Train Loss : 11666.841701542367, \tValid Loss :  2295.7659570450883 , Time for 1000 epochs : 1.9456362710043322\n",
      "Epoch 98999 : Train Accuracy : 0.93306, \tValid  Accuracy : 0.9341,\t Train Loss : 11305.714208883644, \tValid Loss :  2230.534044611456 , Time for 1000 epochs : 1.3812245250155684\n",
      "Epoch 99999 : Train Accuracy : 0.9322, \tValid  Accuracy : 0.9353,\t Train Loss : 11267.270623830671, \tValid Loss :  2223.276263186085 , Time for 1000 epochs : 1.666174284007866\n",
      "Epoch 100999 : Train Accuracy : 0.92972, \tValid  Accuracy : 0.9342,\t Train Loss : 11512.685930644422, \tValid Loss :  2262.824025453776 , Time for 1000 epochs : 1.5775327770097647\n",
      "Epoch 101999 : Train Accuracy : 0.9279, \tValid  Accuracy : 0.9311,\t Train Loss : 11857.995972043453, \tValid Loss :  2315.348801453692 , Time for 1000 epochs : 1.6133701959915925\n",
      "Epoch 102999 : Train Accuracy : 0.9264, \tValid  Accuracy : 0.9312,\t Train Loss : 12065.971088420481, \tValid Loss :  2342.428361041641 , Time for 1000 epochs : 1.5908526570128743\n",
      "Epoch 103999 : Train Accuracy : 0.92722, \tValid  Accuracy : 0.932,\t Train Loss : 11966.499045099188, \tValid Loss :  2317.311681477154 , Time for 1000 epochs : 1.7767905729997437\n",
      "Epoch 104999 : Train Accuracy : 0.92948, \tValid  Accuracy : 0.9328,\t Train Loss : 11677.979356602362, \tValid Loss :  2257.0653653215036 , Time for 1000 epochs : 1.4204566800035536\n",
      "Epoch 105999 : Train Accuracy : 0.93134, \tValid  Accuracy : 0.9352,\t Train Loss : 11412.079914461652, \tValid Loss :  2200.534013569706 , Time for 1000 epochs : 2.27563560398994\n",
      "Epoch 106999 : Train Accuracy : 0.9319, \tValid  Accuracy : 0.9345,\t Train Loss : 11438.053928943233, \tValid Loss :  2199.804524798502 , Time for 1000 epochs : 1.484780011989642\n",
      "Epoch 107999 : Train Accuracy : 0.92998, \tValid  Accuracy : 0.9326,\t Train Loss : 11778.326396850733, \tValid Loss :  2258.8286514924957 , Time for 1000 epochs : 1.3433684649935458\n",
      "Epoch 108999 : Train Accuracy : 0.9277, \tValid  Accuracy : 0.932,\t Train Loss : 12181.269084896187, \tValid Loss :  2329.4050258755246 , Time for 1000 epochs : 2.702813073003199\n",
      "Epoch 109999 : Train Accuracy : 0.9268, \tValid  Accuracy : 0.9312,\t Train Loss : 12412.681479295463, \tValid Loss :  2366.9995805183275 , Time for 1000 epochs : 2.1052174659853335\n",
      "Epoch 110999 : Train Accuracy : 0.92762, \tValid  Accuracy : 0.9325,\t Train Loss : 12299.675461968722, \tValid Loss :  2335.836416987934 , Time for 1000 epochs : 2.3249567150196526\n",
      "Epoch 111999 : Train Accuracy : 0.93022, \tValid  Accuracy : 0.9354,\t Train Loss : 11904.558652713738, \tValid Loss :  2248.78359579906 , Time for 1000 epochs : 1.7091483600088395\n",
      "Epoch 112999 : Train Accuracy : 0.93202, \tValid  Accuracy : 0.9374,\t Train Loss : 11585.150249603807, \tValid Loss :  2174.5091271027527 , Time for 1000 epochs : 2.4765613180061337\n",
      "Epoch 113999 : Train Accuracy : 0.93088, \tValid  Accuracy : 0.9375,\t Train Loss : 11546.087290795529, \tValid Loss :  2156.635121429639 , Time for 1000 epochs : 1.9021342209889553\n",
      "Epoch 114999 : Train Accuracy : 0.92948, \tValid  Accuracy : 0.9364,\t Train Loss : 11681.225484803335, \tValid Loss :  2178.400551828812 , Time for 1000 epochs : 1.4792740539996885\n",
      "Epoch 115999 : Train Accuracy : 0.9292, \tValid  Accuracy : 0.9361,\t Train Loss : 11660.804078001009, \tValid Loss :  2178.9556901324386 , Time for 1000 epochs : 1.9108373509952798\n",
      "Epoch 116999 : Train Accuracy : 0.93096, \tValid  Accuracy : 0.9373,\t Train Loss : 11397.660683339918, \tValid Loss :  2143.4216476603915 , Time for 1000 epochs : 1.6128781989973504\n",
      "Epoch 117999 : Train Accuracy : 0.93342, \tValid  Accuracy : 0.939,\t Train Loss : 11092.911175583533, \tValid Loss :  2108.416356486716 , Time for 1000 epochs : 1.7239734579925425\n",
      "Epoch 118999 : Train Accuracy : 0.93452, \tValid  Accuracy : 0.9392,\t Train Loss : 10952.295962128173, \tValid Loss :  2108.0600755908918 , Time for 1000 epochs : 1.9423783649981488\n",
      "Epoch 119999 : Train Accuracy : 0.93432, \tValid  Accuracy : 0.9373,\t Train Loss : 11012.960277713633, \tValid Loss :  2144.1379509438566 , Time for 1000 epochs : 1.460511804005364\n",
      "Epoch 120999 : Train Accuracy : 0.9328, \tValid  Accuracy : 0.9364,\t Train Loss : 11176.625668632685, \tValid Loss :  2196.8777311082363 , Time for 1000 epochs : 1.5438966109941248\n",
      "Epoch 121999 : Train Accuracy : 0.93132, \tValid  Accuracy : 0.9349,\t Train Loss : 11279.858671542897, \tValid Loss :  2235.054837031875 , Time for 1000 epochs : 2.0078360959887505\n",
      "Epoch 122999 : Train Accuracy : 0.93218, \tValid  Accuracy : 0.9351,\t Train Loss : 11232.914171246515, \tValid Loss :  2242.098202707407 , Time for 1000 epochs : 1.369259798026178\n",
      "Epoch 123999 : Train Accuracy : 0.93394, \tValid  Accuracy : 0.9363,\t Train Loss : 10973.554797104642, \tValid Loss :  2206.475318880995 , Time for 1000 epochs : 1.5713041330163833\n",
      "Epoch 124999 : Train Accuracy : 0.936, \tValid  Accuracy : 0.9383,\t Train Loss : 10647.968085823613, \tValid Loss :  2155.6205131363295 , Time for 1000 epochs : 1.9959574550157413\n",
      "Epoch 125999 : Train Accuracy : 0.93796, \tValid  Accuracy : 0.9399,\t Train Loss : 10422.476685686817, \tValid Loss :  2122.484553927645 , Time for 1000 epochs : 1.3911935380019713\n",
      "Epoch 126999 : Train Accuracy : 0.93788, \tValid  Accuracy : 0.9379,\t Train Loss : 10362.669231186654, \tValid Loss :  2122.509085396105 , Time for 1000 epochs : 1.5058511930110399\n",
      "Epoch 127999 : Train Accuracy : 0.93628, \tValid  Accuracy : 0.9355,\t Train Loss : 10485.200167239866, \tValid Loss :  2158.7632071453645 , Time for 1000 epochs : 1.2946988190233242\n",
      "Epoch 128999 : Train Accuracy : 0.93468, \tValid  Accuracy : 0.9338,\t Train Loss : 10678.29404579359, \tValid Loss :  2206.832416413916 , Time for 1000 epochs : 1.2316921809979249\n",
      "Epoch 129999 : Train Accuracy : 0.93368, \tValid  Accuracy : 0.9332,\t Train Loss : 10797.19651652843, \tValid Loss :  2238.2958845426233 , Time for 1000 epochs : 1.5717265999992378\n",
      "Epoch 130999 : Train Accuracy : 0.93406, \tValid  Accuracy : 0.9331,\t Train Loss : 10782.763664841457, \tValid Loss :  2240.8358112083074 , Time for 1000 epochs : 1.5026625689934008\n",
      "Epoch 131999 : Train Accuracy : 0.9351, \tValid  Accuracy : 0.9339,\t Train Loss : 10660.139072044953, \tValid Loss :  2218.037502013085 , Time for 1000 epochs : 1.162580436997814\n",
      "Epoch 132999 : Train Accuracy : 0.93604, \tValid  Accuracy : 0.9355,\t Train Loss : 10541.274078832455, \tValid Loss :  2193.7018659218816 , Time for 1000 epochs : 1.5672782380133867\n",
      "Epoch 133999 : Train Accuracy : 0.93708, \tValid  Accuracy : 0.9369,\t Train Loss : 10524.596790577678, \tValid Loss :  2187.270555272885 , Time for 1000 epochs : 1.2475833510106895\n",
      "Epoch 134999 : Train Accuracy : 0.93712, \tValid  Accuracy : 0.9381,\t Train Loss : 10583.133655948901, \tValid Loss :  2197.051035870278 , Time for 1000 epochs : 1.2360128220170736\n",
      "Epoch 135999 : Train Accuracy : 0.93632, \tValid  Accuracy : 0.9376,\t Train Loss : 10668.165732599626, \tValid Loss :  2215.768401159574 , Time for 1000 epochs : 2.2881628140166868\n",
      "Epoch 136999 : Train Accuracy : 0.9351, \tValid  Accuracy : 0.9371,\t Train Loss : 10749.212671816753, \tValid Loss :  2238.7056959731526 , Time for 1000 epochs : 1.3870133930176962\n",
      "Epoch 137999 : Train Accuracy : 0.9345, \tValid  Accuracy : 0.9361,\t Train Loss : 10784.159400348934, \tValid Loss :  2254.251017426311 , Time for 1000 epochs : 1.6781342510075774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138999 : Train Accuracy : 0.93464, \tValid  Accuracy : 0.9356,\t Train Loss : 10717.185814146269, \tValid Loss :  2250.4419111793577 , Time for 1000 epochs : 1.2567932470119558\n",
      "Epoch 139999 : Train Accuracy : 0.93604, \tValid  Accuracy : 0.9354,\t Train Loss : 10577.036377134034, \tValid Loss :  2230.67734300099 , Time for 1000 epochs : 1.6598715169820935\n",
      "Epoch 140999 : Train Accuracy : 0.93738, \tValid  Accuracy : 0.9362,\t Train Loss : 10415.621448601929, \tValid Loss :  2203.421586002239 , Time for 1000 epochs : 1.443315729004098\n",
      "Epoch 141999 : Train Accuracy : 0.93816, \tValid  Accuracy : 0.9367,\t Train Loss : 10258.790068108256, \tValid Loss :  2170.76267185042 , Time for 1000 epochs : 1.203809808997903\n",
      "Epoch 142999 : Train Accuracy : 0.93852, \tValid  Accuracy : 0.9391,\t Train Loss : 10162.645515120777, \tValid Loss :  2145.5898539697123 , Time for 1000 epochs : 1.4490944940189365\n",
      "Epoch 143999 : Train Accuracy : 0.9379, \tValid  Accuracy : 0.9397,\t Train Loss : 10146.188974305202, \tValid Loss :  2134.4522852370264 , Time for 1000 epochs : 1.2462973880174104\n",
      "Epoch 144999 : Train Accuracy : 0.93778, \tValid  Accuracy : 0.9393,\t Train Loss : 10175.401930606462, \tValid Loss :  2136.0631720225765 , Time for 1000 epochs : 1.4803855659847613\n",
      "Epoch 145999 : Train Accuracy : 0.93758, \tValid  Accuracy : 0.9397,\t Train Loss : 10188.619417002365, \tValid Loss :  2140.637475671291 , Time for 1000 epochs : 1.542113456001971\n",
      "Epoch 146999 : Train Accuracy : 0.9377, \tValid  Accuracy : 0.9391,\t Train Loss : 10213.549638318696, \tValid Loss :  2150.8015733626617 , Time for 1000 epochs : 2.982975229009753\n",
      "Epoch 147999 : Train Accuracy : 0.93754, \tValid  Accuracy : 0.9383,\t Train Loss : 10241.350387331811, \tValid Loss :  2160.9306008731955 , Time for 1000 epochs : 1.4593473809945863\n",
      "Epoch 148999 : Train Accuracy : 0.93746, \tValid  Accuracy : 0.9378,\t Train Loss : 10254.705635935112, \tValid Loss :  2165.6854173797033 , Time for 1000 epochs : 3.7448898809961975\n",
      "Epoch 149999 : Train Accuracy : 0.9378, \tValid  Accuracy : 0.9379,\t Train Loss : 10274.757945649402, \tValid Loss :  2169.149202685853 , Time for 1000 epochs : 1.6745387270057108\n",
      "Epoch 150999 : Train Accuracy : 0.93814, \tValid  Accuracy : 0.9396,\t Train Loss : 10236.29404941924, \tValid Loss :  2157.4907558860573 , Time for 1000 epochs : 1.4782034360105172\n",
      "Epoch 151999 : Train Accuracy : 0.93946, \tValid  Accuracy : 0.9402,\t Train Loss : 10130.914548613813, \tValid Loss :  2130.811796121584 , Time for 1000 epochs : 1.5907217820058577\n",
      "Epoch 152999 : Train Accuracy : 0.93984, \tValid  Accuracy : 0.9411,\t Train Loss : 9995.575047095801, \tValid Loss :  2099.486952002526 , Time for 1000 epochs : 1.6968517530185636\n",
      "Epoch 153999 : Train Accuracy : 0.9406, \tValid  Accuracy : 0.9416,\t Train Loss : 9874.841632327683, \tValid Loss :  2071.3908842559226 , Time for 1000 epochs : 1.573164364992408\n",
      "Epoch 154999 : Train Accuracy : 0.94086, \tValid  Accuracy : 0.9418,\t Train Loss : 9770.304888034836, \tValid Loss :  2049.291664540234 , Time for 1000 epochs : 1.6913886539987288\n",
      "Epoch 155999 : Train Accuracy : 0.94146, \tValid  Accuracy : 0.9422,\t Train Loss : 9667.370497522617, \tValid Loss :  2030.0610803246675 , Time for 1000 epochs : 1.6858385179948527\n",
      "Epoch 156999 : Train Accuracy : 0.9426, \tValid  Accuracy : 0.9431,\t Train Loss : 9581.887605578242, \tValid Loss :  2012.70042710364 , Time for 1000 epochs : 2.5798097970255185\n",
      "Epoch 157999 : Train Accuracy : 0.94292, \tValid  Accuracy : 0.9435,\t Train Loss : 9548.027673800378, \tValid Loss :  2005.552018712852 , Time for 1000 epochs : 2.3498516239924356\n",
      "Epoch 158999 : Train Accuracy : 0.94256, \tValid  Accuracy : 0.9429,\t Train Loss : 9567.092270647272, \tValid Loss :  2006.8565591474294 , Time for 1000 epochs : 1.384333381021861\n",
      "Epoch 159999 : Train Accuracy : 0.94274, \tValid  Accuracy : 0.9437,\t Train Loss : 9635.354864855532, \tValid Loss :  2014.3941980037002 , Time for 1000 epochs : 1.0436772629909683\n",
      "Epoch 160999 : Train Accuracy : 0.94248, \tValid  Accuracy : 0.9429,\t Train Loss : 9731.131867614788, \tValid Loss :  2027.9657792488435 , Time for 1000 epochs : 1.412306868005544\n",
      "Epoch 161999 : Train Accuracy : 0.94172, \tValid  Accuracy : 0.9414,\t Train Loss : 9812.85622438146, \tValid Loss :  2038.9003777318599 , Time for 1000 epochs : 2.006507104000775\n",
      "Epoch 162999 : Train Accuracy : 0.94162, \tValid  Accuracy : 0.9418,\t Train Loss : 9791.452185695769, \tValid Loss :  2027.9673131883646 , Time for 1000 epochs : 1.4576664280029945\n",
      "Epoch 163999 : Train Accuracy : 0.94226, \tValid  Accuracy : 0.9428,\t Train Loss : 9694.304019743697, \tValid Loss :  2002.8588676927368 , Time for 1000 epochs : 1.055515607004054\n",
      "Epoch 164999 : Train Accuracy : 0.943, \tValid  Accuracy : 0.9442,\t Train Loss : 9588.426453153867, \tValid Loss :  1978.5887944274696 , Time for 1000 epochs : 1.4070507890137378\n",
      "Epoch 165999 : Train Accuracy : 0.94338, \tValid  Accuracy : 0.9448,\t Train Loss : 9568.44913364616, \tValid Loss :  1970.9685646300618 , Time for 1000 epochs : 1.2510382779873908\n",
      "Epoch 166999 : Train Accuracy : 0.94258, \tValid  Accuracy : 0.944,\t Train Loss : 9653.311307901367, \tValid Loss :  1986.6327546930845 , Time for 1000 epochs : 1.0290108150220476\n",
      "Epoch 167999 : Train Accuracy : 0.94174, \tValid  Accuracy : 0.9431,\t Train Loss : 9800.051620345968, \tValid Loss :  2019.8363101157788 , Time for 1000 epochs : 1.0814921729906928\n",
      "Epoch 168999 : Train Accuracy : 0.94068, \tValid  Accuracy : 0.9427,\t Train Loss : 9953.107703487402, \tValid Loss :  2055.1612683257135 , Time for 1000 epochs : 1.415099477977492\n",
      "Epoch 169999 : Train Accuracy : 0.94, \tValid  Accuracy : 0.9407,\t Train Loss : 10024.07720712556, \tValid Loss :  2072.372522233543 , Time for 1000 epochs : 1.6086408559931442\n",
      "Epoch 170999 : Train Accuracy : 0.94042, \tValid  Accuracy : 0.94,\t Train Loss : 9954.446674294662, \tValid Loss :  2063.250610981921 , Time for 1000 epochs : 1.528057813004125\n",
      "Epoch 171999 : Train Accuracy : 0.94166, \tValid  Accuracy : 0.9411,\t Train Loss : 9730.559403510179, \tValid Loss :  2025.0478433994372 , Time for 1000 epochs : 1.5509088649996556\n",
      "Epoch 172999 : Train Accuracy : 0.94338, \tValid  Accuracy : 0.9426,\t Train Loss : 9492.364389067154, \tValid Loss :  1984.6128600169825 , Time for 1000 epochs : 1.8352741179987788\n",
      "Epoch 173999 : Train Accuracy : 0.9435, \tValid  Accuracy : 0.943,\t Train Loss : 9381.709382632189, \tValid Loss :  1968.8242109062548 , Time for 1000 epochs : 1.7126068550278433\n",
      "Epoch 174999 : Train Accuracy : 0.9436, \tValid  Accuracy : 0.9435,\t Train Loss : 9392.857066221506, \tValid Loss :  1977.1011469723874 , Time for 1000 epochs : 1.6718170490057673\n",
      "Epoch 175999 : Train Accuracy : 0.94262, \tValid  Accuracy : 0.9422,\t Train Loss : 9489.47572026056, \tValid Loss :  2002.4193919979052 , Time for 1000 epochs : 2.0523154939874075\n",
      "Epoch 176999 : Train Accuracy : 0.94104, \tValid  Accuracy : 0.9423,\t Train Loss : 9641.233944213893, \tValid Loss :  2036.930637215773 , Time for 1000 epochs : 1.4058980369882192\n",
      "Epoch 177999 : Train Accuracy : 0.9403, \tValid  Accuracy : 0.942,\t Train Loss : 9767.297894349464, \tValid Loss :  2067.5830687310736 , Time for 1000 epochs : 1.6295991329825483\n",
      "Epoch 178999 : Train Accuracy : 0.93958, \tValid  Accuracy : 0.9418,\t Train Loss : 9803.445830315191, \tValid Loss :  2078.2579958429114 , Time for 1000 epochs : 1.8803071900038049\n",
      "Epoch 179999 : Train Accuracy : 0.93966, \tValid  Accuracy : 0.9416,\t Train Loss : 9797.531300245097, \tValid Loss :  2078.3291714125858 , Time for 1000 epochs : 1.4308201850217301\n",
      "Epoch 180999 : Train Accuracy : 0.94008, \tValid  Accuracy : 0.9423,\t Train Loss : 9752.871246963701, \tValid Loss :  2069.5382080388267 , Time for 1000 epochs : 2.236778997001238\n",
      "Epoch 181999 : Train Accuracy : 0.9399, \tValid  Accuracy : 0.9426,\t Train Loss : 9695.364654229708, \tValid Loss :  2056.326203144795 , Time for 1000 epochs : 1.543795718025649\n",
      "Epoch 182999 : Train Accuracy : 0.94104, \tValid  Accuracy : 0.9427,\t Train Loss : 9542.88083237269, \tValid Loss :  2023.90306784725 , Time for 1000 epochs : 1.2994567269925028\n",
      "Epoch 183999 : Train Accuracy : 0.94214, \tValid  Accuracy : 0.944,\t Train Loss : 9349.42340900064, \tValid Loss :  1983.106779134425 , Time for 1000 epochs : 1.5225815930170938\n",
      "Epoch 184999 : Train Accuracy : 0.94374, \tValid  Accuracy : 0.9443,\t Train Loss : 9138.345039795617, \tValid Loss :  1936.3226587811082 , Time for 1000 epochs : 1.7876365380070638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185999 : Train Accuracy : 0.94482, \tValid  Accuracy : 0.9451,\t Train Loss : 8991.144781484385, \tValid Loss :  1899.3666333692317 , Time for 1000 epochs : 1.6771262149850372\n",
      "Epoch 186999 : Train Accuracy : 0.94524, \tValid  Accuracy : 0.9451,\t Train Loss : 8914.300366896656, \tValid Loss :  1874.5084222314858 , Time for 1000 epochs : 1.471729320997838\n",
      "Epoch 187999 : Train Accuracy : 0.94584, \tValid  Accuracy : 0.9456,\t Train Loss : 8923.152434837059, \tValid Loss :  1869.8084829925954 , Time for 1000 epochs : 1.579311374021927\n",
      "Epoch 188999 : Train Accuracy : 0.9452, \tValid  Accuracy : 0.9449,\t Train Loss : 9066.093550918364, \tValid Loss :  1890.6635003753022 , Time for 1000 epochs : 1.462732412997866\n",
      "Epoch 189999 : Train Accuracy : 0.9437, \tValid  Accuracy : 0.9441,\t Train Loss : 9278.769740044503, \tValid Loss :  1925.7833713363452 , Time for 1000 epochs : 1.5498623170133214\n",
      "Epoch 190999 : Train Accuracy : 0.94214, \tValid  Accuracy : 0.9429,\t Train Loss : 9485.791024794786, \tValid Loss :  1960.4671577753818 , Time for 1000 epochs : 1.3392698930110782\n",
      "Epoch 191999 : Train Accuracy : 0.94202, \tValid  Accuracy : 0.9425,\t Train Loss : 9522.50444132039, \tValid Loss :  1962.1151642141388 , Time for 1000 epochs : 1.5533417480182834\n",
      "Epoch 192999 : Train Accuracy : 0.94292, \tValid  Accuracy : 0.9428,\t Train Loss : 9355.705275835324, \tValid Loss :  1927.2332311647313 , Time for 1000 epochs : 1.639948320982512\n",
      "Epoch 193999 : Train Accuracy : 0.94404, \tValid  Accuracy : 0.9444,\t Train Loss : 9125.301210711, \tValid Loss :  1882.0951064902763 , Time for 1000 epochs : 1.7304125259979628\n",
      "Epoch 194999 : Train Accuracy : 0.94556, \tValid  Accuracy : 0.9455,\t Train Loss : 8924.949744249625, \tValid Loss :  1846.0523253431604 , Time for 1000 epochs : 1.592537922988413\n",
      "Epoch 195999 : Train Accuracy : 0.94556, \tValid  Accuracy : 0.9461,\t Train Loss : 8861.536393125507, \tValid Loss :  1834.903116259901 , Time for 1000 epochs : 1.9527286190132145\n",
      "Epoch 196999 : Train Accuracy : 0.94448, \tValid  Accuracy : 0.9456,\t Train Loss : 8950.94545201933, \tValid Loss :  1852.7032510675185 , Time for 1000 epochs : 4.835242022003513\n",
      "Epoch 197999 : Train Accuracy : 0.94354, \tValid  Accuracy : 0.9453,\t Train Loss : 9108.50655124018, \tValid Loss :  1883.2116056431596 , Time for 1000 epochs : 1.293252183997538\n",
      "Epoch 198999 : Train Accuracy : 0.94304, \tValid  Accuracy : 0.9453,\t Train Loss : 9174.842030500397, \tValid Loss :  1897.5046356208518 , Time for 1000 epochs : 1.5547980260162149\n",
      "Epoch 199999 : Train Accuracy : 0.94358, \tValid  Accuracy : 0.9462,\t Train Loss : 9090.845194424042, \tValid Loss :  1885.1038308912055 , Time for 1000 epochs : 1.7396240379894152\n",
      "Epoch 200999 : Train Accuracy : 0.94552, \tValid  Accuracy : 0.9471,\t Train Loss : 8871.475207242407, \tValid Loss :  1850.4125864737166 , Time for 1000 epochs : 1.9023142459918745\n",
      "Epoch 201999 : Train Accuracy : 0.94722, \tValid  Accuracy : 0.949,\t Train Loss : 8604.913775679728, \tValid Loss :  1807.6530834711043 , Time for 1000 epochs : 1.5229789470031392\n",
      "Epoch 202999 : Train Accuracy : 0.94788, \tValid  Accuracy : 0.9487,\t Train Loss : 8407.742248278735, \tValid Loss :  1779.5276913367013 , Time for 1000 epochs : 1.930061718012439\n",
      "Epoch 203999 : Train Accuracy : 0.94862, \tValid  Accuracy : 0.9494,\t Train Loss : 8354.843134524419, \tValid Loss :  1777.269846843307 , Time for 1000 epochs : 2.3421015279891435\n",
      "Epoch 204999 : Train Accuracy : 0.9483, \tValid  Accuracy : 0.9489,\t Train Loss : 8468.94292961586, \tValid Loss :  1806.1633596069275 , Time for 1000 epochs : 1.8442251319938805\n",
      "Epoch 205999 : Train Accuracy : 0.94726, \tValid  Accuracy : 0.9485,\t Train Loss : 8694.903328044906, \tValid Loss :  1858.3648081166077 , Time for 1000 epochs : 1.6805210869933944\n",
      "Epoch 206999 : Train Accuracy : 0.94606, \tValid  Accuracy : 0.9468,\t Train Loss : 8912.808362656355, \tValid Loss :  1912.2509518938296 , Time for 1000 epochs : 1.6260302170121577\n",
      "Epoch 207999 : Train Accuracy : 0.94594, \tValid  Accuracy : 0.9462,\t Train Loss : 8972.527148924377, \tValid Loss :  1937.7488362234687 , Time for 1000 epochs : 2.113696301006712\n",
      "Epoch 208999 : Train Accuracy : 0.94688, \tValid  Accuracy : 0.9477,\t Train Loss : 8873.650986591943, \tValid Loss :  1934.9214950685346 , Time for 1000 epochs : 1.8932018940104172\n",
      "Epoch 209999 : Train Accuracy : 0.94792, \tValid  Accuracy : 0.9471,\t Train Loss : 8730.939098457735, \tValid Loss :  1924.2601208655128 , Time for 1000 epochs : 2.3643356619868428\n",
      "Epoch 210999 : Train Accuracy : 0.94816, \tValid  Accuracy : 0.9468,\t Train Loss : 8649.850783033424, \tValid Loss :  1922.6325355423169 , Time for 1000 epochs : 1.61977890500566\n",
      "Epoch 211999 : Train Accuracy : 0.94796, \tValid  Accuracy : 0.9461,\t Train Loss : 8632.381568468434, \tValid Loss :  1929.4478747829694 , Time for 1000 epochs : 1.6162299849966075\n",
      "Epoch 212999 : Train Accuracy : 0.94766, \tValid  Accuracy : 0.9461,\t Train Loss : 8645.721118534408, \tValid Loss :  1938.7840375584447 , Time for 1000 epochs : 1.6060897930001374\n",
      "Epoch 213999 : Train Accuracy : 0.94732, \tValid  Accuracy : 0.9462,\t Train Loss : 8646.412080728394, \tValid Loss :  1942.6303301604958 , Time for 1000 epochs : 2.012575634988025\n",
      "Epoch 214999 : Train Accuracy : 0.94754, \tValid  Accuracy : 0.9454,\t Train Loss : 8604.870146595584, \tValid Loss :  1937.4803937303873 , Time for 1000 epochs : 1.6300608740129974\n",
      "Epoch 215999 : Train Accuracy : 0.9476, \tValid  Accuracy : 0.9446,\t Train Loss : 8542.052028038883, \tValid Loss :  1923.906583820855 , Time for 1000 epochs : 1.6210944560007192\n",
      "Epoch 216999 : Train Accuracy : 0.94728, \tValid  Accuracy : 0.946,\t Train Loss : 8512.014046587137, \tValid Loss :  1912.567763374142 , Time for 1000 epochs : 2.7032039320038166\n",
      "Epoch 217999 : Train Accuracy : 0.94808, \tValid  Accuracy : 0.9462,\t Train Loss : 8480.429514068926, \tValid Loss :  1901.0769944913213 , Time for 1000 epochs : 1.368521452008281\n",
      "Epoch 218999 : Train Accuracy : 0.94858, \tValid  Accuracy : 0.9469,\t Train Loss : 8427.926053352869, \tValid Loss :  1887.8137576865972 , Time for 1000 epochs : 2.2499036520021036\n",
      "Epoch 219999 : Train Accuracy : 0.94938, \tValid  Accuracy : 0.9463,\t Train Loss : 8354.605424325217, \tValid Loss :  1870.8047373058887 , Time for 1000 epochs : 1.6672369170119055\n",
      "Epoch 220999 : Train Accuracy : 0.94954, \tValid  Accuracy : 0.9475,\t Train Loss : 8298.583429920625, \tValid Loss :  1856.1784695488336 , Time for 1000 epochs : 2.061614820995601\n",
      "Epoch 221999 : Train Accuracy : 0.94948, \tValid  Accuracy : 0.9481,\t Train Loss : 8228.045306155253, \tValid Loss :  1837.8093014607177 , Time for 1000 epochs : 1.53695022300235\n",
      "Epoch 222999 : Train Accuracy : 0.95012, \tValid  Accuracy : 0.9492,\t Train Loss : 8139.621656448556, \tValid Loss :  1815.9954860630742 , Time for 1000 epochs : 1.4408232709974982\n",
      "Epoch 223999 : Train Accuracy : 0.95124, \tValid  Accuracy : 0.9495,\t Train Loss : 7984.941415250062, \tValid Loss :  1781.5134618390935 , Time for 1000 epochs : 1.5810096719942521\n",
      "Epoch 224999 : Train Accuracy : 0.95222, \tValid  Accuracy : 0.9502,\t Train Loss : 7836.085831432857, \tValid Loss :  1748.0760709031151 , Time for 1000 epochs : 1.5411780330177862\n",
      "Epoch 225999 : Train Accuracy : 0.95292, \tValid  Accuracy : 0.9504,\t Train Loss : 7755.329726990433, \tValid Loss :  1729.220048063939 , Time for 1000 epochs : 1.7511324160150252\n",
      "Epoch 226999 : Train Accuracy : 0.9521, \tValid  Accuracy : 0.9502,\t Train Loss : 7810.706284613935, \tValid Loss :  1738.521116320777 , Time for 1000 epochs : 1.6208753210084978\n",
      "Epoch 227999 : Train Accuracy : 0.95058, \tValid  Accuracy : 0.9499,\t Train Loss : 7999.764731478801, \tValid Loss :  1773.7865471387186 , Time for 1000 epochs : 1.5155583570012823\n",
      "Epoch 228999 : Train Accuracy : 0.94838, \tValid  Accuracy : 0.9473,\t Train Loss : 8285.715337865186, \tValid Loss :  1826.4624132637896 , Time for 1000 epochs : 1.6533480540092569\n",
      "Epoch 229999 : Train Accuracy : 0.94652, \tValid  Accuracy : 0.9457,\t Train Loss : 8572.90079005378, \tValid Loss :  1880.0181136085364 , Time for 1000 epochs : 1.3993370309763122\n",
      "Epoch 230999 : Train Accuracy : 0.9457, \tValid  Accuracy : 0.9441,\t Train Loss : 8768.203698286896, \tValid Loss :  1918.1953861145291 , Time for 1000 epochs : 1.6379641439998522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231999 : Train Accuracy : 0.94566, \tValid  Accuracy : 0.9442,\t Train Loss : 8807.712165910507, \tValid Loss :  1930.3076458798341 , Time for 1000 epochs : 2.5605794889852405\n",
      "Epoch 232999 : Train Accuracy : 0.94664, \tValid  Accuracy : 0.9455,\t Train Loss : 8666.91399422484, \tValid Loss :  1910.6288855889304 , Time for 1000 epochs : 1.7592414420214482\n",
      "Epoch 233999 : Train Accuracy : 0.94748, \tValid  Accuracy : 0.9475,\t Train Loss : 8401.710760690956, \tValid Loss :  1867.1226110442062 , Time for 1000 epochs : 1.631573805003427\n",
      "Epoch 234999 : Train Accuracy : 0.94998, \tValid  Accuracy : 0.9489,\t Train Loss : 8139.713335609589, \tValid Loss :  1824.8826243048593 , Time for 1000 epochs : 1.54157161898911\n",
      "Epoch 235999 : Train Accuracy : 0.95132, \tValid  Accuracy : 0.9503,\t Train Loss : 7937.758723381501, \tValid Loss :  1790.0416823307728 , Time for 1000 epochs : 1.3951874939957634\n",
      "Epoch 236999 : Train Accuracy : 0.9512, \tValid  Accuracy : 0.9505,\t Train Loss : 7869.469006457625, \tValid Loss :  1781.454191408001 , Time for 1000 epochs : 1.9885494530026335\n",
      "Epoch 237999 : Train Accuracy : 0.95048, \tValid  Accuracy : 0.9493,\t Train Loss : 7984.5243566760455, \tValid Loss :  1808.1325809199013 , Time for 1000 epochs : 1.6964981509954669\n",
      "Epoch 238999 : Train Accuracy : 0.94918, \tValid  Accuracy : 0.9476,\t Train Loss : 8237.384680305879, \tValid Loss :  1864.0904454964239 , Time for 1000 epochs : 1.2938075929996558\n",
      "Epoch 239999 : Train Accuracy : 0.94778, \tValid  Accuracy : 0.946,\t Train Loss : 8500.797655370154, \tValid Loss :  1923.012071021631 , Time for 1000 epochs : 1.6085383990139235\n",
      "Epoch 240999 : Train Accuracy : 0.94746, \tValid  Accuracy : 0.9451,\t Train Loss : 8661.302390045323, \tValid Loss :  1960.6792813226843 , Time for 1000 epochs : 1.507276529999217\n",
      "Epoch 241999 : Train Accuracy : 0.94722, \tValid  Accuracy : 0.9451,\t Train Loss : 8659.03978913865, \tValid Loss :  1966.8897391775872 , Time for 1000 epochs : 1.9263796379964333\n",
      "Epoch 242999 : Train Accuracy : 0.9483, \tValid  Accuracy : 0.9455,\t Train Loss : 8501.54524245067, \tValid Loss :  1944.6613601896684 , Time for 1000 epochs : 1.9209685889945831\n",
      "Epoch 243999 : Train Accuracy : 0.9494, \tValid  Accuracy : 0.9477,\t Train Loss : 8260.16003900537, \tValid Loss :  1909.969345756787 , Time for 1000 epochs : 1.4653814710036386\n",
      "Epoch 244999 : Train Accuracy : 0.9504, \tValid  Accuracy : 0.9479,\t Train Loss : 8033.315580401827, \tValid Loss :  1881.057295978641 , Time for 1000 epochs : 2.2817409240233246\n",
      "Epoch 245999 : Train Accuracy : 0.9513, \tValid  Accuracy : 0.9479,\t Train Loss : 7821.568121605, \tValid Loss :  1856.5138909485381 , Time for 1000 epochs : 1.7079611340013798\n",
      "Epoch 246999 : Train Accuracy : 0.95184, \tValid  Accuracy : 0.9475,\t Train Loss : 7677.9292981902545, \tValid Loss :  1843.9292554805022 , Time for 1000 epochs : 1.8838025279983412\n",
      "Epoch 247999 : Train Accuracy : 0.9514, \tValid  Accuracy : 0.9471,\t Train Loss : 7671.684974540334, \tValid Loss :  1854.9808139171312 , Time for 1000 epochs : 1.7229709820239805\n",
      "Epoch 248999 : Train Accuracy : 0.95124, \tValid  Accuracy : 0.9451,\t Train Loss : 7784.238541580459, \tValid Loss :  1884.6644582569868 , Time for 1000 epochs : 1.6201278690132312\n",
      "Epoch 249999 : Train Accuracy : 0.95036, \tValid  Accuracy : 0.9428,\t Train Loss : 7952.824663540957, \tValid Loss :  1918.96337315464 , Time for 1000 epochs : 1.8791312490066048\n",
      "Epoch 250999 : Train Accuracy : 0.94994, \tValid  Accuracy : 0.9425,\t Train Loss : 8037.866954898631, \tValid Loss :  1927.2193724859492 , Time for 1000 epochs : 1.452166524977656\n",
      "Epoch 251999 : Train Accuracy : 0.95016, \tValid  Accuracy : 0.9426,\t Train Loss : 8018.828459663907, \tValid Loss :  1909.9474371752758 , Time for 1000 epochs : 1.1822933260118589\n",
      "Epoch 252999 : Train Accuracy : 0.95036, \tValid  Accuracy : 0.943,\t Train Loss : 7943.376268779939, \tValid Loss :  1884.9369781094329 , Time for 1000 epochs : 1.0977971499960404\n",
      "Epoch 253999 : Train Accuracy : 0.9514, \tValid  Accuracy : 0.944,\t Train Loss : 7808.673040642506, \tValid Loss :  1849.0472973017527 , Time for 1000 epochs : 1.3044166050094645\n",
      "Epoch 254999 : Train Accuracy : 0.95218, \tValid  Accuracy : 0.9453,\t Train Loss : 7644.732816274599, \tValid Loss :  1810.286657833268 , Time for 1000 epochs : 1.274581614008639\n",
      "Epoch 255999 : Train Accuracy : 0.95352, \tValid  Accuracy : 0.9466,\t Train Loss : 7540.657770395018, \tValid Loss :  1787.5585427739582 , Time for 1000 epochs : 1.3895462689979468\n",
      "Epoch 256999 : Train Accuracy : 0.95358, \tValid  Accuracy : 0.9478,\t Train Loss : 7507.620401675385, \tValid Loss :  1783.4486168098747 , Time for 1000 epochs : 1.784840565000195\n",
      "Epoch 257999 : Train Accuracy : 0.95406, \tValid  Accuracy : 0.9482,\t Train Loss : 7501.35934150219, \tValid Loss :  1790.4271233890252 , Time for 1000 epochs : 1.3264839769981336\n",
      "Epoch 258999 : Train Accuracy : 0.9543, \tValid  Accuracy : 0.9492,\t Train Loss : 7463.213539920881, \tValid Loss :  1794.0054821130911 , Time for 1000 epochs : 1.236603113997262\n",
      "Epoch 259999 : Train Accuracy : 0.9539, \tValid  Accuracy : 0.9493,\t Train Loss : 7448.216541510618, \tValid Loss :  1802.5545760614393 , Time for 1000 epochs : 1.155539831990609\n",
      "Epoch 260999 : Train Accuracy : 0.95424, \tValid  Accuracy : 0.9492,\t Train Loss : 7457.660272627517, \tValid Loss :  1816.3277470048513 , Time for 1000 epochs : 1.1467115439882036\n",
      "Epoch 261999 : Train Accuracy : 0.95406, \tValid  Accuracy : 0.9492,\t Train Loss : 7496.512548650668, \tValid Loss :  1835.653170476214 , Time for 1000 epochs : 1.1589705329970457\n",
      "Epoch 262999 : Train Accuracy : 0.95392, \tValid  Accuracy : 0.9488,\t Train Loss : 7556.589430352029, \tValid Loss :  1858.7344401238968 , Time for 1000 epochs : 1.0346798930258956\n",
      "Epoch 263999 : Train Accuracy : 0.95326, \tValid  Accuracy : 0.9484,\t Train Loss : 7597.604508916556, \tValid Loss :  1876.2639652751297 , Time for 1000 epochs : 4.267821443005232\n",
      "Epoch 264999 : Train Accuracy : 0.95248, \tValid  Accuracy : 0.9479,\t Train Loss : 7642.345839097518, \tValid Loss :  1891.2553844105933 , Time for 1000 epochs : 1.4702971640217584\n",
      "Epoch 265999 : Train Accuracy : 0.95226, \tValid  Accuracy : 0.9485,\t Train Loss : 7676.10052679194, \tValid Loss :  1902.5052406474038 , Time for 1000 epochs : 1.0732714270125143\n",
      "Epoch 266999 : Train Accuracy : 0.95224, \tValid  Accuracy : 0.9486,\t Train Loss : 7662.438033691924, \tValid Loss :  1902.2147398681623 , Time for 1000 epochs : 1.085107370017795\n",
      "Epoch 267999 : Train Accuracy : 0.95284, \tValid  Accuracy : 0.9497,\t Train Loss : 7564.363171801871, \tValid Loss :  1884.4088994327612 , Time for 1000 epochs : 1.473122321011033\n",
      "Epoch 268999 : Train Accuracy : 0.95418, \tValid  Accuracy : 0.9496,\t Train Loss : 7380.59078754142, \tValid Loss :  1847.0577007605891 , Time for 1000 epochs : 1.6979960890021175\n",
      "Epoch 269999 : Train Accuracy : 0.95556, \tValid  Accuracy : 0.951,\t Train Loss : 7194.680579738167, \tValid Loss :  1807.4760488896643 , Time for 1000 epochs : 1.1401966499979608\n",
      "Epoch 270999 : Train Accuracy : 0.95604, \tValid  Accuracy : 0.9513,\t Train Loss : 7095.204516141049, \tValid Loss :  1782.2541017518317 , Time for 1000 epochs : 0.9553946450178046\n",
      "Epoch 271999 : Train Accuracy : 0.95618, \tValid  Accuracy : 0.9507,\t Train Loss : 7098.204479236653, \tValid Loss :  1775.0791683911475 , Time for 1000 epochs : 1.04432506399462\n",
      "Epoch 272999 : Train Accuracy : 0.95554, \tValid  Accuracy : 0.9496,\t Train Loss : 7177.603393386215, \tValid Loss :  1780.9868799382823 , Time for 1000 epochs : 0.9867377960181329\n",
      "Epoch 273999 : Train Accuracy : 0.95446, \tValid  Accuracy : 0.9478,\t Train Loss : 7296.558614520408, \tValid Loss :  1792.4008106715105 , Time for 1000 epochs : 1.418786463997094\n",
      "Epoch 274999 : Train Accuracy : 0.95374, \tValid  Accuracy : 0.9472,\t Train Loss : 7416.878116968932, \tValid Loss :  1803.8100557847088 , Time for 1000 epochs : 1.1008711899921764\n",
      "Epoch 275999 : Train Accuracy : 0.95344, \tValid  Accuracy : 0.9469,\t Train Loss : 7512.889655192193, \tValid Loss :  1811.966505822962 , Time for 1000 epochs : 1.2481631580158137\n",
      "Epoch 276999 : Train Accuracy : 0.95296, \tValid  Accuracy : 0.9464,\t Train Loss : 7579.057168670477, \tValid Loss :  1816.2370016380617 , Time for 1000 epochs : 1.0317188950139098\n",
      "Epoch 277999 : Train Accuracy : 0.9532, \tValid  Accuracy : 0.9476,\t Train Loss : 7556.2291128202305, \tValid Loss :  1807.3306251435274 , Time for 1000 epochs : 1.3314974560053088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278999 : Train Accuracy : 0.95384, \tValid  Accuracy : 0.9479,\t Train Loss : 7435.216991438619, \tValid Loss :  1782.9315668644495 , Time for 1000 epochs : 1.269394167989958\n",
      "Epoch 279999 : Train Accuracy : 0.95534, \tValid  Accuracy : 0.9496,\t Train Loss : 7254.898893467489, \tValid Loss :  1749.630613371131 , Time for 1000 epochs : 1.0675114399928134\n",
      "Epoch 280999 : Train Accuracy : 0.95654, \tValid  Accuracy : 0.9507,\t Train Loss : 7089.022910904975, \tValid Loss :  1720.6243907973835 , Time for 1000 epochs : 1.0586355310224462\n",
      "Epoch 281999 : Train Accuracy : 0.95706, \tValid  Accuracy : 0.9525,\t Train Loss : 6960.541940994916, \tValid Loss :  1701.4976688481524 , Time for 1000 epochs : 1.201809409976704\n",
      "Epoch 282999 : Train Accuracy : 0.95798, \tValid  Accuracy : 0.9525,\t Train Loss : 6882.958147671657, \tValid Loss :  1693.1746563557513 , Time for 1000 epochs : 1.1101826039957814\n",
      "Epoch 283999 : Train Accuracy : 0.9579, \tValid  Accuracy : 0.9527,\t Train Loss : 6860.416058139752, \tValid Loss :  1697.1395926202958 , Time for 1000 epochs : 1.0502334990014788\n",
      "Epoch 284999 : Train Accuracy : 0.95732, \tValid  Accuracy : 0.953,\t Train Loss : 6856.296429050865, \tValid Loss :  1707.896652526096 , Time for 1000 epochs : 1.3578492990054656\n",
      "Epoch 285999 : Train Accuracy : 0.95732, \tValid  Accuracy : 0.9529,\t Train Loss : 6905.741086252402, \tValid Loss :  1731.302160805112 , Time for 1000 epochs : 1.1091917240119074\n",
      "Epoch 286999 : Train Accuracy : 0.95658, \tValid  Accuracy : 0.9526,\t Train Loss : 7003.930517938223, \tValid Loss :  1763.3549385450683 , Time for 1000 epochs : 1.1105257470044307\n",
      "Epoch 287999 : Train Accuracy : 0.95612, \tValid  Accuracy : 0.9523,\t Train Loss : 7101.725912191117, \tValid Loss :  1794.198011850096 , Time for 1000 epochs : 1.1430651979753748\n",
      "Epoch 288999 : Train Accuracy : 0.95552, \tValid  Accuracy : 0.9525,\t Train Loss : 7166.5355903427435, \tValid Loss :  1815.858819735662 , Time for 1000 epochs : 1.0218208960141055\n",
      "Epoch 289999 : Train Accuracy : 0.95592, \tValid  Accuracy : 0.9523,\t Train Loss : 7158.592349735304, \tValid Loss :  1819.6495041094236 , Time for 1000 epochs : 1.0031768410117365\n",
      "Epoch 290999 : Train Accuracy : 0.95612, \tValid  Accuracy : 0.9518,\t Train Loss : 7100.869152175947, \tValid Loss :  1811.1969561662704 , Time for 1000 epochs : 1.0878285669896286\n",
      "Epoch 291999 : Train Accuracy : 0.9569, \tValid  Accuracy : 0.9524,\t Train Loss : 6989.727978137408, \tValid Loss :  1788.4782272251632 , Time for 1000 epochs : 1.1730841750104446\n",
      "Epoch 292999 : Train Accuracy : 0.9577, \tValid  Accuracy : 0.9528,\t Train Loss : 6874.030425674543, \tValid Loss :  1760.1105987698447 , Time for 1000 epochs : 1.0280579699901864\n",
      "Epoch 293999 : Train Accuracy : 0.95818, \tValid  Accuracy : 0.9537,\t Train Loss : 6803.7419781107055, \tValid Loss :  1735.1928231051422 , Time for 1000 epochs : 1.0837429419916589\n",
      "Epoch 294999 : Train Accuracy : 0.95848, \tValid  Accuracy : 0.9536,\t Train Loss : 6802.520820982095, \tValid Loss :  1722.752267291446 , Time for 1000 epochs : 1.0401950270170346\n",
      "Epoch 295999 : Train Accuracy : 0.9585, \tValid  Accuracy : 0.954,\t Train Loss : 6821.818440748504, \tValid Loss :  1719.3679682229615 , Time for 1000 epochs : 1.0498514709761366\n",
      "Epoch 296999 : Train Accuracy : 0.95862, \tValid  Accuracy : 0.954,\t Train Loss : 6838.205644491981, \tValid Loss :  1717.2129349529205 , Time for 1000 epochs : 1.616242718999274\n",
      "Epoch 297999 : Train Accuracy : 0.95836, \tValid  Accuracy : 0.9541,\t Train Loss : 6827.449843244669, \tValid Loss :  1713.7095553924685 , Time for 1000 epochs : 2.0734829250141047\n",
      "Epoch 298999 : Train Accuracy : 0.95846, \tValid  Accuracy : 0.9539,\t Train Loss : 6777.685346743967, \tValid Loss :  1706.226344994832 , Time for 1000 epochs : 1.3815503609948792\n",
      "Epoch 299999 : Train Accuracy : 0.95848, \tValid  Accuracy : 0.9535,\t Train Loss : 6710.965259446301, \tValid Loss :  1698.8860818752655 , Time for 1000 epochs : 2.1590522050100844\n",
      "Epoch 300999 : Train Accuracy : 0.95868, \tValid  Accuracy : 0.9526,\t Train Loss : 6642.343398457632, \tValid Loss :  1695.0864538967314 , Time for 1000 epochs : 2.461453218013048\n",
      "Epoch 301999 : Train Accuracy : 0.95892, \tValid  Accuracy : 0.953,\t Train Loss : 6595.965316876624, \tValid Loss :  1699.5963676068995 , Time for 1000 epochs : 3.3377967870037537\n",
      "Epoch 302999 : Train Accuracy : 0.9586, \tValid  Accuracy : 0.9514,\t Train Loss : 6610.893373088298, \tValid Loss :  1719.3672425953032 , Time for 1000 epochs : 1.4817082539957482\n",
      "Epoch 303999 : Train Accuracy : 0.95864, \tValid  Accuracy : 0.9511,\t Train Loss : 6677.552896091713, \tValid Loss :  1747.039246216033 , Time for 1000 epochs : 1.606342498009326\n",
      "Epoch 304999 : Train Accuracy : 0.9579, \tValid  Accuracy : 0.9506,\t Train Loss : 6751.5093837351105, \tValid Loss :  1772.8384929815393 , Time for 1000 epochs : 1.491564969997853\n",
      "Epoch 305999 : Train Accuracy : 0.95778, \tValid  Accuracy : 0.9505,\t Train Loss : 6788.833996453495, \tValid Loss :  1787.9189686210082 , Time for 1000 epochs : 1.4410660919966176\n",
      "Epoch 306999 : Train Accuracy : 0.9581, \tValid  Accuracy : 0.9508,\t Train Loss : 6765.369246439066, \tValid Loss :  1788.8353477279138 , Time for 1000 epochs : 1.741849332000129\n",
      "Epoch 307999 : Train Accuracy : 0.95874, \tValid  Accuracy : 0.9514,\t Train Loss : 6694.362874615706, \tValid Loss :  1777.878622284526 , Time for 1000 epochs : 1.448255942988908\n",
      "Epoch 308999 : Train Accuracy : 0.95926, \tValid  Accuracy : 0.9523,\t Train Loss : 6583.47643840842, \tValid Loss :  1752.6360452687154 , Time for 1000 epochs : 1.5833895049872808\n",
      "Epoch 309999 : Train Accuracy : 0.95952, \tValid  Accuracy : 0.9528,\t Train Loss : 6496.783091843208, \tValid Loss :  1726.7207273660943 , Time for 1000 epochs : 1.802098759013461\n",
      "Epoch 310999 : Train Accuracy : 0.95946, \tValid  Accuracy : 0.9524,\t Train Loss : 6483.735548527571, \tValid Loss :  1713.262916607967 , Time for 1000 epochs : 2.4527016829815693\n",
      "Epoch 311999 : Train Accuracy : 0.95902, \tValid  Accuracy : 0.9523,\t Train Loss : 6532.714299379109, \tValid Loss :  1712.5220658437333 , Time for 1000 epochs : 1.5751553179870825\n",
      "Epoch 312999 : Train Accuracy : 0.95852, \tValid  Accuracy : 0.9523,\t Train Loss : 6579.419941545272, \tValid Loss :  1713.5652943330401 , Time for 1000 epochs : 1.6934253119979985\n",
      "Epoch 313999 : Train Accuracy : 0.95802, \tValid  Accuracy : 0.952,\t Train Loss : 6605.248126667856, \tValid Loss :  1712.0586101502365 , Time for 1000 epochs : 1.693111881002551\n",
      "Epoch 314999 : Train Accuracy : 0.9582, \tValid  Accuracy : 0.9523,\t Train Loss : 6583.572039369581, \tValid Loss :  1703.6955344355538 , Time for 1000 epochs : 1.834075089020189\n",
      "Epoch 315999 : Train Accuracy : 0.95918, \tValid  Accuracy : 0.9526,\t Train Loss : 6507.04943198691, \tValid Loss :  1687.186025631855 , Time for 1000 epochs : 1.636297828023089\n",
      "Epoch 316999 : Train Accuracy : 0.9601, \tValid  Accuracy : 0.9534,\t Train Loss : 6391.68964726493, \tValid Loss :  1666.0377197414086 , Time for 1000 epochs : 1.8647681130096316\n",
      "Epoch 317999 : Train Accuracy : 0.9606, \tValid  Accuracy : 0.9546,\t Train Loss : 6301.020647611851, \tValid Loss :  1648.7091444557484 , Time for 1000 epochs : 1.4229660150012933\n",
      "Epoch 318999 : Train Accuracy : 0.96152, \tValid  Accuracy : 0.955,\t Train Loss : 6220.2079641169785, \tValid Loss :  1635.9807765373105 , Time for 1000 epochs : 1.347238611022476\n",
      "Epoch 319999 : Train Accuracy : 0.96182, \tValid  Accuracy : 0.9548,\t Train Loss : 6183.305599253173, \tValid Loss :  1633.9834460830457 , Time for 1000 epochs : 1.7085513719939627\n",
      "Epoch 320999 : Train Accuracy : 0.96138, \tValid  Accuracy : 0.9547,\t Train Loss : 6209.220653685896, \tValid Loss :  1644.7043700020101 , Time for 1000 epochs : 1.3196885939978529\n",
      "Epoch 321999 : Train Accuracy : 0.96074, \tValid  Accuracy : 0.9541,\t Train Loss : 6296.432020049319, \tValid Loss :  1667.7496259339027 , Time for 1000 epochs : 7.344485521985916\n",
      "Epoch 322999 : Train Accuracy : 0.96028, \tValid  Accuracy : 0.9534,\t Train Loss : 6422.5515529772565, \tValid Loss :  1698.6879091495914 , Time for 1000 epochs : 1.6338677169987932\n",
      "Epoch 323999 : Train Accuracy : 0.95986, \tValid  Accuracy : 0.9523,\t Train Loss : 6528.599356943516, \tValid Loss :  1726.533696509868 , Time for 1000 epochs : 5.32218487400678\n",
      "Epoch 324999 : Train Accuracy : 0.95982, \tValid  Accuracy : 0.9522,\t Train Loss : 6572.250232491375, \tValid Loss :  1741.0627458345557 , Time for 1000 epochs : 1.6782109460036736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325999 : Train Accuracy : 0.95982, \tValid  Accuracy : 0.9512,\t Train Loss : 6540.123151661706, \tValid Loss :  1738.3592891625415 , Time for 1000 epochs : 1.6089662309968844\n",
      "Epoch 326999 : Train Accuracy : 0.96028, \tValid  Accuracy : 0.9516,\t Train Loss : 6471.488641209957, \tValid Loss :  1726.382190725908 , Time for 1000 epochs : 1.8041004099941347\n",
      "Epoch 327999 : Train Accuracy : 0.96082, \tValid  Accuracy : 0.9521,\t Train Loss : 6348.169155728247, \tValid Loss :  1702.498930158291 , Time for 1000 epochs : 1.4149634360219352\n",
      "Epoch 328999 : Train Accuracy : 0.96156, \tValid  Accuracy : 0.9534,\t Train Loss : 6209.2397748867, \tValid Loss :  1674.5133097267358 , Time for 1000 epochs : 1.3958206989918835\n",
      "Epoch 329999 : Train Accuracy : 0.96206, \tValid  Accuracy : 0.9543,\t Train Loss : 6119.477095254839, \tValid Loss :  1655.4625046296044 , Time for 1000 epochs : 1.7831763389986008\n",
      "Epoch 330999 : Train Accuracy : 0.96172, \tValid  Accuracy : 0.9545,\t Train Loss : 6093.999703375992, \tValid Loss :  1648.2398735175734 , Time for 1000 epochs : 1.7888005080167204\n",
      "Epoch 331999 : Train Accuracy : 0.96192, \tValid  Accuracy : 0.9544,\t Train Loss : 6128.720126749069, \tValid Loss :  1651.6521952489993 , Time for 1000 epochs : 1.376263760990696\n",
      "Epoch 332999 : Train Accuracy : 0.96158, \tValid  Accuracy : 0.9541,\t Train Loss : 6184.776117308629, \tValid Loss :  1660.6743358695928 , Time for 1000 epochs : 1.5002112559741363\n",
      "Epoch 333999 : Train Accuracy : 0.96126, \tValid  Accuracy : 0.9538,\t Train Loss : 6239.146831570785, \tValid Loss :  1670.082445853077 , Time for 1000 epochs : 1.5943754990003072\n",
      "Epoch 334999 : Train Accuracy : 0.9613, \tValid  Accuracy : 0.9529,\t Train Loss : 6292.453266792905, \tValid Loss :  1679.1889009347458 , Time for 1000 epochs : 1.930015777994413\n",
      "Epoch 335999 : Train Accuracy : 0.96116, \tValid  Accuracy : 0.9529,\t Train Loss : 6325.783745242963, \tValid Loss :  1684.7625552437985 , Time for 1000 epochs : 1.806493509997381\n",
      "Epoch 336999 : Train Accuracy : 0.96102, \tValid  Accuracy : 0.9531,\t Train Loss : 6334.275529280003, \tValid Loss :  1685.9887457183145 , Time for 1000 epochs : 1.8255043519893661\n",
      "Epoch 337999 : Train Accuracy : 0.96118, \tValid  Accuracy : 0.9541,\t Train Loss : 6316.758125358033, \tValid Loss :  1681.8640580195872 , Time for 1000 epochs : 1.359696883999277\n",
      "Epoch 338999 : Train Accuracy : 0.96132, \tValid  Accuracy : 0.954,\t Train Loss : 6284.437911757613, \tValid Loss :  1674.5568685751211 , Time for 1000 epochs : 1.9977346939849667\n",
      "Epoch 339999 : Train Accuracy : 0.9617, \tValid  Accuracy : 0.9542,\t Train Loss : 6239.369099072892, \tValid Loss :  1665.1655180948746 , Time for 1000 epochs : 1.7083289200090803\n",
      "Epoch 340999 : Train Accuracy : 0.96192, \tValid  Accuracy : 0.9539,\t Train Loss : 6196.6714687614885, \tValid Loss :  1656.967835161633 , Time for 1000 epochs : 1.6889748040121049\n",
      "Epoch 341999 : Train Accuracy : 0.96214, \tValid  Accuracy : 0.9545,\t Train Loss : 6154.730859085786, \tValid Loss :  1648.5980459037974 , Time for 1000 epochs : 1.639563928998541\n",
      "Epoch 342999 : Train Accuracy : 0.96208, \tValid  Accuracy : 0.9558,\t Train Loss : 6129.6658999463, \tValid Loss :  1642.9169270135208 , Time for 1000 epochs : 1.5249876320012845\n",
      "Epoch 343999 : Train Accuracy : 0.9619, \tValid  Accuracy : 0.9556,\t Train Loss : 6132.471738692221, \tValid Loss :  1642.497820750807 , Time for 1000 epochs : 1.9239769729902036\n",
      "Epoch 344999 : Train Accuracy : 0.9618, \tValid  Accuracy : 0.9552,\t Train Loss : 6146.6841161414495, \tValid Loss :  1644.2846988764973 , Time for 1000 epochs : 1.6465683379792608\n",
      "Epoch 345999 : Train Accuracy : 0.96156, \tValid  Accuracy : 0.9548,\t Train Loss : 6162.807381480094, \tValid Loss :  1646.03552286471 , Time for 1000 epochs : 1.627754345012363\n",
      "Epoch 346999 : Train Accuracy : 0.96138, \tValid  Accuracy : 0.9535,\t Train Loss : 6174.872997281236, \tValid Loss :  1648.1083652750622 , Time for 1000 epochs : 1.3993296500120778\n",
      "Epoch 347999 : Train Accuracy : 0.9615, \tValid  Accuracy : 0.954,\t Train Loss : 6165.29817045627, \tValid Loss :  1648.4042331183487 , Time for 1000 epochs : 1.686512385000242\n",
      "Epoch 348999 : Train Accuracy : 0.96188, \tValid  Accuracy : 0.9545,\t Train Loss : 6144.985624344447, \tValid Loss :  1646.7930655195212 , Time for 1000 epochs : 1.7700851309928112\n",
      "Epoch 349999 : Train Accuracy : 0.96266, \tValid  Accuracy : 0.9538,\t Train Loss : 6105.533254870645, \tValid Loss :  1642.1076580735769 , Time for 1000 epochs : 1.349837246001698\n",
      "Epoch 350999 : Train Accuracy : 0.96274, \tValid  Accuracy : 0.9548,\t Train Loss : 6063.705206704889, \tValid Loss :  1637.721762492075 , Time for 1000 epochs : 1.6187093509943224\n",
      "Epoch 351999 : Train Accuracy : 0.96368, \tValid  Accuracy : 0.9546,\t Train Loss : 5989.069414397776, \tValid Loss :  1625.016220757669 , Time for 1000 epochs : 1.611540211015381\n",
      "Epoch 352999 : Train Accuracy : 0.96426, \tValid  Accuracy : 0.9551,\t Train Loss : 5905.855993944279, \tValid Loss :  1607.7052550012936 , Time for 1000 epochs : 1.5348940749827307\n",
      "Epoch 353999 : Train Accuracy : 0.9645, \tValid  Accuracy : 0.956,\t Train Loss : 5838.370895272328, \tValid Loss :  1592.1445266449377 , Time for 1000 epochs : 1.7698106379830278\n",
      "Epoch 354999 : Train Accuracy : 0.96464, \tValid  Accuracy : 0.9572,\t Train Loss : 5799.182787676824, \tValid Loss :  1580.9833885347068 , Time for 1000 epochs : 1.4866466099920217\n",
      "Epoch 355999 : Train Accuracy : 0.96424, \tValid  Accuracy : 0.9581,\t Train Loss : 5794.679200581632, \tValid Loss :  1576.0667886520903 , Time for 1000 epochs : 1.4095120560086798\n",
      "Epoch 356999 : Train Accuracy : 0.9637, \tValid  Accuracy : 0.9576,\t Train Loss : 5822.056408756347, \tValid Loss :  1578.852584581243 , Time for 1000 epochs : 1.7594190520176198\n",
      "Epoch 357999 : Train Accuracy : 0.96304, \tValid  Accuracy : 0.9568,\t Train Loss : 5865.288318650379, \tValid Loss :  1586.42460234294 , Time for 1000 epochs : 1.9844416310079396\n",
      "Epoch 358999 : Train Accuracy : 0.96268, \tValid  Accuracy : 0.9562,\t Train Loss : 5907.536283960066, \tValid Loss :  1593.5853873146677 , Time for 1000 epochs : 1.4052128080220427\n",
      "Epoch 359999 : Train Accuracy : 0.96242, \tValid  Accuracy : 0.9562,\t Train Loss : 5934.381920088377, \tValid Loss :  1599.5111188801825 , Time for 1000 epochs : 3.459173429000657\n",
      "Epoch 360999 : Train Accuracy : 0.9622, \tValid  Accuracy : 0.9556,\t Train Loss : 5963.608030176358, \tValid Loss :  1606.9184933640395 , Time for 1000 epochs : 2.2654613589984365\n",
      "Epoch 361999 : Train Accuracy : 0.9626, \tValid  Accuracy : 0.9561,\t Train Loss : 5957.653791727452, \tValid Loss :  1610.1662986923698 , Time for 1000 epochs : 2.3758219330047723\n",
      "Epoch 362999 : Train Accuracy : 0.96312, \tValid  Accuracy : 0.9558,\t Train Loss : 5904.621362284639, \tValid Loss :  1608.1228874495248 , Time for 1000 epochs : 1.5109270499960985\n",
      "Epoch 363999 : Train Accuracy : 0.96354, \tValid  Accuracy : 0.9554,\t Train Loss : 5829.9290178068795, \tValid Loss :  1605.431661742411 , Time for 1000 epochs : 1.7192329310055356\n",
      "Epoch 364999 : Train Accuracy : 0.96406, \tValid  Accuracy : 0.9558,\t Train Loss : 5754.852508825953, \tValid Loss :  1603.72098253281 , Time for 1000 epochs : 1.4963906880002469\n",
      "Epoch 365999 : Train Accuracy : 0.96438, \tValid  Accuracy : 0.9561,\t Train Loss : 5695.397323535585, \tValid Loss :  1604.9966307516097 , Time for 1000 epochs : 1.372425875015324\n",
      "Epoch 366999 : Train Accuracy : 0.96432, \tValid  Accuracy : 0.9563,\t Train Loss : 5669.871876543835, \tValid Loss :  1609.738386741993 , Time for 1000 epochs : 1.6963039619731717\n",
      "Epoch 367999 : Train Accuracy : 0.96434, \tValid  Accuracy : 0.9557,\t Train Loss : 5671.957636646875, \tValid Loss :  1614.7112368455907 , Time for 1000 epochs : 1.5535622340103146\n",
      "Epoch 368999 : Train Accuracy : 0.96434, \tValid  Accuracy : 0.9549,\t Train Loss : 5686.391272259384, \tValid Loss :  1617.7992001230402 , Time for 1000 epochs : 1.7134189630160108\n",
      "Epoch 369999 : Train Accuracy : 0.96452, \tValid  Accuracy : 0.9549,\t Train Loss : 5694.363617200877, \tValid Loss :  1615.9567073255487 , Time for 1000 epochs : 1.6514057690219488\n",
      "Epoch 370999 : Train Accuracy : 0.96484, \tValid  Accuracy : 0.9549,\t Train Loss : 5688.959095118331, \tValid Loss :  1607.75795195453 , Time for 1000 epochs : 1.4277034210099373\n",
      "Epoch 371999 : Train Accuracy : 0.96502, \tValid  Accuracy : 0.9555,\t Train Loss : 5669.604526646832, \tValid Loss :  1593.4183297452582 , Time for 1000 epochs : 1.3537036829802673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372999 : Train Accuracy : 0.96506, \tValid  Accuracy : 0.9558,\t Train Loss : 5660.443510722478, \tValid Loss :  1579.492278610961 , Time for 1000 epochs : 1.6428420380107127\n",
      "Epoch 373999 : Train Accuracy : 0.96482, \tValid  Accuracy : 0.9559,\t Train Loss : 5672.806154881141, \tValid Loss :  1569.1069031406957 , Time for 1000 epochs : 1.5871098760107998\n",
      "Epoch 374999 : Train Accuracy : 0.96436, \tValid  Accuracy : 0.9563,\t Train Loss : 5695.7524897233425, \tValid Loss :  1563.0244350849066 , Time for 1000 epochs : 1.3938324690097943\n",
      "Epoch 375999 : Train Accuracy : 0.96424, \tValid  Accuracy : 0.957,\t Train Loss : 5730.687827918973, \tValid Loss :  1561.2576606269085 , Time for 1000 epochs : 1.4904822560201865\n",
      "Epoch 376999 : Train Accuracy : 0.96414, \tValid  Accuracy : 0.957,\t Train Loss : 5750.315988075615, \tValid Loss :  1560.3666760829656 , Time for 1000 epochs : 1.5709741169994231\n",
      "Epoch 377999 : Train Accuracy : 0.96412, \tValid  Accuracy : 0.9566,\t Train Loss : 5757.007306969347, \tValid Loss :  1559.0521778082789 , Time for 1000 epochs : 1.9102491080120672\n",
      "Epoch 378999 : Train Accuracy : 0.96372, \tValid  Accuracy : 0.9569,\t Train Loss : 5752.318260404222, \tValid Loss :  1558.23473604888 , Time for 1000 epochs : 2.0555597269849386\n",
      "Epoch 379999 : Train Accuracy : 0.96442, \tValid  Accuracy : 0.9575,\t Train Loss : 5728.114500917972, \tValid Loss :  1555.8525248052817 , Time for 1000 epochs : 2.0530438819841947\n",
      "Epoch 380999 : Train Accuracy : 0.96472, \tValid  Accuracy : 0.958,\t Train Loss : 5686.35029827664, \tValid Loss :  1553.7678078908466 , Time for 1000 epochs : 1.6594009439868387\n",
      "Epoch 381999 : Train Accuracy : 0.96548, \tValid  Accuracy : 0.9574,\t Train Loss : 5622.082104183943, \tValid Loss :  1551.5288550145137 , Time for 1000 epochs : 1.4733597110025585\n",
      "Epoch 382999 : Train Accuracy : 0.96568, \tValid  Accuracy : 0.9567,\t Train Loss : 5559.903797662616, \tValid Loss :  1553.9052634529435 , Time for 1000 epochs : 1.5942616959800944\n",
      "Epoch 383999 : Train Accuracy : 0.96578, \tValid  Accuracy : 0.9565,\t Train Loss : 5530.299517801001, \tValid Loss :  1564.4872747834888 , Time for 1000 epochs : 1.7330183789890725\n",
      "Epoch 384999 : Train Accuracy : 0.9659, \tValid  Accuracy : 0.9563,\t Train Loss : 5514.080780866692, \tValid Loss :  1577.389642457786 , Time for 1000 epochs : 1.2814034750044812\n",
      "Epoch 385999 : Train Accuracy : 0.96596, \tValid  Accuracy : 0.9558,\t Train Loss : 5511.014771156751, \tValid Loss :  1592.9842221179363 , Time for 1000 epochs : 1.5967817029741127\n",
      "Epoch 386999 : Train Accuracy : 0.96586, \tValid  Accuracy : 0.9554,\t Train Loss : 5510.56891412275, \tValid Loss :  1607.5590782018428 , Time for 1000 epochs : 1.339251928991871\n",
      "Epoch 387999 : Train Accuracy : 0.96598, \tValid  Accuracy : 0.9554,\t Train Loss : 5517.54351975916, \tValid Loss :  1619.978930189456 , Time for 1000 epochs : 1.5907735049840994\n",
      "Epoch 388999 : Train Accuracy : 0.96594, \tValid  Accuracy : 0.9546,\t Train Loss : 5529.8921755991, \tValid Loss :  1630.5740041400902 , Time for 1000 epochs : 1.303458689013496\n",
      "Epoch 389999 : Train Accuracy : 0.96574, \tValid  Accuracy : 0.9551,\t Train Loss : 5556.619386555852, \tValid Loss :  1639.6456597506549 , Time for 1000 epochs : 1.0516466289991513\n",
      "Epoch 390999 : Train Accuracy : 0.9655, \tValid  Accuracy : 0.9553,\t Train Loss : 5588.233024691659, \tValid Loss :  1644.5251998790534 , Time for 1000 epochs : 1.4974172950023785\n",
      "Epoch 391999 : Train Accuracy : 0.96522, \tValid  Accuracy : 0.9554,\t Train Loss : 5604.42745781253, \tValid Loss :  1642.2145704813177 , Time for 1000 epochs : 1.452179977990454\n",
      "Epoch 392999 : Train Accuracy : 0.96546, \tValid  Accuracy : 0.9553,\t Train Loss : 5603.777532691598, \tValid Loss :  1636.839193640237 , Time for 1000 epochs : 1.810630313004367\n",
      "Epoch 393999 : Train Accuracy : 0.96564, \tValid  Accuracy : 0.955,\t Train Loss : 5588.200049464975, \tValid Loss :  1628.9298715158798 , Time for 1000 epochs : 1.7405569649999961\n",
      "Epoch 394999 : Train Accuracy : 0.96602, \tValid  Accuracy : 0.9554,\t Train Loss : 5560.41463613849, \tValid Loss :  1618.3521750402988 , Time for 1000 epochs : 1.346236145007424\n",
      "Epoch 395999 : Train Accuracy : 0.96614, \tValid  Accuracy : 0.9563,\t Train Loss : 5517.09029352262, \tValid Loss :  1605.0216421625837 , Time for 1000 epochs : 1.3876819079741836\n",
      "Epoch 396999 : Train Accuracy : 0.9664, \tValid  Accuracy : 0.9562,\t Train Loss : 5478.112137027143, \tValid Loss :  1592.6890786181946 , Time for 1000 epochs : 1.9484337260073517\n",
      "Epoch 397999 : Train Accuracy : 0.96646, \tValid  Accuracy : 0.9563,\t Train Loss : 5458.475157583106, \tValid Loss :  1583.7312925954222 , Time for 1000 epochs : 1.3975308029912412\n",
      "Epoch 398999 : Train Accuracy : 0.96642, \tValid  Accuracy : 0.9558,\t Train Loss : 5473.2607314655315, \tValid Loss :  1582.6017334109297 , Time for 1000 epochs : 1.7117407979967538\n",
      "Epoch 399999 : Train Accuracy : 0.96574, \tValid  Accuracy : 0.9557,\t Train Loss : 5521.583225689254, \tValid Loss :  1588.0236163357813 , Time for 1000 epochs : 1.381802099000197\n",
      "Epoch 400999 : Train Accuracy : 0.96518, \tValid  Accuracy : 0.9562,\t Train Loss : 5568.556057035586, \tValid Loss :  1593.7231274426465 , Time for 1000 epochs : 1.318735878012376\n",
      "Epoch 401999 : Train Accuracy : 0.96508, \tValid  Accuracy : 0.9559,\t Train Loss : 5574.675976524007, \tValid Loss :  1594.5980043614559 , Time for 1000 epochs : 2.1643545089755207\n",
      "Epoch 402999 : Train Accuracy : 0.96552, \tValid  Accuracy : 0.9557,\t Train Loss : 5534.54452811022, \tValid Loss :  1590.2386485910388 , Time for 1000 epochs : 1.330561715993099\n",
      "Epoch 403999 : Train Accuracy : 0.9662, \tValid  Accuracy : 0.9561,\t Train Loss : 5454.0849045457, \tValid Loss :  1581.0127343290635 , Time for 1000 epochs : 1.0721628829778638\n",
      "Epoch 404999 : Train Accuracy : 0.96648, \tValid  Accuracy : 0.9565,\t Train Loss : 5380.557483376192, \tValid Loss :  1573.7201454952033 , Time for 1000 epochs : 1.133991373993922\n",
      "Epoch 405999 : Train Accuracy : 0.96726, \tValid  Accuracy : 0.9573,\t Train Loss : 5306.6742933143705, \tValid Loss :  1568.390508326021 , Time for 1000 epochs : 1.1843613079981878\n",
      "Epoch 406999 : Train Accuracy : 0.96786, \tValid  Accuracy : 0.9577,\t Train Loss : 5240.393727813007, \tValid Loss :  1565.6960711331667 , Time for 1000 epochs : 1.5130717099818867\n",
      "Epoch 407999 : Train Accuracy : 0.96814, \tValid  Accuracy : 0.9582,\t Train Loss : 5197.574984092058, \tValid Loss :  1568.379422469363 , Time for 1000 epochs : 1.565181842976017\n",
      "Epoch 408999 : Train Accuracy : 0.96772, \tValid  Accuracy : 0.9574,\t Train Loss : 5195.915465339168, \tValid Loss :  1579.289072287414 , Time for 1000 epochs : 1.0384026840038132\n",
      "Epoch 409999 : Train Accuracy : 0.96736, \tValid  Accuracy : 0.957,\t Train Loss : 5238.066394172194, \tValid Loss :  1596.1457485051128 , Time for 1000 epochs : 1.0155175269756\n",
      "Epoch 410999 : Train Accuracy : 0.96678, \tValid  Accuracy : 0.9561,\t Train Loss : 5296.441915949097, \tValid Loss :  1613.1352082098306 , Time for 1000 epochs : 1.0159294030163437\n",
      "Epoch 411999 : Train Accuracy : 0.96702, \tValid  Accuracy : 0.9566,\t Train Loss : 5319.639787968219, \tValid Loss :  1618.8332804826377 , Time for 1000 epochs : 1.3473129679914564\n",
      "Epoch 412999 : Train Accuracy : 0.96734, \tValid  Accuracy : 0.9568,\t Train Loss : 5301.797911295986, \tValid Loss :  1613.736002216132 , Time for 1000 epochs : 1.438513133005472\n",
      "Epoch 413999 : Train Accuracy : 0.96788, \tValid  Accuracy : 0.9572,\t Train Loss : 5268.561091652195, \tValid Loss :  1603.8286717978838 , Time for 1000 epochs : 2.384917643008521\n",
      "Epoch 414999 : Train Accuracy : 0.96778, \tValid  Accuracy : 0.9567,\t Train Loss : 5233.142613801493, \tValid Loss :  1592.1680880953386 , Time for 1000 epochs : 1.0202870139910374\n",
      "Epoch 415999 : Train Accuracy : 0.96766, \tValid  Accuracy : 0.9569,\t Train Loss : 5218.655311908276, \tValid Loss :  1582.05864532469 , Time for 1000 epochs : 1.2517352389986627\n",
      "Epoch 416999 : Train Accuracy : 0.9673, \tValid  Accuracy : 0.957,\t Train Loss : 5221.755409202586, \tValid Loss :  1575.4169936810888 , Time for 1000 epochs : 1.1713592390005942\n",
      "Epoch 417999 : Train Accuracy : 0.96692, \tValid  Accuracy : 0.9575,\t Train Loss : 5241.635954464044, \tValid Loss :  1573.151209041277 , Time for 1000 epochs : 4.861484009976266\n",
      "Epoch 418999 : Train Accuracy : 0.96626, \tValid  Accuracy : 0.957,\t Train Loss : 5275.8621801769295, \tValid Loss :  1574.7251684542894 , Time for 1000 epochs : 1.1836597539950162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419999 : Train Accuracy : 0.96594, \tValid  Accuracy : 0.9566,\t Train Loss : 5304.336370234045, \tValid Loss :  1576.8097823039313 , Time for 1000 epochs : 1.3617110770137515\n",
      "Epoch 420999 : Train Accuracy : 0.96586, \tValid  Accuracy : 0.9562,\t Train Loss : 5327.604692674115, \tValid Loss :  1579.2997892220837 , Time for 1000 epochs : 1.0320294879784342\n",
      "Epoch 421999 : Train Accuracy : 0.96596, \tValid  Accuracy : 0.9558,\t Train Loss : 5320.31946483123, \tValid Loss :  1577.2366084475032 , Time for 1000 epochs : 1.1406025789910927\n",
      "Epoch 422999 : Train Accuracy : 0.96638, \tValid  Accuracy : 0.9557,\t Train Loss : 5282.606428353957, \tValid Loss :  1570.1725818504717 , Time for 1000 epochs : 3.1949529830017127\n",
      "Epoch 423999 : Train Accuracy : 0.96674, \tValid  Accuracy : 0.9561,\t Train Loss : 5233.423378399919, \tValid Loss :  1561.6774432942955 , Time for 1000 epochs : 1.1463459490041714\n",
      "Epoch 424999 : Train Accuracy : 0.9674, \tValid  Accuracy : 0.9563,\t Train Loss : 5174.964508340166, \tValid Loss :  1552.5868109551639 , Time for 1000 epochs : 0.9944774950272404\n",
      "Epoch 425999 : Train Accuracy : 0.96766, \tValid  Accuracy : 0.9569,\t Train Loss : 5134.608523176457, \tValid Loss :  1549.2192375755367 , Time for 1000 epochs : 0.99245024000993\n",
      "Epoch 426999 : Train Accuracy : 0.96772, \tValid  Accuracy : 0.9571,\t Train Loss : 5122.569860468944, \tValid Loss :  1552.002500344334 , Time for 1000 epochs : 1.1479208139935508\n",
      "Epoch 427999 : Train Accuracy : 0.96784, \tValid  Accuracy : 0.9573,\t Train Loss : 5138.018099883992, \tValid Loss :  1561.1637364320047 , Time for 1000 epochs : 1.0225414900050964\n",
      "Epoch 428999 : Train Accuracy : 0.96792, \tValid  Accuracy : 0.957,\t Train Loss : 5166.291298924663, \tValid Loss :  1570.6946374487384 , Time for 1000 epochs : 0.9784584139997605\n",
      "Epoch 429999 : Train Accuracy : 0.96806, \tValid  Accuracy : 0.9574,\t Train Loss : 5188.594034358092, \tValid Loss :  1576.4424762217375 , Time for 1000 epochs : 1.4280700639938004\n",
      "Epoch 430999 : Train Accuracy : 0.96812, \tValid  Accuracy : 0.9578,\t Train Loss : 5182.776987528647, \tValid Loss :  1573.6184825494274 , Time for 1000 epochs : 1.1060355950030498\n",
      "Epoch 431999 : Train Accuracy : 0.96824, \tValid  Accuracy : 0.9583,\t Train Loss : 5154.775814195062, \tValid Loss :  1562.5470505315222 , Time for 1000 epochs : 1.0672754679981153\n",
      "Epoch 432999 : Train Accuracy : 0.96838, \tValid  Accuracy : 0.9587,\t Train Loss : 5122.923474478696, \tValid Loss :  1550.5890801403393 , Time for 1000 epochs : 1.2896777639980428\n",
      "Epoch 433999 : Train Accuracy : 0.96852, \tValid  Accuracy : 0.9593,\t Train Loss : 5086.506345256999, \tValid Loss :  1537.6333329249978 , Time for 1000 epochs : 1.0144102179910988\n",
      "Epoch 434999 : Train Accuracy : 0.96856, \tValid  Accuracy : 0.9592,\t Train Loss : 5056.531870439587, \tValid Loss :  1525.5770461042734 , Time for 1000 epochs : 2.4135727130051237\n",
      "Epoch 435999 : Train Accuracy : 0.96864, \tValid  Accuracy : 0.9599,\t Train Loss : 5047.438229108679, \tValid Loss :  1517.0571687996953 , Time for 1000 epochs : 1.0181186080153566\n",
      "Epoch 436999 : Train Accuracy : 0.96846, \tValid  Accuracy : 0.9591,\t Train Loss : 5051.900204204329, \tValid Loss :  1511.3312779896914 , Time for 1000 epochs : 1.3087315429875161\n",
      "Epoch 437999 : Train Accuracy : 0.96816, \tValid  Accuracy : 0.9587,\t Train Loss : 5069.506385558226, \tValid Loss :  1508.9130584305092 , Time for 1000 epochs : 1.2241662180167623\n",
      "Epoch 438999 : Train Accuracy : 0.96772, \tValid  Accuracy : 0.9586,\t Train Loss : 5091.16926776787, \tValid Loss :  1507.4708064233519 , Time for 1000 epochs : 4.737189378007315\n",
      "Epoch 439999 : Train Accuracy : 0.9675, \tValid  Accuracy : 0.9587,\t Train Loss : 5113.573355856418, \tValid Loss :  1507.0453487425682 , Time for 1000 epochs : 1.011384844983695\n",
      "Epoch 440999 : Train Accuracy : 0.96734, \tValid  Accuracy : 0.958,\t Train Loss : 5121.04275227363, \tValid Loss :  1504.9526882830016 , Time for 1000 epochs : 1.0684277169930283\n",
      "Epoch 441999 : Train Accuracy : 0.96726, \tValid  Accuracy : 0.9589,\t Train Loss : 5107.30206072112, \tValid Loss :  1501.3027123968438 , Time for 1000 epochs : 1.2315603570023086\n",
      "Epoch 442999 : Train Accuracy : 0.96746, \tValid  Accuracy : 0.9589,\t Train Loss : 5084.605073541497, \tValid Loss :  1498.7835540556755 , Time for 1000 epochs : 2.9903540009981953\n",
      "Epoch 443999 : Train Accuracy : 0.96778, \tValid  Accuracy : 0.9589,\t Train Loss : 5062.9569211195585, \tValid Loss :  1499.1929908974937 , Time for 1000 epochs : 1.4029852639941964\n",
      "Epoch 444999 : Train Accuracy : 0.96814, \tValid  Accuracy : 0.9585,\t Train Loss : 5057.313022539652, \tValid Loss :  1505.7732914772982 , Time for 1000 epochs : 1.4505259959842078\n",
      "Epoch 445999 : Train Accuracy : 0.9679, \tValid  Accuracy : 0.9585,\t Train Loss : 5072.510133996431, \tValid Loss :  1519.2447873963276 , Time for 1000 epochs : 3.7733000309963245\n",
      "Epoch 446999 : Train Accuracy : 0.96816, \tValid  Accuracy : 0.9584,\t Train Loss : 5098.527195996483, \tValid Loss :  1536.4824891031715 , Time for 1000 epochs : 2.1765210799931083\n",
      "Epoch 447999 : Train Accuracy : 0.96794, \tValid  Accuracy : 0.9587,\t Train Loss : 5107.734808101547, \tValid Loss :  1549.6980817750564 , Time for 1000 epochs : 1.8460282630112488\n",
      "Epoch 448999 : Train Accuracy : 0.96828, \tValid  Accuracy : 0.9589,\t Train Loss : 5108.571834655089, \tValid Loss :  1559.5305197260718 , Time for 1000 epochs : 1.9868190169800073\n",
      "Epoch 449999 : Train Accuracy : 0.968, \tValid  Accuracy : 0.9594,\t Train Loss : 5102.756218648666, \tValid Loss :  1566.1388349864897 , Time for 1000 epochs : 1.2193907879991457\n",
      "Epoch 450999 : Train Accuracy : 0.96836, \tValid  Accuracy : 0.9594,\t Train Loss : 5068.398586777709, \tValid Loss :  1562.4668170310867 , Time for 1000 epochs : 4.02837395700044\n",
      "Epoch 451999 : Train Accuracy : 0.96884, \tValid  Accuracy : 0.9598,\t Train Loss : 5023.792447218035, \tValid Loss :  1553.2951290279793 , Time for 1000 epochs : 1.4411442699783947\n",
      "Epoch 452999 : Train Accuracy : 0.9692, \tValid  Accuracy : 0.9596,\t Train Loss : 4983.562504238425, \tValid Loss :  1542.9464922046132 , Time for 1000 epochs : 1.9863881479832344\n",
      "Epoch 453999 : Train Accuracy : 0.96956, \tValid  Accuracy : 0.9589,\t Train Loss : 4954.530886144771, \tValid Loss :  1532.9903447339518 , Time for 1000 epochs : 2.52990407901234\n",
      "Epoch 454999 : Train Accuracy : 0.96948, \tValid  Accuracy : 0.9591,\t Train Loss : 4957.436303046705, \tValid Loss :  1529.362364983922 , Time for 1000 epochs : 1.5383528389793355\n",
      "Epoch 455999 : Train Accuracy : 0.96918, \tValid  Accuracy : 0.9584,\t Train Loss : 4989.845931000082, \tValid Loss :  1533.0674280673454 , Time for 1000 epochs : 1.3850892159971409\n",
      "Epoch 456999 : Train Accuracy : 0.96862, \tValid  Accuracy : 0.9589,\t Train Loss : 5034.586202150695, \tValid Loss :  1540.0970069616142 , Time for 1000 epochs : 3.436502822994953\n",
      "Epoch 457999 : Train Accuracy : 0.9683, \tValid  Accuracy : 0.9582,\t Train Loss : 5059.308641558175, \tValid Loss :  1544.8001359062173 , Time for 1000 epochs : 1.5244078949908726\n",
      "Epoch 458999 : Train Accuracy : 0.9683, \tValid  Accuracy : 0.9585,\t Train Loss : 5048.970991262049, \tValid Loss :  1544.650947054685 , Time for 1000 epochs : 1.7987095169955865\n",
      "Epoch 459999 : Train Accuracy : 0.96886, \tValid  Accuracy : 0.9586,\t Train Loss : 5013.401762978918, \tValid Loss :  1539.8283426919074 , Time for 1000 epochs : 1.408259864023421\n",
      "Epoch 460999 : Train Accuracy : 0.96948, \tValid  Accuracy : 0.9588,\t Train Loss : 4962.90909467219, \tValid Loss :  1532.8003360571483 , Time for 1000 epochs : 1.644806513999356\n",
      "Epoch 461999 : Train Accuracy : 0.9698, \tValid  Accuracy : 0.9593,\t Train Loss : 4912.194651559531, \tValid Loss :  1526.532445506617 , Time for 1000 epochs : 1.6326638399914373\n",
      "Epoch 462999 : Train Accuracy : 0.97018, \tValid  Accuracy : 0.9585,\t Train Loss : 4880.544292712222, \tValid Loss :  1523.3994633413915 , Time for 1000 epochs : 1.404808448976837\n",
      "Epoch 463999 : Train Accuracy : 0.97022, \tValid  Accuracy : 0.9589,\t Train Loss : 4874.087972293142, \tValid Loss :  1524.630542505905 , Time for 1000 epochs : 1.428686255007051\n",
      "Epoch 464999 : Train Accuracy : 0.97004, \tValid  Accuracy : 0.9585,\t Train Loss : 4889.81733550817, \tValid Loss :  1530.1733268389482 , Time for 1000 epochs : 1.7944900050060824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465999 : Train Accuracy : 0.96988, \tValid  Accuracy : 0.9582,\t Train Loss : 4920.260263144895, \tValid Loss :  1538.2721965930348 , Time for 1000 epochs : 2.852624327002559\n",
      "Epoch 466999 : Train Accuracy : 0.96958, \tValid  Accuracy : 0.958,\t Train Loss : 4941.476189161321, \tValid Loss :  1543.9753007557367 , Time for 1000 epochs : 1.6378123460162897\n",
      "Epoch 467999 : Train Accuracy : 0.96978, \tValid  Accuracy : 0.958,\t Train Loss : 4947.697887641716, \tValid Loss :  1545.8566384815072 , Time for 1000 epochs : 1.5997875870089047\n",
      "Epoch 468999 : Train Accuracy : 0.96986, \tValid  Accuracy : 0.9581,\t Train Loss : 4943.111093027934, \tValid Loss :  1544.7587795115762 , Time for 1000 epochs : 1.5453008189797401\n",
      "Epoch 469999 : Train Accuracy : 0.96998, \tValid  Accuracy : 0.9584,\t Train Loss : 4930.228757362004, \tValid Loss :  1540.681247502515 , Time for 1000 epochs : 1.5913418749987613\n",
      "Epoch 470999 : Train Accuracy : 0.96948, \tValid  Accuracy : 0.9592,\t Train Loss : 4914.938179713094, \tValid Loss :  1534.382997432367 , Time for 1000 epochs : 1.7886036070121918\n",
      "Epoch 471999 : Train Accuracy : 0.96928, \tValid  Accuracy : 0.9601,\t Train Loss : 4899.301454845981, \tValid Loss :  1527.1541480255123 , Time for 1000 epochs : 1.3531620719877537\n",
      "Epoch 472999 : Train Accuracy : 0.96928, \tValid  Accuracy : 0.9601,\t Train Loss : 4899.460545776091, \tValid Loss :  1522.684469104106 , Time for 1000 epochs : 2.735583017987665\n",
      "Epoch 473999 : Train Accuracy : 0.96936, \tValid  Accuracy : 0.9597,\t Train Loss : 4903.110123562532, \tValid Loss :  1520.1243637920754 , Time for 1000 epochs : 1.4222911779943388\n",
      "Epoch 474999 : Train Accuracy : 0.96936, \tValid  Accuracy : 0.9595,\t Train Loss : 4904.032045439394, \tValid Loss :  1518.778427417047 , Time for 1000 epochs : 1.447062602994265\n",
      "Epoch 475999 : Train Accuracy : 0.96944, \tValid  Accuracy : 0.959,\t Train Loss : 4897.585399006236, \tValid Loss :  1516.8398620423698 , Time for 1000 epochs : 1.6474534620065242\n",
      "Epoch 476999 : Train Accuracy : 0.96934, \tValid  Accuracy : 0.9581,\t Train Loss : 4885.666773167972, \tValid Loss :  1515.176447165811 , Time for 1000 epochs : 1.694683759007603\n",
      "Epoch 477999 : Train Accuracy : 0.96938, \tValid  Accuracy : 0.9595,\t Train Loss : 4866.941210666832, \tValid Loss :  1513.1738589917895 , Time for 1000 epochs : 1.5550673130201176\n",
      "Epoch 478999 : Train Accuracy : 0.96952, \tValid  Accuracy : 0.9594,\t Train Loss : 4843.747190932744, \tValid Loss :  1510.8084046468707 , Time for 1000 epochs : 1.6213327949808445\n",
      "Epoch 479999 : Train Accuracy : 0.96974, \tValid  Accuracy : 0.9589,\t Train Loss : 4817.5238359302375, \tValid Loss :  1508.2451858128002 , Time for 1000 epochs : 1.3354491259960923\n",
      "Epoch 480999 : Train Accuracy : 0.96966, \tValid  Accuracy : 0.9594,\t Train Loss : 4795.9676735757985, \tValid Loss :  1507.552540603722 , Time for 1000 epochs : 1.8170945229940116\n",
      "Epoch 481999 : Train Accuracy : 0.96992, \tValid  Accuracy : 0.9589,\t Train Loss : 4780.629871343993, \tValid Loss :  1508.6762315384185 , Time for 1000 epochs : 1.5366638030100148\n",
      "Epoch 482999 : Train Accuracy : 0.97006, \tValid  Accuracy : 0.9593,\t Train Loss : 4770.128247863595, \tValid Loss :  1511.5588257780466 , Time for 1000 epochs : 1.4288977859832812\n",
      "Epoch 483999 : Train Accuracy : 0.97024, \tValid  Accuracy : 0.959,\t Train Loss : 4765.850335671232, \tValid Loss :  1515.635204993072 , Time for 1000 epochs : 1.5662887289945502\n",
      "Epoch 484999 : Train Accuracy : 0.97028, \tValid  Accuracy : 0.9598,\t Train Loss : 4762.922650497965, \tValid Loss :  1520.190177367592 , Time for 1000 epochs : 1.5882192850112915\n",
      "Epoch 485999 : Train Accuracy : 0.97064, \tValid  Accuracy : 0.9589,\t Train Loss : 4764.42800132738, \tValid Loss :  1525.7730777743468 , Time for 1000 epochs : 4.942404247995\n",
      "Epoch 486999 : Train Accuracy : 0.9707, \tValid  Accuracy : 0.9588,\t Train Loss : 4761.734744871617, \tValid Loss :  1531.418970622422 , Time for 1000 epochs : 1.5081635270034894\n",
      "Epoch 487999 : Train Accuracy : 0.9707, \tValid  Accuracy : 0.9589,\t Train Loss : 4753.701936691861, \tValid Loss :  1536.3640143929385 , Time for 1000 epochs : 1.3672402560187038\n",
      "Epoch 488999 : Train Accuracy : 0.97084, \tValid  Accuracy : 0.959,\t Train Loss : 4748.952699526326, \tValid Loss :  1541.0967106657138 , Time for 1000 epochs : 1.918873969989363\n",
      "Epoch 489999 : Train Accuracy : 0.97094, \tValid  Accuracy : 0.959,\t Train Loss : 4746.880449604072, \tValid Loss :  1546.2095937426936 , Time for 1000 epochs : 1.3820405800070148\n",
      "Epoch 490999 : Train Accuracy : 0.97066, \tValid  Accuracy : 0.9582,\t Train Loss : 4747.308437553093, \tValid Loss :  1550.1792937394398 , Time for 1000 epochs : 1.4606030439899769\n",
      "Epoch 491999 : Train Accuracy : 0.97054, \tValid  Accuracy : 0.9578,\t Train Loss : 4749.515349947996, \tValid Loss :  1553.4523394705307 , Time for 1000 epochs : 1.7753254419949371\n",
      "Epoch 492999 : Train Accuracy : 0.97026, \tValid  Accuracy : 0.9572,\t Train Loss : 4757.965200236013, \tValid Loss :  1558.2387273833765 , Time for 1000 epochs : 1.3817942480091006\n",
      "Epoch 493999 : Train Accuracy : 0.97018, \tValid  Accuracy : 0.9572,\t Train Loss : 4761.491018402961, \tValid Loss :  1561.6724814553327 , Time for 1000 epochs : 1.5554062460141722\n",
      "Epoch 494999 : Train Accuracy : 0.97006, \tValid  Accuracy : 0.9571,\t Train Loss : 4757.723892939816, \tValid Loss :  1561.4909543951167 , Time for 1000 epochs : 1.3912610209954437\n",
      "Epoch 495999 : Train Accuracy : 0.97016, \tValid  Accuracy : 0.9574,\t Train Loss : 4751.876741939283, \tValid Loss :  1560.568688111713 , Time for 1000 epochs : 1.6699099519755691\n",
      "Epoch 496999 : Train Accuracy : 0.97006, \tValid  Accuracy : 0.958,\t Train Loss : 4740.90180376917, \tValid Loss :  1556.8455934078993 , Time for 1000 epochs : 1.5321457240206655\n",
      "Epoch 497999 : Train Accuracy : 0.9702, \tValid  Accuracy : 0.9589,\t Train Loss : 4737.337848741022, \tValid Loss :  1553.0404658021102 , Time for 1000 epochs : 1.5326838720066007\n",
      "Epoch 498999 : Train Accuracy : 0.97006, \tValid  Accuracy : 0.9591,\t Train Loss : 4759.300276417718, \tValid Loss :  1554.5986760701376 , Time for 1000 epochs : 1.3335509290045593\n",
      "Epoch 499999 : Train Accuracy : 0.96946, \tValid  Accuracy : 0.9588,\t Train Loss : 4803.2728238152, \tValid Loss :  1560.6414712861006 , Time for 1000 epochs : 1.6278926499944646\n",
      "Epoch 500999 : Train Accuracy : 0.9695, \tValid  Accuracy : 0.9588,\t Train Loss : 4844.978828512616, \tValid Loss :  1566.7159896559112 , Time for 1000 epochs : 1.2190847219899297\n",
      "Epoch 501999 : Train Accuracy : 0.96946, \tValid  Accuracy : 0.9583,\t Train Loss : 4847.959593672947, \tValid Loss :  1564.6511272795108 , Time for 1000 epochs : 1.5264288789767306\n",
      "Epoch 502999 : Train Accuracy : 0.96966, \tValid  Accuracy : 0.9585,\t Train Loss : 4820.263826933432, \tValid Loss :  1557.5563473526786 , Time for 1000 epochs : 1.588101354020182\n",
      "Epoch 503999 : Train Accuracy : 0.97002, \tValid  Accuracy : 0.9589,\t Train Loss : 4750.848654996308, \tValid Loss :  1543.7660703986064 , Time for 1000 epochs : 1.3953509189886972\n",
      "Epoch 504999 : Train Accuracy : 0.97086, \tValid  Accuracy : 0.9588,\t Train Loss : 4665.606561383823, \tValid Loss :  1527.859886762363 , Time for 1000 epochs : 1.5067526390193962\n",
      "Epoch 505999 : Train Accuracy : 0.97152, \tValid  Accuracy : 0.959,\t Train Loss : 4594.507329702705, \tValid Loss :  1515.4476055684277 , Time for 1000 epochs : 1.5583818209997844\n",
      "Epoch 506999 : Train Accuracy : 0.97192, \tValid  Accuracy : 0.9591,\t Train Loss : 4553.005387565285, \tValid Loss :  1509.5630509697626 , Time for 1000 epochs : 1.5925632430007681\n",
      "Epoch 507999 : Train Accuracy : 0.972, \tValid  Accuracy : 0.9593,\t Train Loss : 4546.820738521724, \tValid Loss :  1510.98310168233 , Time for 1000 epochs : 1.4643390729906969\n",
      "Epoch 508999 : Train Accuracy : 0.97202, \tValid  Accuracy : 0.9592,\t Train Loss : 4567.238450369946, \tValid Loss :  1517.7088637450263 , Time for 1000 epochs : 1.7664914579945616\n",
      "Epoch 509999 : Train Accuracy : 0.97184, \tValid  Accuracy : 0.9579,\t Train Loss : 4606.12964042979, \tValid Loss :  1528.3833762685792 , Time for 1000 epochs : 1.3557036519923713\n",
      "Epoch 510999 : Train Accuracy : 0.97142, \tValid  Accuracy : 0.9584,\t Train Loss : 4656.9797702023425, \tValid Loss :  1540.5633683723167 , Time for 1000 epochs : 1.436693820025539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 511999 : Train Accuracy : 0.97142, \tValid  Accuracy : 0.9581,\t Train Loss : 4686.318335463035, \tValid Loss :  1547.148203005251 , Time for 1000 epochs : 1.5953124139923602\n",
      "Epoch 512999 : Train Accuracy : 0.97132, \tValid  Accuracy : 0.9579,\t Train Loss : 4700.35538430425, \tValid Loss :  1549.761114286933 , Time for 1000 epochs : 1.3942636179854162\n",
      "Epoch 513999 : Train Accuracy : 0.97124, \tValid  Accuracy : 0.9585,\t Train Loss : 4697.152703028282, \tValid Loss :  1547.4931829996435 , Time for 1000 epochs : 1.4805875000020023\n",
      "Epoch 514999 : Train Accuracy : 0.9714, \tValid  Accuracy : 0.9589,\t Train Loss : 4680.052567814429, \tValid Loss :  1541.4984719284064 , Time for 1000 epochs : 1.494444105977891\n",
      "Epoch 515999 : Train Accuracy : 0.97156, \tValid  Accuracy : 0.9586,\t Train Loss : 4649.611017276149, \tValid Loss :  1533.6175972235376 , Time for 1000 epochs : 1.5415143530117348\n",
      "Epoch 516999 : Train Accuracy : 0.97186, \tValid  Accuracy : 0.9583,\t Train Loss : 4611.502821044669, \tValid Loss :  1524.6870870935152 , Time for 1000 epochs : 3.0396167570143007\n",
      "Epoch 517999 : Train Accuracy : 0.9719, \tValid  Accuracy : 0.9584,\t Train Loss : 4582.837104341668, \tValid Loss :  1518.366167316565 , Time for 1000 epochs : 1.5549480149929877\n",
      "Epoch 518999 : Train Accuracy : 0.97184, \tValid  Accuracy : 0.9588,\t Train Loss : 4571.177917437149, \tValid Loss :  1516.5945789543525 , Time for 1000 epochs : 1.4980912600003649\n",
      "Epoch 519999 : Train Accuracy : 0.97162, \tValid  Accuracy : 0.9582,\t Train Loss : 4567.829560097951, \tValid Loss :  1517.406430485846 , Time for 1000 epochs : 1.448076567001408\n",
      "Epoch 520999 : Train Accuracy : 0.97154, \tValid  Accuracy : 0.9576,\t Train Loss : 4561.756549262009, \tValid Loss :  1518.4465442779467 , Time for 1000 epochs : 1.668128710007295\n",
      "Epoch 521999 : Train Accuracy : 0.97154, \tValid  Accuracy : 0.9578,\t Train Loss : 4553.6575868352065, \tValid Loss :  1519.3798562666345 , Time for 1000 epochs : 1.4583160479960497\n",
      "Epoch 522999 : Train Accuracy : 0.97124, \tValid  Accuracy : 0.9575,\t Train Loss : 4541.21699162536, \tValid Loss :  1519.8379927720005 , Time for 1000 epochs : 1.366563955991296\n",
      "Epoch 523999 : Train Accuracy : 0.9714, \tValid  Accuracy : 0.9576,\t Train Loss : 4528.0276864606285, \tValid Loss :  1520.6287436689697 , Time for 1000 epochs : 1.889548270002706\n",
      "Epoch 524999 : Train Accuracy : 0.97134, \tValid  Accuracy : 0.9581,\t Train Loss : 4518.99494601472, \tValid Loss :  1521.8184218674205 , Time for 1000 epochs : 1.6011018499848433\n",
      "Epoch 525999 : Train Accuracy : 0.9714, \tValid  Accuracy : 0.9584,\t Train Loss : 4520.279354325845, \tValid Loss :  1525.0916141343214 , Time for 1000 epochs : 1.3388107490027323\n",
      "Epoch 526999 : Train Accuracy : 0.97132, \tValid  Accuracy : 0.9586,\t Train Loss : 4525.7088775850525, \tValid Loss :  1529.3398369555166 , Time for 1000 epochs : 1.0003979959874414\n",
      "Epoch 527999 : Train Accuracy : 0.97154, \tValid  Accuracy : 0.9587,\t Train Loss : 4524.898253016039, \tValid Loss :  1533.1458914215411 , Time for 1000 epochs : 1.2927187900058925\n",
      "Epoch 528999 : Train Accuracy : 0.97146, \tValid  Accuracy : 0.9584,\t Train Loss : 4519.234332674052, \tValid Loss :  1535.9708292866765 , Time for 1000 epochs : 1.7163552489946596\n",
      "Epoch 529999 : Train Accuracy : 0.97154, \tValid  Accuracy : 0.9589,\t Train Loss : 4507.970151063268, \tValid Loss :  1538.7150729461573 , Time for 1000 epochs : 3.4232384889910463\n",
      "Epoch 530999 : Train Accuracy : 0.9719, \tValid  Accuracy : 0.9593,\t Train Loss : 4493.5078533694505, \tValid Loss :  1541.5759702991268 , Time for 1000 epochs : 6.585525800008327\n",
      "Epoch 531999 : Train Accuracy : 0.97206, \tValid  Accuracy : 0.9588,\t Train Loss : 4479.791731188758, \tValid Loss :  1544.8445482632815 , Time for 1000 epochs : 1.2459390310104936\n",
      "Epoch 532999 : Train Accuracy : 0.97212, \tValid  Accuracy : 0.9588,\t Train Loss : 4469.574292293503, \tValid Loss :  1549.355940925206 , Time for 1000 epochs : 1.1350695920118596\n",
      "Epoch 533999 : Train Accuracy : 0.97212, \tValid  Accuracy : 0.9585,\t Train Loss : 4468.30180786018, \tValid Loss :  1554.5060336840188 , Time for 1000 epochs : 1.0300504949991591\n",
      "Epoch 534999 : Train Accuracy : 0.97206, \tValid  Accuracy : 0.9579,\t Train Loss : 4473.0815858552, \tValid Loss :  1559.1409178107424 , Time for 1000 epochs : 1.0190317519882228\n",
      "Epoch 535999 : Train Accuracy : 0.972, \tValid  Accuracy : 0.9577,\t Train Loss : 4475.75317179734, \tValid Loss :  1561.076080439517 , Time for 1000 epochs : 1.3476709459791891\n",
      "Epoch 536999 : Train Accuracy : 0.97212, \tValid  Accuracy : 0.9578,\t Train Loss : 4476.755167286988, \tValid Loss :  1560.8547805082146 , Time for 1000 epochs : 1.0328611099976115\n",
      "Epoch 537999 : Train Accuracy : 0.97208, \tValid  Accuracy : 0.9583,\t Train Loss : 4465.476999980325, \tValid Loss :  1555.0004578089115 , Time for 1000 epochs : 0.9902288440207485\n",
      "Epoch 538999 : Train Accuracy : 0.9721, \tValid  Accuracy : 0.9584,\t Train Loss : 4438.860326851755, \tValid Loss :  1542.9045618146013 , Time for 1000 epochs : 0.9868086200149264\n",
      "Epoch 539999 : Train Accuracy : 0.97208, \tValid  Accuracy : 0.9584,\t Train Loss : 4411.3891567920655, \tValid Loss :  1528.8298298907707 , Time for 1000 epochs : 0.989644816989312\n",
      "Epoch 540999 : Train Accuracy : 0.97232, \tValid  Accuracy : 0.9579,\t Train Loss : 4393.906184891233, \tValid Loss :  1515.8767556201906 , Time for 1000 epochs : 0.9823750219948124\n",
      "Epoch 541999 : Train Accuracy : 0.97234, \tValid  Accuracy : 0.9588,\t Train Loss : 4393.018856877569, \tValid Loss :  1506.2553945018728 , Time for 1000 epochs : 1.1948748379945755\n",
      "Epoch 542999 : Train Accuracy : 0.97236, \tValid  Accuracy : 0.9584,\t Train Loss : 4405.692701908625, \tValid Loss :  1500.946848981123 , Time for 1000 epochs : 1.0186835559725296\n",
      "Epoch 543999 : Train Accuracy : 0.97218, \tValid  Accuracy : 0.9581,\t Train Loss : 4425.953980560376, \tValid Loss :  1498.746873372418 , Time for 1000 epochs : 1.0450878939882386\n",
      "Epoch 544999 : Train Accuracy : 0.97188, \tValid  Accuracy : 0.9578,\t Train Loss : 4450.247026022648, \tValid Loss :  1499.0119551462913 , Time for 1000 epochs : 0.9663636400073301\n",
      "Epoch 545999 : Train Accuracy : 0.97116, \tValid  Accuracy : 0.958,\t Train Loss : 4469.233657520945, \tValid Loss :  1499.8599169010924 , Time for 1000 epochs : 0.9969918779970612\n",
      "Epoch 546999 : Train Accuracy : 0.9711, \tValid  Accuracy : 0.9585,\t Train Loss : 4472.017369851669, \tValid Loss :  1499.5282581709184 , Time for 1000 epochs : 0.9645741609856486\n",
      "Epoch 547999 : Train Accuracy : 0.97112, \tValid  Accuracy : 0.9586,\t Train Loss : 4456.117963526007, \tValid Loss :  1497.4600394470172 , Time for 1000 epochs : 0.9704322210163809\n",
      "Epoch 548999 : Train Accuracy : 0.97122, \tValid  Accuracy : 0.9591,\t Train Loss : 4433.505561305683, \tValid Loss :  1495.28061398764 , Time for 1000 epochs : 1.148988434986677\n",
      "Epoch 549999 : Train Accuracy : 0.97166, \tValid  Accuracy : 0.959,\t Train Loss : 4405.928115718728, \tValid Loss :  1493.7397807043044 , Time for 1000 epochs : 1.704432870988967\n",
      "Epoch 550999 : Train Accuracy : 0.97208, \tValid  Accuracy : 0.9598,\t Train Loss : 4385.30985611802, \tValid Loss :  1495.3609711617123 , Time for 1000 epochs : 0.9972744320111815\n",
      "Epoch 551999 : Train Accuracy : 0.97238, \tValid  Accuracy : 0.9594,\t Train Loss : 4382.125802783368, \tValid Loss :  1501.92696228368 , Time for 1000 epochs : 0.9654442309984006\n",
      "Epoch 552999 : Train Accuracy : 0.97222, \tValid  Accuracy : 0.9591,\t Train Loss : 4398.976305042335, \tValid Loss :  1512.8992009927624 , Time for 1000 epochs : 0.9758494530105963\n",
      "Epoch 553999 : Train Accuracy : 0.97202, \tValid  Accuracy : 0.9592,\t Train Loss : 4423.390087799697, \tValid Loss :  1524.4778300797889 , Time for 1000 epochs : 1.0241155929979868\n",
      "Epoch 554999 : Train Accuracy : 0.97214, \tValid  Accuracy : 0.9582,\t Train Loss : 4444.186339954985, \tValid Loss :  1534.7549481733738 , Time for 1000 epochs : 1.1230061999813188\n",
      "Epoch 555999 : Train Accuracy : 0.97214, \tValid  Accuracy : 0.9582,\t Train Loss : 4452.163143151909, \tValid Loss :  1541.083189366567 , Time for 1000 epochs : 1.0508173390117008\n",
      "Epoch 556999 : Train Accuracy : 0.97236, \tValid  Accuracy : 0.9581,\t Train Loss : 4442.65702028786, \tValid Loss :  1542.2090230862955 , Time for 1000 epochs : 0.9957437580160331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 557999 : Train Accuracy : 0.9725, \tValid  Accuracy : 0.9585,\t Train Loss : 4417.028859358916, \tValid Loss :  1538.1130241288588 , Time for 1000 epochs : 1.0140147999918554\n",
      "Epoch 558999 : Train Accuracy : 0.97298, \tValid  Accuracy : 0.9581,\t Train Loss : 4386.714864097685, \tValid Loss :  1530.6061961733014 , Time for 1000 epochs : 0.9614795929810498\n",
      "Epoch 559999 : Train Accuracy : 0.973, \tValid  Accuracy : 0.9588,\t Train Loss : 4351.361082985057, \tValid Loss :  1520.6433966026352 , Time for 1000 epochs : 0.977228120988002\n",
      "Epoch 560999 : Train Accuracy : 0.9732, \tValid  Accuracy : 0.9588,\t Train Loss : 4322.611763327443, \tValid Loss :  1511.618795056874 , Time for 1000 epochs : 0.9899006920168176\n",
      "Epoch 561999 : Train Accuracy : 0.97344, \tValid  Accuracy : 0.9597,\t Train Loss : 4307.2540477373705, \tValid Loss :  1505.112457527662 , Time for 1000 epochs : 1.2154536249872763\n",
      "Epoch 562999 : Train Accuracy : 0.97298, \tValid  Accuracy : 0.9593,\t Train Loss : 4305.542430024153, \tValid Loss :  1501.5609742538632 , Time for 1000 epochs : 1.0526161509915255\n",
      "Epoch 563999 : Train Accuracy : 0.97296, \tValid  Accuracy : 0.9594,\t Train Loss : 4315.145570717289, \tValid Loss :  1500.7807033147653 , Time for 1000 epochs : 0.9763347219850402\n",
      "Epoch 564999 : Train Accuracy : 0.97248, \tValid  Accuracy : 0.9589,\t Train Loss : 4330.268434195739, \tValid Loss :  1502.161890798354 , Time for 1000 epochs : 1.032741311006248\n",
      "Epoch 565999 : Train Accuracy : 0.9726, \tValid  Accuracy : 0.9584,\t Train Loss : 4348.5789582237385, \tValid Loss :  1504.8154529658252 , Time for 1000 epochs : 0.9582795329915825\n",
      "Epoch 566999 : Train Accuracy : 0.9722, \tValid  Accuracy : 0.9584,\t Train Loss : 4366.030432177726, \tValid Loss :  1508.356588945945 , Time for 1000 epochs : 0.9506011680059601\n",
      "Epoch 567999 : Train Accuracy : 0.9722, \tValid  Accuracy : 0.958,\t Train Loss : 4372.60009806192, \tValid Loss :  1511.1696321893069 , Time for 1000 epochs : 1.1346519659855403\n",
      "Epoch 568999 : Train Accuracy : 0.97218, \tValid  Accuracy : 0.9578,\t Train Loss : 4363.125716183765, \tValid Loss :  1512.5833458297723 , Time for 1000 epochs : 0.9803020590043161\n",
      "Epoch 569999 : Train Accuracy : 0.9726, \tValid  Accuracy : 0.959,\t Train Loss : 4342.1247780669955, \tValid Loss :  1513.4259892663936 , Time for 1000 epochs : 0.9677671239769552\n",
      "Epoch 570999 : Train Accuracy : 0.97256, \tValid  Accuracy : 0.9587,\t Train Loss : 4319.430335080566, \tValid Loss :  1515.0142697801052 , Time for 1000 epochs : 0.9972511600062717\n",
      "Epoch 571999 : Train Accuracy : 0.97268, \tValid  Accuracy : 0.9586,\t Train Loss : 4294.699869106095, \tValid Loss :  1517.5642739693983 , Time for 1000 epochs : 1.347588876989903\n",
      "Epoch 572999 : Train Accuracy : 0.97306, \tValid  Accuracy : 0.9592,\t Train Loss : 4277.534599120519, \tValid Loss :  1521.5394784550406 , Time for 1000 epochs : 1.5813652200158685\n",
      "Epoch 573999 : Train Accuracy : 0.97302, \tValid  Accuracy : 0.9589,\t Train Loss : 4271.576128788008, \tValid Loss :  1528.2478270304246 , Time for 1000 epochs : 1.5920215469959658\n",
      "Epoch 574999 : Train Accuracy : 0.97316, \tValid  Accuracy : 0.9585,\t Train Loss : 4279.477632296539, \tValid Loss :  1537.2815228485913 , Time for 1000 epochs : 1.0755511650058907\n",
      "Epoch 575999 : Train Accuracy : 0.9729, \tValid  Accuracy : 0.958,\t Train Loss : 4298.160765676585, \tValid Loss :  1547.4653144975323 , Time for 1000 epochs : 1.0251464530010708\n",
      "Epoch 576999 : Train Accuracy : 0.97296, \tValid  Accuracy : 0.9579,\t Train Loss : 4319.805887886165, \tValid Loss :  1556.7110340349648 , Time for 1000 epochs : 1.2472987440123688\n",
      "Epoch 577999 : Train Accuracy : 0.973, \tValid  Accuracy : 0.9583,\t Train Loss : 4335.956853732845, \tValid Loss :  1563.3270745542447 , Time for 1000 epochs : 1.6589202090108301\n",
      "Epoch 578999 : Train Accuracy : 0.97286, \tValid  Accuracy : 0.9584,\t Train Loss : 4346.2473361775665, \tValid Loss :  1567.4707872889892 , Time for 1000 epochs : 1.1079164230031893\n",
      "Epoch 579999 : Train Accuracy : 0.97298, \tValid  Accuracy : 0.9583,\t Train Loss : 4352.989724115909, \tValid Loss :  1569.9259152243142 , Time for 1000 epochs : 1.186735116993077\n",
      "Epoch 580999 : Train Accuracy : 0.97308, \tValid  Accuracy : 0.9588,\t Train Loss : 4351.699481869823, \tValid Loss :  1569.8608493585134 , Time for 1000 epochs : 1.0223043869773392\n",
      "Epoch 581999 : Train Accuracy : 0.9732, \tValid  Accuracy : 0.959,\t Train Loss : 4339.810171562868, \tValid Loss :  1566.9173057695982 , Time for 1000 epochs : 1.274484202003805\n",
      "Epoch 582999 : Train Accuracy : 0.9733, \tValid  Accuracy : 0.9588,\t Train Loss : 4314.099161686443, \tValid Loss :  1559.8171661868519 , Time for 1000 epochs : 0.996735875000013\n",
      "Epoch 583999 : Train Accuracy : 0.97344, \tValid  Accuracy : 0.9588,\t Train Loss : 4276.820663589432, \tValid Loss :  1548.8085468952538 , Time for 1000 epochs : 1.029411658004392\n",
      "Epoch 584999 : Train Accuracy : 0.97356, \tValid  Accuracy : 0.9588,\t Train Loss : 4239.805789277436, \tValid Loss :  1536.8610255362812 , Time for 1000 epochs : 0.9801797750114929\n",
      "Epoch 585999 : Train Accuracy : 0.97378, \tValid  Accuracy : 0.9591,\t Train Loss : 4212.002342600131, \tValid Loss :  1526.5422207957342 , Time for 1000 epochs : 1.1171610089950264\n",
      "Epoch 586999 : Train Accuracy : 0.97406, \tValid  Accuracy : 0.9591,\t Train Loss : 4194.799703576721, \tValid Loss :  1518.2729059372623 , Time for 1000 epochs : 0.989241289003985\n",
      "Epoch 587999 : Train Accuracy : 0.97408, \tValid  Accuracy : 0.9595,\t Train Loss : 4189.63952510575, \tValid Loss :  1511.851419543332 , Time for 1000 epochs : 1.348208612005692\n",
      "Epoch 588999 : Train Accuracy : 0.9736, \tValid  Accuracy : 0.9592,\t Train Loss : 4197.857428837503, \tValid Loss :  1507.7265269990728 , Time for 1000 epochs : 1.0087503799877595\n",
      "Epoch 589999 : Train Accuracy : 0.97332, \tValid  Accuracy : 0.9589,\t Train Loss : 4217.1854644057175, \tValid Loss :  1506.180055013444 , Time for 1000 epochs : 0.9714232319965959\n",
      "Epoch 590999 : Train Accuracy : 0.97302, \tValid  Accuracy : 0.9589,\t Train Loss : 4241.778451772829, \tValid Loss :  1506.5986565953574 , Time for 1000 epochs : 0.9969711340090726\n",
      "Epoch 591999 : Train Accuracy : 0.97278, \tValid  Accuracy : 0.9587,\t Train Loss : 4264.878687342813, \tValid Loss :  1507.8818643098934 , Time for 1000 epochs : 0.9938244250079151\n",
      "Epoch 592999 : Train Accuracy : 0.97276, \tValid  Accuracy : 0.9588,\t Train Loss : 4280.940815399204, \tValid Loss :  1508.9641089619395 , Time for 1000 epochs : 1.2301507780211978\n",
      "Epoch 593999 : Train Accuracy : 0.97258, \tValid  Accuracy : 0.9585,\t Train Loss : 4284.635065834561, \tValid Loss :  1509.1700671560345 , Time for 1000 epochs : 1.031945472001098\n",
      "Epoch 594999 : Train Accuracy : 0.97266, \tValid  Accuracy : 0.9585,\t Train Loss : 4275.273612647441, \tValid Loss :  1508.0905488634155 , Time for 1000 epochs : 1.001811125985114\n",
      "Epoch 595999 : Train Accuracy : 0.97294, \tValid  Accuracy : 0.9588,\t Train Loss : 4254.8314780808805, \tValid Loss :  1506.2438554872508 , Time for 1000 epochs : 1.0086277649970725\n",
      "Epoch 596999 : Train Accuracy : 0.97326, \tValid  Accuracy : 0.959,\t Train Loss : 4231.338658366312, \tValid Loss :  1504.9694508910545 , Time for 1000 epochs : 0.9706070349784568\n",
      "Epoch 597999 : Train Accuracy : 0.97366, \tValid  Accuracy : 0.9591,\t Train Loss : 4210.045252533431, \tValid Loss :  1504.741682262114 , Time for 1000 epochs : 1.1911102129961364\n",
      "Epoch 598999 : Train Accuracy : 0.97392, \tValid  Accuracy : 0.9583,\t Train Loss : 4196.755384801967, \tValid Loss :  1506.8977642430532 , Time for 1000 epochs : 1.0237728040083311\n",
      "Epoch 599999 : Train Accuracy : 0.97412, \tValid  Accuracy : 0.958,\t Train Loss : 4194.03454884734, \tValid Loss :  1512.0533632759507 , Time for 1000 epochs : 1.0071650479803793\n",
      "Epoch 600999 : Train Accuracy : 0.9739, \tValid  Accuracy : 0.9576,\t Train Loss : 4200.6992779218535, \tValid Loss :  1519.4826449302705 , Time for 1000 epochs : 0.9759481840010267\n",
      "Epoch 601999 : Train Accuracy : 0.97372, \tValid  Accuracy : 0.9577,\t Train Loss : 4212.274283503769, \tValid Loss :  1528.1311767352463 , Time for 1000 epochs : 1.0108069939888082\n",
      "Epoch 602999 : Train Accuracy : 0.97384, \tValid  Accuracy : 0.9582,\t Train Loss : 4223.3603911405235, \tValid Loss :  1536.6206065177644 , Time for 1000 epochs : 1.279411794996122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 603999 : Train Accuracy : 0.97366, \tValid  Accuracy : 0.9581,\t Train Loss : 4226.978810656567, \tValid Loss :  1542.2553398994592 , Time for 1000 epochs : 1.3299221390043385\n",
      "Epoch 604999 : Train Accuracy : 0.97388, \tValid  Accuracy : 0.9583,\t Train Loss : 4214.482132662933, \tValid Loss :  1543.2579995581666 , Time for 1000 epochs : 1.5491531800071243\n",
      "Epoch 605999 : Train Accuracy : 0.97404, \tValid  Accuracy : 0.9586,\t Train Loss : 4192.47089864531, \tValid Loss :  1541.574703632583 , Time for 1000 epochs : 1.2048324680072255\n",
      "Epoch 606999 : Train Accuracy : 0.97414, \tValid  Accuracy : 0.959,\t Train Loss : 4167.580817265779, \tValid Loss :  1538.3147816010921 , Time for 1000 epochs : 1.063328137010103\n",
      "Epoch 607999 : Train Accuracy : 0.97418, \tValid  Accuracy : 0.9593,\t Train Loss : 4145.591499522977, \tValid Loss :  1535.076141276299 , Time for 1000 epochs : 1.4903250570059754\n",
      "Epoch 608999 : Train Accuracy : 0.97444, \tValid  Accuracy : 0.9593,\t Train Loss : 4130.84841623001, \tValid Loss :  1533.5950297547836 , Time for 1000 epochs : 1.2399598769843578\n",
      "Epoch 609999 : Train Accuracy : 0.9745, \tValid  Accuracy : 0.9593,\t Train Loss : 4124.794566733684, \tValid Loss :  1533.9725558373914 , Time for 1000 epochs : 1.867513382981997\n",
      "Epoch 610999 : Train Accuracy : 0.97428, \tValid  Accuracy : 0.959,\t Train Loss : 4130.476889364087, \tValid Loss :  1536.9802367023929 , Time for 1000 epochs : 1.5442191229958553\n",
      "Epoch 611999 : Train Accuracy : 0.97412, \tValid  Accuracy : 0.9587,\t Train Loss : 4146.539313567626, \tValid Loss :  1542.1825688976114 , Time for 1000 epochs : 1.356955071008997\n",
      "Epoch 612999 : Train Accuracy : 0.97396, \tValid  Accuracy : 0.9583,\t Train Loss : 4167.05648075896, \tValid Loss :  1548.4705875905706 , Time for 1000 epochs : 1.3460974400222767\n",
      "Epoch 613999 : Train Accuracy : 0.97368, \tValid  Accuracy : 0.958,\t Train Loss : 4185.62079916801, \tValid Loss :  1554.5033054557616 , Time for 1000 epochs : 2.1312000589969102\n",
      "Epoch 614999 : Train Accuracy : 0.97358, \tValid  Accuracy : 0.9575,\t Train Loss : 4199.903478804953, \tValid Loss :  1559.6604934582524 , Time for 1000 epochs : 2.098305047984468\n",
      "Epoch 615999 : Train Accuracy : 0.97352, \tValid  Accuracy : 0.9569,\t Train Loss : 4203.925320815275, \tValid Loss :  1562.98292134089 , Time for 1000 epochs : 1.400875924009597\n",
      "Epoch 616999 : Train Accuracy : 0.9735, \tValid  Accuracy : 0.9568,\t Train Loss : 4197.554053949347, \tValid Loss :  1564.7119670346253 , Time for 1000 epochs : 1.5262341380002908\n",
      "Epoch 617999 : Train Accuracy : 0.97368, \tValid  Accuracy : 0.9569,\t Train Loss : 4176.264848731501, \tValid Loss :  1563.985900756842 , Time for 1000 epochs : 1.6288729869993404\n",
      "Epoch 618999 : Train Accuracy : 0.97382, \tValid  Accuracy : 0.9565,\t Train Loss : 4145.063536261651, \tValid Loss :  1561.6783373659284 , Time for 1000 epochs : 1.181107492011506\n",
      "Epoch 619999 : Train Accuracy : 0.97406, \tValid  Accuracy : 0.9561,\t Train Loss : 4115.809606588463, \tValid Loss :  1559.9277063003037 , Time for 1000 epochs : 1.2495657590043265\n",
      "Epoch 620999 : Train Accuracy : 0.97438, \tValid  Accuracy : 0.9567,\t Train Loss : 4091.9864045137265, \tValid Loss :  1559.545929760372 , Time for 1000 epochs : 1.3887251989799552\n",
      "Epoch 621999 : Train Accuracy : 0.97482, \tValid  Accuracy : 0.9572,\t Train Loss : 4075.372565863916, \tValid Loss :  1560.6511025617408 , Time for 1000 epochs : 1.5235297360050026\n",
      "Epoch 622999 : Train Accuracy : 0.97504, \tValid  Accuracy : 0.9574,\t Train Loss : 4071.868250973719, \tValid Loss :  1564.130964916134 , Time for 1000 epochs : 2.3046817630238365\n",
      "Epoch 623999 : Train Accuracy : 0.97492, \tValid  Accuracy : 0.957,\t Train Loss : 4080.18324555116, \tValid Loss :  1569.2364973380174 , Time for 1000 epochs : 1.561601734982105\n",
      "Epoch 624999 : Train Accuracy : 0.9748, \tValid  Accuracy : 0.9569,\t Train Loss : 4096.905108750779, \tValid Loss :  1574.7839599352008 , Time for 1000 epochs : 1.2472767219878733\n",
      "Epoch 625999 : Train Accuracy : 0.97494, \tValid  Accuracy : 0.957,\t Train Loss : 4115.337128412804, \tValid Loss :  1579.3384604608348 , Time for 1000 epochs : 1.2342123109847307\n",
      "Epoch 626999 : Train Accuracy : 0.97468, \tValid  Accuracy : 0.9565,\t Train Loss : 4132.031532604443, \tValid Loss :  1582.5715600818207 , Time for 1000 epochs : 1.3887624990020413\n",
      "Epoch 627999 : Train Accuracy : 0.97456, \tValid  Accuracy : 0.9566,\t Train Loss : 4142.836052996494, \tValid Loss :  1584.3724980352122 , Time for 1000 epochs : 1.5280525410198607\n",
      "Epoch 628999 : Train Accuracy : 0.97468, \tValid  Accuracy : 0.9567,\t Train Loss : 4144.532937673646, \tValid Loss :  1583.672205791212 , Time for 1000 epochs : 1.3145137640240137\n",
      "Epoch 629999 : Train Accuracy : 0.97468, \tValid  Accuracy : 0.957,\t Train Loss : 4133.65946244067, \tValid Loss :  1579.7738693823544 , Time for 1000 epochs : 1.495348450000165\n",
      "Epoch 630999 : Train Accuracy : 0.97462, \tValid  Accuracy : 0.9571,\t Train Loss : 4109.886380218778, \tValid Loss :  1572.1114613166474 , Time for 1000 epochs : 1.310993999009952\n",
      "Epoch 631999 : Train Accuracy : 0.97474, \tValid  Accuracy : 0.9576,\t Train Loss : 4081.6513529162985, \tValid Loss :  1563.1151756503043 , Time for 1000 epochs : 1.1803952750051394\n",
      "Epoch 632999 : Train Accuracy : 0.9749, \tValid  Accuracy : 0.9583,\t Train Loss : 4055.019781715884, \tValid Loss :  1554.1677688906982 , Time for 1000 epochs : 2.964452085987432\n",
      "Epoch 633999 : Train Accuracy : 0.97488, \tValid  Accuracy : 0.9585,\t Train Loss : 4035.7523797048957, \tValid Loss :  1546.8094553852734 , Time for 1000 epochs : 4.124952862010105\n",
      "Epoch 634999 : Train Accuracy : 0.97478, \tValid  Accuracy : 0.9586,\t Train Loss : 4024.162930265894, \tValid Loss :  1541.5234035427134 , Time for 1000 epochs : 1.4911340569960885\n",
      "Epoch 635999 : Train Accuracy : 0.97466, \tValid  Accuracy : 0.9588,\t Train Loss : 4020.8938599753633, \tValid Loss :  1538.604490102239 , Time for 1000 epochs : 2.2501292649831157\n",
      "Epoch 636999 : Train Accuracy : 0.97484, \tValid  Accuracy : 0.9584,\t Train Loss : 4026.960739674974, \tValid Loss :  1538.300993708381 , Time for 1000 epochs : 3.0951020179782063\n",
      "Epoch 637999 : Train Accuracy : 0.97458, \tValid  Accuracy : 0.9581,\t Train Loss : 4038.3558935267274, \tValid Loss :  1539.6727672130662 , Time for 1000 epochs : 2.018651491001947\n",
      "Epoch 638999 : Train Accuracy : 0.97456, \tValid  Accuracy : 0.9577,\t Train Loss : 4049.970902004053, \tValid Loss :  1542.0023380845275 , Time for 1000 epochs : 1.8847013039921876\n",
      "Epoch 639999 : Train Accuracy : 0.97476, \tValid  Accuracy : 0.9577,\t Train Loss : 4059.976186430121, \tValid Loss :  1544.7117473556511 , Time for 1000 epochs : 2.332864779018564\n",
      "Epoch 640999 : Train Accuracy : 0.97472, \tValid  Accuracy : 0.9578,\t Train Loss : 4064.911977573927, \tValid Loss :  1547.4792354810243 , Time for 1000 epochs : 1.6711802599893417\n",
      "Epoch 641999 : Train Accuracy : 0.9746, \tValid  Accuracy : 0.9579,\t Train Loss : 4061.463561039256, \tValid Loss :  1548.516678451426 , Time for 1000 epochs : 1.5736640300019644\n",
      "Epoch 642999 : Train Accuracy : 0.97474, \tValid  Accuracy : 0.9582,\t Train Loss : 4050.6005035765347, \tValid Loss :  1547.8723280789336 , Time for 1000 epochs : 2.251502936007455\n",
      "Epoch 643999 : Train Accuracy : 0.97484, \tValid  Accuracy : 0.9584,\t Train Loss : 4036.902300846994, \tValid Loss :  1546.7666916391927 , Time for 1000 epochs : 1.9462024579988793\n",
      "Epoch 644999 : Train Accuracy : 0.97506, \tValid  Accuracy : 0.9585,\t Train Loss : 4019.1904137282413, \tValid Loss :  1544.7808367259458 , Time for 1000 epochs : 1.5256074230128434\n",
      "Epoch 645999 : Train Accuracy : 0.97498, \tValid  Accuracy : 0.9582,\t Train Loss : 3998.6057491586835, \tValid Loss :  1541.7846692761464 , Time for 1000 epochs : 1.9826843880000524\n",
      "Epoch 646999 : Train Accuracy : 0.9753, \tValid  Accuracy : 0.958,\t Train Loss : 3980.1150134543427, \tValid Loss :  1538.8440840736362 , Time for 1000 epochs : 1.953442238009302\n",
      "Epoch 647999 : Train Accuracy : 0.97534, \tValid  Accuracy : 0.9582,\t Train Loss : 3967.5495031322585, \tValid Loss :  1536.634651931501 , Time for 1000 epochs : 1.5729270880110562\n",
      "Epoch 648999 : Train Accuracy : 0.97556, \tValid  Accuracy : 0.9583,\t Train Loss : 3963.23799677673, \tValid Loss :  1535.9641726261655 , Time for 1000 epochs : 1.5881728249951266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 649999 : Train Accuracy : 0.97568, \tValid  Accuracy : 0.9583,\t Train Loss : 3967.457783213589, \tValid Loss :  1536.9484731841044 , Time for 1000 epochs : 2.686114759009797\n",
      "Epoch 650999 : Train Accuracy : 0.97564, \tValid  Accuracy : 0.9584,\t Train Loss : 3981.292468086816, \tValid Loss :  1539.912153487513 , Time for 1000 epochs : 1.5014505180006381\n",
      "Epoch 651999 : Train Accuracy : 0.97542, \tValid  Accuracy : 0.9585,\t Train Loss : 4001.1308325381815, \tValid Loss :  1544.3334069827947 , Time for 1000 epochs : 1.5150403449952137\n",
      "Epoch 652999 : Train Accuracy : 0.97532, \tValid  Accuracy : 0.9586,\t Train Loss : 4022.6132078484025, \tValid Loss :  1549.1163525904035 , Time for 1000 epochs : 1.0668389709899202\n",
      "Epoch 653999 : Train Accuracy : 0.97498, \tValid  Accuracy : 0.9581,\t Train Loss : 4036.5761919554807, \tValid Loss :  1552.6745752814163 , Time for 1000 epochs : 1.0696045809891075\n",
      "Epoch 654999 : Train Accuracy : 0.97504, \tValid  Accuracy : 0.9581,\t Train Loss : 4039.176483688899, \tValid Loss :  1554.2009242869813 , Time for 1000 epochs : 1.4122750440146774\n",
      "Epoch 655999 : Train Accuracy : 0.9751, \tValid  Accuracy : 0.9578,\t Train Loss : 4034.0927469950425, \tValid Loss :  1553.9645670224209 , Time for 1000 epochs : 1.1180994269961957\n",
      "Epoch 656999 : Train Accuracy : 0.97532, \tValid  Accuracy : 0.9579,\t Train Loss : 4020.4287344676964, \tValid Loss :  1551.6491630880262 , Time for 1000 epochs : 1.0870067999931052\n",
      "Epoch 657999 : Train Accuracy : 0.97538, \tValid  Accuracy : 0.9582,\t Train Loss : 4001.197633003926, \tValid Loss :  1548.2057310040127 , Time for 1000 epochs : 1.0693708329927176\n",
      "Epoch 658999 : Train Accuracy : 0.97562, \tValid  Accuracy : 0.9579,\t Train Loss : 3982.1145185699916, \tValid Loss :  1544.998383233643 , Time for 1000 epochs : 1.0407630919944495\n",
      "Epoch 659999 : Train Accuracy : 0.97554, \tValid  Accuracy : 0.9581,\t Train Loss : 3966.927963821505, \tValid Loss :  1542.584645922459 , Time for 1000 epochs : 15.049982591008302\n",
      "Epoch 660999 : Train Accuracy : 0.9756, \tValid  Accuracy : 0.9576,\t Train Loss : 3955.6546902122286, \tValid Loss :  1541.1388595461747 , Time for 1000 epochs : 1.3565270469989628\n",
      "Epoch 661999 : Train Accuracy : 0.97562, \tValid  Accuracy : 0.9583,\t Train Loss : 3949.3436621096107, \tValid Loss :  1540.9883278370182 , Time for 1000 epochs : 1.3633622380148154\n",
      "Epoch 662999 : Train Accuracy : 0.97544, \tValid  Accuracy : 0.9589,\t Train Loss : 3948.8086780241447, \tValid Loss :  1541.950568291191 , Time for 1000 epochs : 3.9501421120075975\n",
      "Epoch 663999 : Train Accuracy : 0.97542, \tValid  Accuracy : 0.9588,\t Train Loss : 3953.453553739308, \tValid Loss :  1543.7711360532064 , Time for 1000 epochs : 8.64727862799191\n",
      "Epoch 664999 : Train Accuracy : 0.97544, \tValid  Accuracy : 0.9585,\t Train Loss : 3957.9049794060943, \tValid Loss :  1544.95948459803 , Time for 1000 epochs : 4.472368181013735\n",
      "Epoch 665999 : Train Accuracy : 0.97546, \tValid  Accuracy : 0.9585,\t Train Loss : 3960.3189544975944, \tValid Loss :  1545.1043847497347 , Time for 1000 epochs : 12.394403418002184\n",
      "Epoch 666999 : Train Accuracy : 0.97544, \tValid  Accuracy : 0.9585,\t Train Loss : 3959.985580208261, \tValid Loss :  1544.541526044373 , Time for 1000 epochs : 3.399540390004404\n",
      "Epoch 667999 : Train Accuracy : 0.97546, \tValid  Accuracy : 0.9587,\t Train Loss : 3955.4644411795316, \tValid Loss :  1542.9893654435025 , Time for 1000 epochs : 1.2943785380048212\n",
      "Epoch 668999 : Train Accuracy : 0.97554, \tValid  Accuracy : 0.9592,\t Train Loss : 3946.1973058993603, \tValid Loss :  1540.101206734127 , Time for 1000 epochs : 2.532703576987842\n",
      "Epoch 669999 : Train Accuracy : 0.9755, \tValid  Accuracy : 0.9592,\t Train Loss : 3936.506668259661, \tValid Loss :  1536.8327483417772 , Time for 1000 epochs : 1.1508598680084106\n",
      "Epoch 670999 : Train Accuracy : 0.9757, \tValid  Accuracy : 0.9595,\t Train Loss : 3927.8942290641658, \tValid Loss :  1533.7240110015223 , Time for 1000 epochs : 1.3049293659860268\n",
      "Epoch 671999 : Train Accuracy : 0.97584, \tValid  Accuracy : 0.9591,\t Train Loss : 3921.696346666288, \tValid Loss :  1531.3128400190978 , Time for 1000 epochs : 1.149669366015587\n",
      "Epoch 672999 : Train Accuracy : 0.97578, \tValid  Accuracy : 0.9586,\t Train Loss : 3918.822303285792, \tValid Loss :  1529.6931062150602 , Time for 1000 epochs : 1.1518310719984584\n",
      "Epoch 673999 : Train Accuracy : 0.97588, \tValid  Accuracy : 0.9589,\t Train Loss : 3919.0891702659806, \tValid Loss :  1528.6068312934622 , Time for 1000 epochs : 1.163017471000785\n",
      "Epoch 674999 : Train Accuracy : 0.97588, \tValid  Accuracy : 0.9589,\t Train Loss : 3920.095053178137, \tValid Loss :  1527.6281759732062 , Time for 1000 epochs : 1.3651322810037527\n",
      "Epoch 675999 : Train Accuracy : 0.97568, \tValid  Accuracy : 0.9587,\t Train Loss : 3921.367781350739, \tValid Loss :  1527.1331217233492 , Time for 1000 epochs : 7.797042751975823\n",
      "Epoch 676999 : Train Accuracy : 0.97578, \tValid  Accuracy : 0.9588,\t Train Loss : 3923.2846966062066, \tValid Loss :  1527.0441791339495 , Time for 1000 epochs : 3.3202901530021336\n",
      "Epoch 677999 : Train Accuracy : 0.97578, \tValid  Accuracy : 0.9591,\t Train Loss : 3923.9876836490967, \tValid Loss :  1526.8142644791535 , Time for 1000 epochs : 1.5100536730024032\n",
      "Epoch 678999 : Train Accuracy : 0.97578, \tValid  Accuracy : 0.9592,\t Train Loss : 3923.184999283953, \tValid Loss :  1526.672021801947 , Time for 1000 epochs : 4.002642712992383\n",
      "Epoch 679999 : Train Accuracy : 0.97586, \tValid  Accuracy : 0.9592,\t Train Loss : 3921.3545321721135, \tValid Loss :  1526.5965118818865 , Time for 1000 epochs : 12.584747615008382\n",
      "Epoch 680999 : Train Accuracy : 0.97584, \tValid  Accuracy : 0.9592,\t Train Loss : 3918.0755214412716, \tValid Loss :  1526.5202398394947 , Time for 1000 epochs : 4.405347999010701\n",
      "Epoch 681999 : Train Accuracy : 0.97584, \tValid  Accuracy : 0.9592,\t Train Loss : 3912.3786671908856, \tValid Loss :  1526.4023960232753 , Time for 1000 epochs : 3.61686790100066\n",
      "Epoch 682999 : Train Accuracy : 0.97596, \tValid  Accuracy : 0.959,\t Train Loss : 3906.0538214549697, \tValid Loss :  1526.6135424388447 , Time for 1000 epochs : 2.8515121969976462\n",
      "Epoch 683999 : Train Accuracy : 0.9762, \tValid  Accuracy : 0.9588,\t Train Loss : 3899.8543275483576, \tValid Loss :  1527.3038760894394 , Time for 1000 epochs : 4.330009950004751\n",
      "Epoch 684999 : Train Accuracy : 0.97616, \tValid  Accuracy : 0.9584,\t Train Loss : 3893.462889645183, \tValid Loss :  1528.4298411503535 , Time for 1000 epochs : 1.2654533029999584\n",
      "Epoch 685999 : Train Accuracy : 0.97602, \tValid  Accuracy : 0.9585,\t Train Loss : 3889.2608058723936, \tValid Loss :  1529.8367261912204 , Time for 1000 epochs : 1.2328815030050464\n",
      "Epoch 686999 : Train Accuracy : 0.97594, \tValid  Accuracy : 0.9584,\t Train Loss : 3887.5582318842744, \tValid Loss :  1531.385647472606 , Time for 1000 epochs : 1.6147883179946803\n",
      "Epoch 687999 : Train Accuracy : 0.97598, \tValid  Accuracy : 0.9584,\t Train Loss : 3888.4901675107767, \tValid Loss :  1533.409489855658 , Time for 1000 epochs : 4.399741659988649\n",
      "Epoch 688999 : Train Accuracy : 0.97586, \tValid  Accuracy : 0.9586,\t Train Loss : 3890.601248372772, \tValid Loss :  1535.609250012651 , Time for 1000 epochs : 1.4133677660138346\n",
      "Epoch 689999 : Train Accuracy : 0.9758, \tValid  Accuracy : 0.9583,\t Train Loss : 3893.342815686898, \tValid Loss :  1537.543700149072 , Time for 1000 epochs : 1.4860468089755159\n",
      "Epoch 690999 : Train Accuracy : 0.97582, \tValid  Accuracy : 0.9582,\t Train Loss : 3895.0566033626546, \tValid Loss :  1539.110462220535 , Time for 1000 epochs : 1.8824255480139982\n",
      "Epoch 691999 : Train Accuracy : 0.97578, \tValid  Accuracy : 0.9579,\t Train Loss : 3896.4081727242246, \tValid Loss :  1540.4154909026702 , Time for 1000 epochs : 1.606968266016338\n",
      "Epoch 692999 : Train Accuracy : 0.97574, \tValid  Accuracy : 0.9577,\t Train Loss : 3897.350046198818, \tValid Loss :  1541.5700554429566 , Time for 1000 epochs : 1.3638802109926473\n",
      "Epoch 693999 : Train Accuracy : 0.97576, \tValid  Accuracy : 0.9577,\t Train Loss : 3896.924231690923, \tValid Loss :  1542.6114465657672 , Time for 1000 epochs : 1.2120927670039237\n",
      "Epoch 694999 : Train Accuracy : 0.97574, \tValid  Accuracy : 0.9576,\t Train Loss : 3895.9464270334415, \tValid Loss :  1543.9175174969628 , Time for 1000 epochs : 1.7365425610041711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 695999 : Train Accuracy : 0.97568, \tValid  Accuracy : 0.9577,\t Train Loss : 3895.1714326353936, \tValid Loss :  1545.2168340117198 , Time for 1000 epochs : 1.2638434679829516\n",
      "Epoch 696999 : Train Accuracy : 0.97578, \tValid  Accuracy : 0.9576,\t Train Loss : 3893.1569184179098, \tValid Loss :  1546.0423258800859 , Time for 1000 epochs : 1.397146731003886\n",
      "Epoch 697999 : Train Accuracy : 0.976, \tValid  Accuracy : 0.958,\t Train Loss : 3888.0939953522893, \tValid Loss :  1546.391554433899 , Time for 1000 epochs : 2.1972720839839894\n",
      "Epoch 698999 : Train Accuracy : 0.97602, \tValid  Accuracy : 0.958,\t Train Loss : 3881.734697593035, \tValid Loss :  1546.6236051442747 , Time for 1000 epochs : 1.7632037200091872\n",
      "Epoch 699999 : Train Accuracy : 0.9762, \tValid  Accuracy : 0.9583,\t Train Loss : 3876.396714509795, \tValid Loss :  1546.9387566349199 , Time for 1000 epochs : 2.686558142013382\n",
      "Epoch 700999 : Train Accuracy : 0.97614, \tValid  Accuracy : 0.9585,\t Train Loss : 3873.1497972256993, \tValid Loss :  1547.3962975280147 , Time for 1000 epochs : 1.8500096799980383\n",
      "Epoch 701999 : Train Accuracy : 0.97628, \tValid  Accuracy : 0.9586,\t Train Loss : 3872.060581676206, \tValid Loss :  1548.0072158023634 , Time for 1000 epochs : 1.9471449900011066\n",
      "Epoch 702999 : Train Accuracy : 0.97638, \tValid  Accuracy : 0.959,\t Train Loss : 3873.148399256142, \tValid Loss :  1548.949267165341 , Time for 1000 epochs : 3.812082491989713\n",
      "Epoch 703999 : Train Accuracy : 0.97648, \tValid  Accuracy : 0.9586,\t Train Loss : 3875.987482264854, \tValid Loss :  1550.09507709256 , Time for 1000 epochs : 1.2622155529970769\n",
      "Epoch 704999 : Train Accuracy : 0.97666, \tValid  Accuracy : 0.9581,\t Train Loss : 3878.8693081715505, \tValid Loss :  1551.4438426474894 , Time for 1000 epochs : 1.4796470809960738\n",
      "Epoch 705999 : Train Accuracy : 0.97678, \tValid  Accuracy : 0.958,\t Train Loss : 3880.6057355813664, \tValid Loss :  1552.3247343160288 , Time for 1000 epochs : 1.348997747991234\n",
      "Epoch 706999 : Train Accuracy : 0.97676, \tValid  Accuracy : 0.9577,\t Train Loss : 3880.980329222836, \tValid Loss :  1552.7701699640684 , Time for 1000 epochs : 1.615759545005858\n",
      "Epoch 707999 : Train Accuracy : 0.97652, \tValid  Accuracy : 0.9577,\t Train Loss : 3879.885902444156, \tValid Loss :  1552.827029954873 , Time for 1000 epochs : 1.4118877690052614\n",
      "Epoch 708999 : Train Accuracy : 0.97654, \tValid  Accuracy : 0.9577,\t Train Loss : 3877.710153943911, \tValid Loss :  1552.6183919740906 , Time for 1000 epochs : 1.3012870230013505\n",
      "Epoch 709999 : Train Accuracy : 0.97662, \tValid  Accuracy : 0.9579,\t Train Loss : 3872.296735907068, \tValid Loss :  1551.6606599955226 , Time for 1000 epochs : 1.4821700240136124\n",
      "Epoch 710999 : Train Accuracy : 0.97668, \tValid  Accuracy : 0.9578,\t Train Loss : 3864.5435670624693, \tValid Loss :  1550.152062090036 , Time for 1000 epochs : 1.6689948560087942\n",
      "Epoch 711999 : Train Accuracy : 0.97658, \tValid  Accuracy : 0.9579,\t Train Loss : 3855.4956539702835, \tValid Loss :  1548.1891196206032 , Time for 1000 epochs : 2.8006876849976834\n",
      "Epoch 712999 : Train Accuracy : 0.97674, \tValid  Accuracy : 0.9585,\t Train Loss : 3845.717968938141, \tValid Loss :  1545.9387240922138 , Time for 1000 epochs : 1.0966758810100146\n",
      "Epoch 713999 : Train Accuracy : 0.97672, \tValid  Accuracy : 0.9588,\t Train Loss : 3837.6614046232717, \tValid Loss :  1543.9711443914387 , Time for 1000 epochs : 1.2522515210148413\n",
      "Epoch 714999 : Train Accuracy : 0.9766, \tValid  Accuracy : 0.9589,\t Train Loss : 3832.777497278676, \tValid Loss :  1542.9365664254942 , Time for 1000 epochs : 1.678659348981455\n",
      "Epoch 715999 : Train Accuracy : 0.97634, \tValid  Accuracy : 0.9587,\t Train Loss : 3832.0318071883876, \tValid Loss :  1543.0140775836492 , Time for 1000 epochs : 1.3330507620121352\n",
      "Epoch 716999 : Train Accuracy : 0.9764, \tValid  Accuracy : 0.9584,\t Train Loss : 3834.9205483204587, \tValid Loss :  1543.5504019084317 , Time for 1000 epochs : 1.180451095016906\n",
      "Epoch 717999 : Train Accuracy : 0.97628, \tValid  Accuracy : 0.9582,\t Train Loss : 3841.4138103220866, \tValid Loss :  1544.8182873331132 , Time for 1000 epochs : 1.1267490040045232\n",
      "Epoch 718999 : Train Accuracy : 0.97608, \tValid  Accuracy : 0.9581,\t Train Loss : 3851.0305628295177, \tValid Loss :  1546.8287183788257 , Time for 1000 epochs : 1.0853985490102787\n",
      "Epoch 719999 : Train Accuracy : 0.97596, \tValid  Accuracy : 0.9581,\t Train Loss : 3860.710431261943, \tValid Loss :  1549.2676973309635 , Time for 1000 epochs : 2.135612897021929\n",
      "Epoch 720999 : Train Accuracy : 0.97586, \tValid  Accuracy : 0.9579,\t Train Loss : 3868.5382801258716, \tValid Loss :  1551.6355150095471 , Time for 1000 epochs : 1.8023005569993984\n",
      "Epoch 721999 : Train Accuracy : 0.97584, \tValid  Accuracy : 0.9581,\t Train Loss : 3869.744976716614, \tValid Loss :  1552.4386012538064 , Time for 1000 epochs : 2.377871178003261\n",
      "Epoch 722999 : Train Accuracy : 0.97582, \tValid  Accuracy : 0.9579,\t Train Loss : 3864.9983409165625, \tValid Loss :  1551.8275850812897 , Time for 1000 epochs : 1.7614643340057228\n",
      "Epoch 723999 : Train Accuracy : 0.97592, \tValid  Accuracy : 0.9578,\t Train Loss : 3856.293079113031, \tValid Loss :  1550.4406696652468 , Time for 1000 epochs : 1.9405321280064527\n",
      "Epoch 724999 : Train Accuracy : 0.97596, \tValid  Accuracy : 0.9575,\t Train Loss : 3847.014022664503, \tValid Loss :  1548.9050284174343 , Time for 1000 epochs : 1.8628139890206512\n",
      "Epoch 725999 : Train Accuracy : 0.976, \tValid  Accuracy : 0.9577,\t Train Loss : 3837.716594503126, \tValid Loss :  1547.2243785738467 , Time for 1000 epochs : 1.7929196409822907\n",
      "Epoch 726999 : Train Accuracy : 0.97624, \tValid  Accuracy : 0.9578,\t Train Loss : 3829.8544892349214, \tValid Loss :  1545.9621837046218 , Time for 1000 epochs : 3.4820435569854453\n",
      "Epoch 727999 : Train Accuracy : 0.97658, \tValid  Accuracy : 0.9578,\t Train Loss : 3824.068614925101, \tValid Loss :  1545.6117385377881 , Time for 1000 epochs : 1.98282986698905\n",
      "Epoch 728999 : Train Accuracy : 0.97674, \tValid  Accuracy : 0.9578,\t Train Loss : 3819.6427825976516, \tValid Loss :  1546.0406391986426 , Time for 1000 epochs : 1.3801112610090058\n",
      "Epoch 729999 : Train Accuracy : 0.9771, \tValid  Accuracy : 0.9579,\t Train Loss : 3817.2833389713887, \tValid Loss :  1547.2938782817805 , Time for 1000 epochs : 1.561503464996349\n",
      "Epoch 730999 : Train Accuracy : 0.97724, \tValid  Accuracy : 0.9581,\t Train Loss : 3816.772563786894, \tValid Loss :  1549.1047775817524 , Time for 1000 epochs : 1.3575432039797306\n",
      "Epoch 731999 : Train Accuracy : 0.97724, \tValid  Accuracy : 0.9585,\t Train Loss : 3816.7299463998306, \tValid Loss :  1551.2910425419263 , Time for 1000 epochs : 1.6629436659859493\n",
      "Epoch 732999 : Train Accuracy : 0.9773, \tValid  Accuracy : 0.9585,\t Train Loss : 3815.949246221908, \tValid Loss :  1553.8299561869117 , Time for 1000 epochs : 1.792527298006462\n",
      "Epoch 733999 : Train Accuracy : 0.97728, \tValid  Accuracy : 0.9581,\t Train Loss : 3813.8622778196614, \tValid Loss :  1556.7317134012278 , Time for 1000 epochs : 1.4184019319945946\n",
      "Epoch 734999 : Train Accuracy : 0.97734, \tValid  Accuracy : 0.958,\t Train Loss : 3810.780069498931, \tValid Loss :  1559.5747881790085 , Time for 1000 epochs : 1.288187152997125\n",
      "Epoch 735999 : Train Accuracy : 0.97712, \tValid  Accuracy : 0.9581,\t Train Loss : 3806.874858721387, \tValid Loss :  1562.3325131797692 , Time for 1000 epochs : 1.7440092389879283\n",
      "Epoch 736999 : Train Accuracy : 0.9772, \tValid  Accuracy : 0.958,\t Train Loss : 3804.7627814939547, \tValid Loss :  1565.3451951223024 , Time for 1000 epochs : 1.6198003549943678\n",
      "Epoch 737999 : Train Accuracy : 0.97722, \tValid  Accuracy : 0.9574,\t Train Loss : 3805.0872254092874, \tValid Loss :  1568.582399418486 , Time for 1000 epochs : 1.762784032995114\n",
      "Epoch 738999 : Train Accuracy : 0.977, \tValid  Accuracy : 0.957,\t Train Loss : 3806.578080295063, \tValid Loss :  1571.7194053859212 , Time for 1000 epochs : 1.3349578230117913\n",
      "Epoch 739999 : Train Accuracy : 0.97702, \tValid  Accuracy : 0.957,\t Train Loss : 3807.238542915751, \tValid Loss :  1574.55842768066 , Time for 1000 epochs : 3.23892800899921\n",
      "Epoch 740999 : Train Accuracy : 0.9769, \tValid  Accuracy : 0.9574,\t Train Loss : 3807.0603242294874, \tValid Loss :  1576.6620608341027 , Time for 1000 epochs : 1.5211262129887473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 741999 : Train Accuracy : 0.97702, \tValid  Accuracy : 0.957,\t Train Loss : 3806.0614381849136, \tValid Loss :  1578.1988502975987 , Time for 1000 epochs : 1.241922954999609\n",
      "Epoch 742999 : Train Accuracy : 0.9769, \tValid  Accuracy : 0.9569,\t Train Loss : 3805.5366687479386, \tValid Loss :  1579.5710110602054 , Time for 1000 epochs : 1.1818526329880115\n",
      "Epoch 743999 : Train Accuracy : 0.97698, \tValid  Accuracy : 0.957,\t Train Loss : 3804.8346159756984, \tValid Loss :  1580.4872812817043 , Time for 1000 epochs : 1.1483458649890963\n",
      "Epoch 744999 : Train Accuracy : 0.97714, \tValid  Accuracy : 0.957,\t Train Loss : 3803.1282735484156, \tValid Loss :  1580.7300421640848 , Time for 1000 epochs : 1.65536198602058\n",
      "Epoch 745999 : Train Accuracy : 0.97712, \tValid  Accuracy : 0.9573,\t Train Loss : 3800.4582792259002, \tValid Loss :  1580.4737802364384 , Time for 1000 epochs : 1.2157524309877772\n",
      "Epoch 746999 : Train Accuracy : 0.97718, \tValid  Accuracy : 0.9575,\t Train Loss : 3796.5461684243223, \tValid Loss :  1579.6196669443182 , Time for 1000 epochs : 1.2744282800122164\n",
      "Epoch 747999 : Train Accuracy : 0.97712, \tValid  Accuracy : 0.9577,\t Train Loss : 3792.448998116141, \tValid Loss :  1578.444615324146 , Time for 1000 epochs : 1.1681889040046372\n",
      "Epoch 748999 : Train Accuracy : 0.97712, \tValid  Accuracy : 0.9577,\t Train Loss : 3789.0032700337338, \tValid Loss :  1577.4875424347088 , Time for 1000 epochs : 1.1371563069988042\n",
      "Epoch 749999 : Train Accuracy : 0.97716, \tValid  Accuracy : 0.9579,\t Train Loss : 3785.6462378358506, \tValid Loss :  1576.341761181342 , Time for 1000 epochs : 1.6789967770164367\n",
      "Epoch 750999 : Train Accuracy : 0.97708, \tValid  Accuracy : 0.958,\t Train Loss : 3781.963046477848, \tValid Loss :  1574.8024777945113 , Time for 1000 epochs : 1.5717406579933595\n",
      "Epoch 751999 : Train Accuracy : 0.97708, \tValid  Accuracy : 0.9577,\t Train Loss : 3777.9462203024723, \tValid Loss :  1573.2114245300208 , Time for 1000 epochs : 2.235106309002731\n",
      "Epoch 752999 : Train Accuracy : 0.9772, \tValid  Accuracy : 0.9581,\t Train Loss : 3775.2123116786224, \tValid Loss :  1572.1638240830143 , Time for 1000 epochs : 1.2137084389978554\n",
      "Epoch 753999 : Train Accuracy : 0.97724, \tValid  Accuracy : 0.9579,\t Train Loss : 3773.7898071686295, \tValid Loss :  1571.655949792622 , Time for 1000 epochs : 1.4517566120193806\n",
      "Epoch 754999 : Train Accuracy : 0.97716, \tValid  Accuracy : 0.9581,\t Train Loss : 3772.999463163723, \tValid Loss :  1571.6299832471593 , Time for 1000 epochs : 1.470561905996874\n",
      "Epoch 755999 : Train Accuracy : 0.97716, \tValid  Accuracy : 0.9579,\t Train Loss : 3771.7708618887045, \tValid Loss :  1571.7778783389786 , Time for 1000 epochs : 1.2843013599922415\n",
      "Epoch 756999 : Train Accuracy : 0.97724, \tValid  Accuracy : 0.9578,\t Train Loss : 3770.009579366055, \tValid Loss :  1572.018222101298 , Time for 1000 epochs : 1.1607397350016981\n",
      "Epoch 757999 : Train Accuracy : 0.97734, \tValid  Accuracy : 0.9579,\t Train Loss : 3766.5011405908144, \tValid Loss :  1572.5472971199006 , Time for 1000 epochs : 1.8258550929895137\n",
      "Epoch 758999 : Train Accuracy : 0.97746, \tValid  Accuracy : 0.958,\t Train Loss : 3762.148569812544, \tValid Loss :  1573.0488753209124 , Time for 1000 epochs : 1.9539166879840195\n",
      "Epoch 759999 : Train Accuracy : 0.9776, \tValid  Accuracy : 0.9582,\t Train Loss : 3756.9324322935367, \tValid Loss :  1573.4368780574905 , Time for 1000 epochs : 1.6539693140075542\n",
      "Epoch 760999 : Train Accuracy : 0.97778, \tValid  Accuracy : 0.958,\t Train Loss : 3752.080854158179, \tValid Loss :  1573.97468513467 , Time for 1000 epochs : 1.3079558610043023\n",
      "Epoch 761999 : Train Accuracy : 0.97794, \tValid  Accuracy : 0.9577,\t Train Loss : 3747.6824819872672, \tValid Loss :  1574.7324380103917 , Time for 1000 epochs : 1.4353468460030854\n",
      "Epoch 762999 : Train Accuracy : 0.97796, \tValid  Accuracy : 0.9579,\t Train Loss : 3744.493922218918, \tValid Loss :  1575.829084174405 , Time for 1000 epochs : 1.2496054400107823\n",
      "Epoch 763999 : Train Accuracy : 0.97792, \tValid  Accuracy : 0.9579,\t Train Loss : 3742.1778348148655, \tValid Loss :  1577.1464763149104 , Time for 1000 epochs : 2.1652501889911946\n",
      "Epoch 764999 : Train Accuracy : 0.97786, \tValid  Accuracy : 0.9577,\t Train Loss : 3741.354460533603, \tValid Loss :  1578.551503979798 , Time for 1000 epochs : 1.157875695003895\n",
      "Epoch 765999 : Train Accuracy : 0.97784, \tValid  Accuracy : 0.9581,\t Train Loss : 3740.683067997858, \tValid Loss :  1579.7298868896685 , Time for 1000 epochs : 1.3354292869917117\n",
      "Epoch 766999 : Train Accuracy : 0.97778, \tValid  Accuracy : 0.9581,\t Train Loss : 3740.010288160319, \tValid Loss :  1580.9443752793982 , Time for 1000 epochs : 1.6051001910236664\n",
      "Epoch 767999 : Train Accuracy : 0.9777, \tValid  Accuracy : 0.9578,\t Train Loss : 3739.350295521794, \tValid Loss :  1582.0635181279863 , Time for 1000 epochs : 1.7626706259907223\n",
      "Epoch 768999 : Train Accuracy : 0.97766, \tValid  Accuracy : 0.9577,\t Train Loss : 3737.7830062689704, \tValid Loss :  1582.6020928561636 , Time for 1000 epochs : 1.7678273800120223\n",
      "Epoch 769999 : Train Accuracy : 0.97768, \tValid  Accuracy : 0.9574,\t Train Loss : 3735.9905996205, \tValid Loss :  1582.9299815838192 , Time for 1000 epochs : 1.6369160499889404\n",
      "Epoch 770999 : Train Accuracy : 0.97762, \tValid  Accuracy : 0.9573,\t Train Loss : 3733.860105785864, \tValid Loss :  1582.8643609575233 , Time for 1000 epochs : 1.7354753699910361\n",
      "Epoch 771999 : Train Accuracy : 0.9776, \tValid  Accuracy : 0.957,\t Train Loss : 3731.759919752781, \tValid Loss :  1582.4774830065396 , Time for 1000 epochs : 2.2364394900214393\n",
      "Epoch 772999 : Train Accuracy : 0.97754, \tValid  Accuracy : 0.9572,\t Train Loss : 3730.625367691612, \tValid Loss :  1582.1338689573001 , Time for 1000 epochs : 1.5710528369818348\n",
      "Epoch 773999 : Train Accuracy : 0.97758, \tValid  Accuracy : 0.9574,\t Train Loss : 3729.7208634757085, \tValid Loss :  1581.401316512728 , Time for 1000 epochs : 1.6145790340087842\n",
      "Epoch 774999 : Train Accuracy : 0.97766, \tValid  Accuracy : 0.9576,\t Train Loss : 3728.486743210705, \tValid Loss :  1580.3128801566008 , Time for 1000 epochs : 1.6520005530037452\n",
      "Epoch 775999 : Train Accuracy : 0.97762, \tValid  Accuracy : 0.9577,\t Train Loss : 3726.834418591811, \tValid Loss :  1579.1136642422414 , Time for 1000 epochs : 1.3143918839923572\n",
      "Epoch 776999 : Train Accuracy : 0.97766, \tValid  Accuracy : 0.9577,\t Train Loss : 3724.250514314057, \tValid Loss :  1577.8865659717537 , Time for 1000 epochs : 1.2978922479960602\n",
      "Epoch 777999 : Train Accuracy : 0.97754, \tValid  Accuracy : 0.9578,\t Train Loss : 3721.3351587223674, \tValid Loss :  1576.7114661749229 , Time for 1000 epochs : 1.492064752994338\n",
      "Epoch 778999 : Train Accuracy : 0.97742, \tValid  Accuracy : 0.9577,\t Train Loss : 3719.1731476932378, \tValid Loss :  1575.5775787565494 , Time for 1000 epochs : 1.5552821190212853\n",
      "Epoch 779999 : Train Accuracy : 0.97746, \tValid  Accuracy : 0.9574,\t Train Loss : 3717.485909089204, \tValid Loss :  1574.5545242696694 , Time for 1000 epochs : 1.5787318310176488\n",
      "Epoch 780999 : Train Accuracy : 0.97758, \tValid  Accuracy : 0.9574,\t Train Loss : 3715.6401884534725, \tValid Loss :  1573.6010600900509 , Time for 1000 epochs : 1.6601350790006109\n",
      "Epoch 781999 : Train Accuracy : 0.97764, \tValid  Accuracy : 0.9573,\t Train Loss : 3713.599700952523, \tValid Loss :  1572.701904109682 , Time for 1000 epochs : 1.5650815989938565\n",
      "Epoch 782999 : Train Accuracy : 0.9776, \tValid  Accuracy : 0.9575,\t Train Loss : 3711.377245346192, \tValid Loss :  1571.8054792090047 , Time for 1000 epochs : 1.3032304070075043\n",
      "Epoch 783999 : Train Accuracy : 0.97758, \tValid  Accuracy : 0.9576,\t Train Loss : 3708.1976704188223, \tValid Loss :  1570.9453080816297 , Time for 1000 epochs : 1.3373321120161563\n",
      "Epoch 784999 : Train Accuracy : 0.97762, \tValid  Accuracy : 0.9575,\t Train Loss : 3704.3748163953233, \tValid Loss :  1570.3981742491624 , Time for 1000 epochs : 1.320494175015483\n",
      "Epoch 785999 : Train Accuracy : 0.97772, \tValid  Accuracy : 0.9573,\t Train Loss : 3700.355581429558, \tValid Loss :  1570.1363937597446 , Time for 1000 epochs : 1.5335922550002579\n",
      "Epoch 786999 : Train Accuracy : 0.97782, \tValid  Accuracy : 0.9575,\t Train Loss : 3696.7618562186776, \tValid Loss :  1570.3547846839206 , Time for 1000 epochs : 1.5411091780115385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 787999 : Train Accuracy : 0.97792, \tValid  Accuracy : 0.9575,\t Train Loss : 3694.6761432700773, \tValid Loss :  1570.9964858978244 , Time for 1000 epochs : 1.3595549979945645\n",
      "Epoch 788999 : Train Accuracy : 0.97798, \tValid  Accuracy : 0.9575,\t Train Loss : 3694.141871019865, \tValid Loss :  1572.3562197988542 , Time for 1000 epochs : 1.566001730010612\n",
      "Epoch 789999 : Train Accuracy : 0.9778, \tValid  Accuracy : 0.9578,\t Train Loss : 3696.117177501909, \tValid Loss :  1574.4760865798955 , Time for 1000 epochs : 1.2819081720081158\n",
      "Epoch 790999 : Train Accuracy : 0.9778, \tValid  Accuracy : 0.9577,\t Train Loss : 3700.4855403033353, \tValid Loss :  1577.0456125515027 , Time for 1000 epochs : 1.3911307170055807\n",
      "Epoch 791999 : Train Accuracy : 0.97772, \tValid  Accuracy : 0.958,\t Train Loss : 3705.815125005499, \tValid Loss :  1579.508770354867 , Time for 1000 epochs : 1.2668005919840652\n",
      "Epoch 792999 : Train Accuracy : 0.97762, \tValid  Accuracy : 0.9579,\t Train Loss : 3710.434827272686, \tValid Loss :  1581.5437396873617 , Time for 1000 epochs : 1.6100895289855544\n",
      "Epoch 793999 : Train Accuracy : 0.97762, \tValid  Accuracy : 0.9579,\t Train Loss : 3713.10875253526, \tValid Loss :  1582.8978017625907 , Time for 1000 epochs : 1.8242085099918768\n",
      "Epoch 794999 : Train Accuracy : 0.9777, \tValid  Accuracy : 0.9578,\t Train Loss : 3713.096711457712, \tValid Loss :  1583.6540754676953 , Time for 1000 epochs : 3.363210634008283\n",
      "Epoch 795999 : Train Accuracy : 0.9777, \tValid  Accuracy : 0.9579,\t Train Loss : 3711.293990464485, \tValid Loss :  1583.8475689073673 , Time for 1000 epochs : 3.274848019995261\n",
      "Epoch 796999 : Train Accuracy : 0.97758, \tValid  Accuracy : 0.9577,\t Train Loss : 3706.8636211872717, \tValid Loss :  1583.22495438953 , Time for 1000 epochs : 1.2066177009837702\n",
      "Epoch 797999 : Train Accuracy : 0.9777, \tValid  Accuracy : 0.9579,\t Train Loss : 3700.4888805243822, \tValid Loss :  1582.0247719091292 , Time for 1000 epochs : 1.8307027390110306\n",
      "Epoch 798999 : Train Accuracy : 0.97772, \tValid  Accuracy : 0.9582,\t Train Loss : 3693.1934851546807, \tValid Loss :  1580.5378854403596 , Time for 1000 epochs : 1.1569055730069522\n",
      "Epoch 799999 : Train Accuracy : 0.97776, \tValid  Accuracy : 0.9585,\t Train Loss : 3686.6602125788454, \tValid Loss :  1579.0263264744342 , Time for 1000 epochs : 1.4718673239985947\n"
     ]
    }
   ],
   "source": [
    "trainLogSAG = train_loopSAG(800000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction pour calculer le temps en fonction de chaque epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculatesTimes(X):\n",
    "    newArr = []\n",
    "    newArr.append(X[0])\n",
    "    for i in range(1, len(X)):\n",
    "        newArr.append(X[i] + newArr[i-1])\n",
    "    return newArr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphiques, comparaison et discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francoisdavid/miniconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py:128: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(calculatesTimes(trainLogSG[\"time\"]), trainLogSG[\"train_lossSG\"] )\n",
    "plt.plot(calculatesTimes(trainLogFD[\"time\"]), trainLogFD[\"train_lossFD\"] )\n",
    "plt.plot(calculatesTimes(trainLogSAG[\"time\"][:800]), trainLogSAG[\"train_lossFD\"][:800] )\n",
    "\n",
    "\n",
    "plt.xlabel('Temps en Secondes')\n",
    "plt.ylabel('Erreur d\\'entropie croisée')\n",
    "\n",
    "plt.legend([\"Stochastic Gradient\", \"Finite  Gradient\" , \"Stochastic Average Gradient\"])\n",
    "plt.title(\"Convergence de l'erreur d\\'entropie croisée des 3 algorithmes sur le dataset MNIST\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparativement, nous pouvons voir que l'algorithme du SAG converge de façon très rapide vers l'optimum. Au départ, puisque les index visités sont minimes, l'algorithme du SAG diminue très rapidement l'erreur tel l'algorithme du Stochastic Gradient. Par la suite, plus les itérations se multiplient, plus la moyenne des gradients visités prend en considération plus de paires du de l'ensemble d'entrainement et, par ce fait même, des tendances de l'algorithme du Finite Gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SG Temps pour 1000 itérations:  0.7366669293014857  secondes\n",
      "FD Temps pour 1 itération:  15.659318439675554  secondes\n",
      "SAG Temps pour 1000 itérations:  1.6737234646915748  secondes\n"
     ]
    }
   ],
   "source": [
    "print(\"SG Temps pour 1000 itérations: \", np.array(trainLogSG[\"time\"]).mean() * 1000 , \" secondes\")\n",
    "print(\"FD Temps pour 1 itération: \", np.array(trainLogFD[\"time\"]).mean(), \" secondes\")\n",
    "print(\"SAG Temps pour 1000 itérations: \", np.array(trainLogSAG[\"time\"][:800]).mean(), \" secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme du Finite Gradient est celui qui prend le plus de temps puisqu'il itère sur toutes les données de  l'ensemble d'entrainement, pour un total de 80 \"effectives passes\" à travers les données ($80 \\times 50 000$ calculations de gradients pour 80 modifications de paramètres du réseau de neurones). Chacune de ces modifications prenait environ 15.66 secondes à être calculée. \n",
    "Comparativement à l'algorithme du Stochastic Gradient, le SAG prend un peu plus de temps (pour le même nombre d'évaluation de fonctions/itérations) principalement puisque nous devons ajuster le dictionnaire de mémoire des gradients ainsi que le déplacement avec la moyenne des index recherchés. Pour 1000 itérations (modifications des paramètres) l'algorithme SG prend environ 0.73 secondes / 1000 itérations  alors que le SAG prend environ 1.6737 secondes  / 1000 itérations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est facile de voir que,  au  départ, l'algorithme du Stochastic Gradient converge rapidement vers l'optimum. Cependant, il se met à osciller vers  la valeur d'environ 18000 de l'erreur d'entropy-croisée puisque les modifications faites à l'algorithme ne reflètent pas toutes les fonctions désirées (paires de données) et ne représente pas une direction de descente générale vers l'optimum. De plus, nous pouvons constater que le SAG obtient les mêmes tendances que le SG (converge rapide au départ) mais n'oscille pas beaucoup dans la convergence puisque les fonctions prises en compte dans le gradient de déplacement sont plus nombreuses et donc plus générales, ce qui permet d'avoir une meilleure estimation de la descente optimale.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après les premières itérations de l'algorithme, le SAG devient similaire au Finite Gradient tout en gardant un coût d'itération de O(1) comparativement à O(n) pour le Finite Gradient. Au final, pour un considérable laps de temps, nous  pouvons donc voir que le SAG se rapproche plus rapidement de l'optimum que le FG et devrait être utilisé si nous n'avons pas assez de ressources/temps pour évaluer les finite gradient jusqu'à point minimum (optimum) de la fonction g(x). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est important de noter que dans l'algorithme du Stochastic Gradient ainsi que le Stochastic Average Gradient, je n'ai pas utilisé de Minibatch pour pouvoir observer les tendances des algorithmes standards (sans prendre avantage de la computation en parallèle des architectures modernes).  Cependant, il pourrait être intéressant de comparer les algorithmes avec les minibatchs puisque de ce fait, les gradients calculés à chaque itération seraient une moyennes d'un nombre arbitraire de fonctions/paires de données et seraient donc plus représentatifs du gradient optimal. Dans cette même optique, le calcul des gradients dans l'algorithme du Finite Difference est fait un à la fois pour ne pas qu'un algorithme soit avantagé par la computation en parallèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Évaluation similaire sur le set de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francoisdavid/miniconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py:128: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(calculatesTimes(trainLogSG[\"time\"]), trainLogSG[\"validation_lossSG\"] )\n",
    "plt.plot(calculatesTimes(trainLogFD[\"time\"]), trainLogFD[\"validation_lossFD\"] )\n",
    "plt.plot(calculatesTimes(trainLogSAG[\"time\"][:800]), trainLogSAG[\"validation_lossFD\"][:800] )\n",
    "\n",
    "plt.xlabel('Temps en Secondes')\n",
    "plt.ylabel('Erreur d\\'entropie croisée')\n",
    "\n",
    "plt.legend([\"Stochastic Gradient\", \"Finite  Gradient\" , \"Stochastic Average Gradient\"])\n",
    "plt.title(\"Convergence de l'erreur d\\'entropie croisée des 3 algorithmes sur le dataset MNIST (Validation)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que les mêmes tendances sont observées sur le set de validation comparativement au set d'entrainement. Ce qui signifie que les tendances sont représentatives des données similaires au MNIST et le modèle peut performer de manière similaire sur de nouvelles images du même type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discusion  sur les conditions d'arrêt des algorithmes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une des questions importantes dans l'entrainement des algorithmes d'entrainement de Deep Learning est les conditions d'arrêts, soit quand devons-nous arrêter d'entrainer notre réseau de neurones. Pour l'algorithme du Stochastic Average Gradient ainsi que celui du Finite Gradient, il devrait toujours se diriger de manière relativement constante vers l'objectif X*. Dans ce cas, il est avantageux d'exécuter l'algorithme pour le plus de temps possible jusqu'à ce qu'il ait atteint le seuil de précision espéré. Ces algorithmes se dirigent vers l'optimum de manière linéaire avec un taux de convergence de $g^k$ pour $0<g<1$. Cependant, le Stochastic Average Gradient prend en considération que le gradient de chaque fonction sélectionnée est relativement proche du gradient des prochaines itérations. Dans quelques situations, il se peut que ce ne soit pas le cas et que le modèle ne s'améliore pas à chaque itération. Dans ce cas, il serait préférable d'avoir une condition d'arrêt si le modèle n'améliore pas la situation actuelle (comme le \"Early-Stopping\" discuté dans le dernier paragraphe de cette sous-section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas de l'algorithme du Stochastic Gradient, il converge vers l'optimum de manière sous-linéaire avec un  taux de convergence de $1/k$. Après un grand nombre d'itérations k, le progrès marginal vers la solution diminue grandement et puisque chaque itération de cet algorithme ne prend en considération qu'une paire de données de l'ensemble d'entrainement, l'algorithme peut osciller puisque le gradient calculé n'était pas le gradient optimal.  Donc un point à une certaine itération antérieure peut avoir obtenu une meilleure optimisation de  l'objectif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une technique utile pour le Stochastic Gradient est une version de ce qui est appelé l' \"early-stopping\" où nous calculons à chaque itération le résultat de la fonction objectif, gardons en mémoire les paramètres de l'itération à laquelle la fonction objective était la plus optimale. Lorsque ce résultat n'a pas été améliorer (diminuer dans ce cas-ci) pour un certain nombre d'itérations, nous arrêtons l'algorithme et utilisons les paramètres qui ont été sauvegardés à l'itération durant laquelle la solution était la plus optimale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approche avec une technique de \"Retrospective Approximation\" adaptée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet algorithme, j'utilise les concepts de Retrospective Approximation pour tenter d'obtenir un comparatif avec les trois algorithmes étudiés plus haut.  Je commence l'algorithme avec un ensemble de 100 fonctions (paires de données) et je modifie l'architecture avec le finite gradient sur cet ensemble (rapide et précis la taille de cet ensemble n'est pas grande) pour obtenir un niveau d'erreur de précision de classification de $ 80\\% \\times \\left(\\frac{99}{100}\\right)^k $, ou k est l'itération actuelle. Cette séquence tend vers 0 alors que les itérations s'accumulent, nous sommes donc de plus en plus exigeants par rapport à la performance de l'algorithme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À chaque itération, la taille des échantillons correspond à $ 100 + (100)k $, ou k est l'itération actuelle. Donc la taille de l'échantillon que nous prenons en compte augmente de 100 nouvelles fonctions/paires de données à chaque itération. La séquence des Ws peut être décrite par à l'iteration k par :  $1/2$ à l'itération actuelle et $1/{2^{k+1-i}}$ pour tous les index des itérations antérieures i. À chaque itération, je m'assure de prendre les données d'entrainement qui n'ont pas été choisies à l'itération précédente en gardant un index modulo de la taille de cet ensemble. Dans cet exemple simpliste, l'échantillon est augmenté linéairement et inclus continuellement de nouvelles fonctions f(x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après plusieurs essais-erreurs, j'ai également constaté qu'il était peut-être plus adéquat de ne plus diminuer l'erreur désirée lorsqu'elle devenait inférieure à 4% puisque les itérations prenaient une large durée de temps pour converger sans trop faire de progrès sur l'ensemble des données et je ne voulais pas que l'algorithme \"overtrain\" sur les données de l'échantillon. De plus, dans les 3 algorithmes plus haut, l'erreur de précision de classification devient rarement en dessous de 3-4 % pour l'ensemble des 50 000 paires de données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loopRetroApprox(iterations):\n",
    "    train_logs = {'train_accuracyFD': [], 'validation_accuracyFD': [], 'train_lossFD': [], 'validation_lossFD': [], 'time': []}\n",
    "    X_trainAll, y_trainAll = train\n",
    "    y_onehot = y_trainAll\n",
    "    dims = [X_trainAll.shape[1], y_onehot.shape[1]]\n",
    "    hidden_dims = hidden_dims = (64, 32)\n",
    "    weights = initialize_weights(dims, hidden_dims)\n",
    "    batch_size = 1\n",
    "    alpha = 0.9999\n",
    "       \n",
    "    # Selection du premier sample size. \n",
    "    sampleSize = 100 \n",
    "    iteration =  0\n",
    "    ErrorThreshold = 0.8\n",
    "    ErrorPercent = 1.0\n",
    "    weightsX =  {} \n",
    "    previousLoss = 2147483647 # Le plus grand integer possible (python)\n",
    "    \n",
    "    cumulativeIndex = 0  # Pour regarder quelles fonctions on été évaluées.\n",
    "    gradsOld = {}\n",
    "    for iteration in range(iterations):\n",
    "        start = timeit.default_timer()\n",
    "        # Reset l'erreur pour quelle soit re-calculé avec la nouvelle taille d'échatillon (sampleSize) \n",
    "        ErrorPercent = 1.0\n",
    "        \n",
    "        Xt, yt = train\n",
    "        X_trainS = Xt[:sampleSize, :]\n",
    "        y_trainS = yt[:sampleSize, :]\n",
    "        \n",
    "        Xv, yv = valid\n",
    "        X_validS = Xv[:sampleSize, :]\n",
    "        y_validS = yv[:sampleSize, :]\n",
    "        \n",
    "        # Ajuster le taux d'apprentissage.\n",
    "        subAlpha = alpha\n",
    "        \n",
    "       \n",
    "        while(ErrorPercent >  ErrorThreshold):\n",
    "            #  Selection d'un index aléatoire dépendament du nombre de donnée dans le training data.\n",
    "            gradsS = {}\n",
    "            for i in range(sampleSize):  # La grosseur du training set.\n",
    "                #print(sampleSize, X_trainS.shape)\n",
    "                \n",
    "                batchX = X_trainS[1 * (i + cumulativeIndex):1 * (i + cumulativeIndex + 1), :]\n",
    "                batchY = y_trainS[1 * (i + cumulativeIndex):1 * (i + cumulativeIndex + 1), :]\n",
    "                cumulativeIndex += 1 \n",
    "                # Regarder pour s'assurer de ne pas aller à l'extérieur de l'ensemble à la prochaine calculation. \n",
    "                if cumulativeIndex == 49999:\n",
    "                    cumulativeIndex = 0 \n",
    "                \n",
    "                cache = forward(batchX, weights, hidden_dims)\n",
    "                grads = backward(weights, cache, batchY, hidden_dims)\n",
    "\n",
    "                # Pour tous les éléments, les additionner pour pouvoir diviser et obtenir la moyenne.\n",
    "                # Si pas la première itération, additionner les nouveaux grads,\n",
    "                if i != 0:\n",
    "                    gradsS['dW3'] += grads[\"dW3\"]\n",
    "                    gradsS[\"dW2\"] += grads[\"dW2\"]\n",
    "                    gradsS[\"dW1\"] += grads[\"dW1\"]\n",
    "                    gradsS[\"db3\"] += grads[\"db3\"]\n",
    "                    gradsS[\"db2\"] += grads[\"db2\"]\n",
    "                    gradsS[\"db1\"] += grads[\"db1\"]\n",
    "                # Si la première itérations, initialiser les gradients avec les gradients respectifs.\n",
    "                else:\n",
    "                    gradsS['dW3'] = grads[\"dW3\"]\n",
    "                    gradsS[\"dW2\"] = grads[\"dW2\"]\n",
    "                    gradsS[\"dW1\"] = grads[\"dW1\"]\n",
    "                    gradsS[\"db3\"] = grads[\"db3\"]\n",
    "                    gradsS[\"db2\"] = grads[\"db2\"]\n",
    "                    gradsS[\"db1\"] = grads[\"db1\"]\n",
    "            if iteration == 0 : \n",
    "                # Diviser pour obtenir la moyenne de chaque gradients.\n",
    "                gradsOld['dW3'] = gradsS[\"dW3\"] * 1 / sampleSize\n",
    "                gradsOld[\"dW2\"] = gradsS[\"dW2\"] * 1 / sampleSize\n",
    "                gradsOld[\"dW1\"] = gradsS[\"dW1\"] * 1 / sampleSize\n",
    "                gradsOld[\"db3\"] = gradsS[\"db3\"] * 1 / sampleSize\n",
    "                gradsOld[\"db2\"] = gradsS[\"db2\"] * 1 / sampleSize\n",
    "                gradsOld[\"db1\"] = gradsS[\"db1\"] * 1 / sampleSize\n",
    "            else : \n",
    "                gradsOld['dW3'] = (gradsS[\"dW3\"] + gradsOld[\"dW3\"]) / sampleSize * 2\n",
    "                gradsOld[\"dW2\"] = (gradsS[\"dW2\"] + gradsOld[\"dW2\"]) / sampleSize * 2\n",
    "                gradsOld[\"dW1\"] = (gradsS[\"dW1\"] + gradsOld[\"dW1\"]) / sampleSize * 2\n",
    "                gradsOld[\"db3\"] = (gradsS[\"db3\"] + gradsOld[\"db3\"]) / sampleSize * 2\n",
    "                gradsOld[\"db2\"] = (gradsS[\"db2\"] + gradsOld[\"db2\"]) / sampleSize * 2\n",
    "                gradsOld[\"db1\"] = (gradsS[\"db1\"] + gradsOld[\"db1\"]) / sampleSize * 2\n",
    "            \n",
    "            # Updater les weights.\n",
    "            weights = update(gradsOld, weights, hidden_dims, subAlpha)\n",
    "            \n",
    "            # Calculate the loss according to the sample selected.\n",
    "            train_loss, train_accuracy, _ = compute_loss_and_accuracy(X_trainS, y_trainS, weights, hidden_dims)\n",
    "            valid_loss, valid_accuracy, _ = compute_loss_and_accuracy(X_validS, y_validS, weights, hidden_dims)\n",
    "           \n",
    "            # Changer l'erreur selon la sous-itération avec le sous échantions de cette itération.\n",
    "            ErrorPercent = 1.0 - train_accuracy \n",
    "            # Modifier le taux d'apprentissage.\n",
    "            if(ErrorPercent  >  ErrorThreshold):\n",
    "                subAlpha *= .98888888\n",
    "\n",
    "        print(\"\\t\\tErrorPercent on sample: \",  ErrorPercent, \"ErrorThreshold: \", ErrorThreshold)\n",
    "        # Arrêter le timer pour calculer cette itération.\n",
    "        stop = timeit.default_timer()\n",
    "        \n",
    "        # Calculer la loss sur tout l'ensemble des données pour voir la convergence\n",
    "        X_trainAll, y_trainAll = train\n",
    "        train_lossAll, train_accuracyAll, _ = compute_loss_and_accuracy(X_trainAll, y_trainAll, weights, hidden_dims)\n",
    "        X_validAll, y_validAll = valid\n",
    "        valid_lossAll, valid_accuracyAll, _ = compute_loss_and_accuracy(X_validAll, y_validAll, weights, hidden_dims)\n",
    "        \n",
    "        if train_loss > previousLoss:\n",
    "            alpha  = alpha  *  .923\n",
    "        previousLoss = train_lossAll\n",
    "        \n",
    "        # Augmenter le sampleSize et diminuer l'erreur voulu\n",
    "        sampleSize += 100 \n",
    "        \n",
    "        #  J'ai réaliser que ça prennait trop de temps a converger lorsque le seuil d'erreur devenait trop petit. \n",
    "        if ErrorThreshold > 0.04:\n",
    "            ErrorThreshold  *= 95/100\n",
    "        \n",
    "        # Imprimer la loss et la precision. Ça l'aide a suivre le progrès\n",
    "        print(f\"Iteration {iteration} : Train Accuracy : {train_accuracyAll}, \\tValid  Accuracy : {valid_accuracyAll},\\t Train Loss : {train_lossAll}, \\tValid Loss :  {valid_lossAll} , Time : {stop - start}\")\n",
    "       \n",
    "        train_logs['train_accuracyFD'].append(train_accuracyAll)\n",
    "        train_logs['validation_accuracyFD'].append(valid_accuracyAll)\n",
    "        train_logs['train_lossFD'].append(train_lossAll)\n",
    "        train_logs['validation_lossFD'].append(valid_lossAll)\n",
    "        train_logs['time'].append(stop - start)\n",
    "        \n",
    "\n",
    "    return train_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tErrorPercent on sample:  0.71 ErrorThreshold:  0.8\n",
      "Iteration 0 : Train Accuracy : 0.21762, \tValid  Accuracy : 0.2249,\t Train Loss : 111199.37841812246, \tValid Loss :  22173.677844642407 , Time : 0.029593589017167687\n",
      "\t\tErrorPercent on sample:  0.64 ErrorThreshold:  0.76\n",
      "Iteration 1 : Train Accuracy : 0.26276, \tValid  Accuracy : 0.2719,\t Train Loss : 106838.89891156142, \tValid Loss :  21279.955512631044 , Time : 0.04899125901283696\n",
      "\t\tErrorPercent on sample:  0.6833333333333333 ErrorThreshold:  0.722\n",
      "Iteration 2 : Train Accuracy : 0.26164, \tValid  Accuracy : 0.2707,\t Train Loss : 106857.96045766973, \tValid Loss :  21283.5995140957 , Time : 0.0636680269963108\n",
      "\t\tErrorPercent on sample:  0.5575 ErrorThreshold:  0.6859\n",
      "Iteration 3 : Train Accuracy : 0.3598, \tValid  Accuracy : 0.384,\t Train Loss : 102390.6732491153, \tValid Loss :  20320.453019215416 , Time : 10.055391487956513\n",
      "\t\tErrorPercent on sample:  0.524 ErrorThreshold:  0.6516049999999999\n",
      "Iteration 4 : Train Accuracy : 0.40052, \tValid  Accuracy : 0.4208,\t Train Loss : 92234.6489429849, \tValid Loss :  18110.93197567271 , Time : 0.08942485402803868\n",
      "\t\tErrorPercent on sample:  0.5383333333333333 ErrorThreshold:  0.6190247499999999\n",
      "Iteration 5 : Train Accuracy : 0.40038, \tValid  Accuracy : 0.4208,\t Train Loss : 92218.84072937869, \tValid Loss :  18107.322477505466 , Time : 0.10209011501865461\n",
      "\t\tErrorPercent on sample:  0.5485714285714286 ErrorThreshold:  0.5880735124999998\n",
      "Iteration 6 : Train Accuracy : 0.40038, \tValid  Accuracy : 0.4208,\t Train Loss : 92218.79575300377, \tValid Loss :  18107.31221076688 , Time : 0.1156942350207828\n",
      "\t\tErrorPercent on sample:  0.55625 ErrorThreshold:  0.5586698368749998\n",
      "Iteration 7 : Train Accuracy : 0.43024, \tValid  Accuracy : 0.4487,\t Train Loss : 92667.37302365, \tValid Loss :  18205.9496876263 , Time : 7.307628330017906\n",
      "\t\tErrorPercent on sample:  0.4144444444444444 ErrorThreshold:  0.5307363450312498\n",
      "Iteration 8 : Train Accuracy : 0.56432, \tValid  Accuracy : 0.5881,\t Train Loss : 83253.71039856774, \tValid Loss :  16253.707582140178 , Time : 0.14317441399907693\n",
      "\t\tErrorPercent on sample:  0.42200000000000004 ErrorThreshold:  0.5041995277796872\n",
      "Iteration 9 : Train Accuracy : 0.56436, \tValid  Accuracy : 0.5882,\t Train Loss : 83247.10976869623, \tValid Loss :  16252.235262255841 , Time : 0.15384785900823772\n",
      "\t\tErrorPercent on sample:  0.42727272727272725 ErrorThreshold:  0.4789895513907029\n",
      "Iteration 10 : Train Accuracy : 0.56436, \tValid  Accuracy : 0.5882,\t Train Loss : 83247.0978127991, \tValid Loss :  16252.23259528753 , Time : 0.17495489498833194\n",
      "\t\tErrorPercent on sample:  0.43166666666666664 ErrorThreshold:  0.45504007382116773\n",
      "Iteration 11 : Train Accuracy : 0.56436, \tValid  Accuracy : 0.5882,\t Train Loss : 83247.09779287275, \tValid Loss :  16252.232590842601 , Time : 0.19991365098394454\n",
      "\t\tErrorPercent on sample:  0.40076923076923077 ErrorThreshold:  0.43228807013010934\n",
      "Iteration 12 : Train Accuracy : 0.53832, \tValid  Accuracy : 0.5661,\t Train Loss : 79653.42933915902, \tValid Loss :  15520.167502314518 , Time : 22.338822193967644\n",
      "\t\tErrorPercent on sample:  0.40714285714285714 ErrorThreshold:  0.41067366662360383\n",
      "Iteration 13 : Train Accuracy : 0.53844, \tValid  Accuracy : 0.566,\t Train Loss : 79628.57665678213, \tValid Loss :  15514.997946169575 , Time : 0.2506532829720527\n",
      "\t\tErrorPercent on sample:  0.3853333333333333 ErrorThreshold:  0.3901399832924236\n",
      "Iteration 14 : Train Accuracy : 0.56976, \tValid  Accuracy : 0.5879,\t Train Loss : 70694.94140218881, \tValid Loss :  13654.679621541434 , Time : 6.76643261697609\n",
      "\t\tErrorPercent on sample:  0.338125 ErrorThreshold:  0.37063298412780243\n",
      "Iteration 15 : Train Accuracy : 0.6386, \tValid  Accuracy : 0.6705,\t Train Loss : 62684.259937338415, \tValid Loss :  12073.307444443572 , Time : 0.2812801169930026\n",
      "\t\tErrorPercent on sample:  0.33705882352941174 ErrorThreshold:  0.3521013349214123\n",
      "Iteration 16 : Train Accuracy : 0.63856, \tValid  Accuracy : 0.6704,\t Train Loss : 62682.51429593337, \tValid Loss :  12072.953919097945 , Time : 0.3402741789468564\n",
      "\t\tErrorPercent on sample:  0.33444444444444443 ErrorThreshold:  0.33449626817534167\n",
      "Iteration 17 : Train Accuracy : 0.63856, \tValid  Accuracy : 0.6704,\t Train Loss : 62682.512366200346, \tValid Loss :  12072.953528786788 , Time : 0.4192543250392191\n",
      "\t\tErrorPercent on sample:  0.28315789473684205 ErrorThreshold:  0.3177714547665746\n",
      "Iteration 18 : Train Accuracy : 0.68538, \tValid  Accuracy : 0.7146,\t Train Loss : 60378.97801468913, \tValid Loss :  11600.296461916667 , Time : 9.564649370964617\n",
      "\t\tErrorPercent on sample:  0.24050000000000005 ErrorThreshold:  0.30188288202824587\n",
      "Iteration 19 : Train Accuracy : 0.73118, \tValid  Accuracy : 0.7597,\t Train Loss : 48571.10485711706, \tValid Loss :  9206.883610301895 , Time : 39.3744380690041\n",
      "\t\tErrorPercent on sample:  0.24238095238095236 ErrorThreshold:  0.28678873792683357\n",
      "Iteration 20 : Train Accuracy : 0.73122, \tValid  Accuracy : 0.7598,\t Train Loss : 48559.608268673226, \tValid Loss :  9204.532746420446 , Time : 0.33414464199449867\n",
      "\t\tErrorPercent on sample:  0.24 ErrorThreshold:  0.27244930103049186\n",
      "Iteration 21 : Train Accuracy : 0.73122, \tValid  Accuracy : 0.7598,\t Train Loss : 48559.59785974298, \tValid Loss :  9204.530617695204 , Time : 0.3475792810204439\n",
      "\t\tErrorPercent on sample:  0.241304347826087 ErrorThreshold:  0.2588268359789673\n",
      "Iteration 22 : Train Accuracy : 0.73122, \tValid  Accuracy : 0.7598,\t Train Loss : 48559.59785069168, \tValid Loss :  9204.530615844144 , Time : 0.3631031670374796\n",
      "\t\tErrorPercent on sample:  0.23958333333333337 ErrorThreshold:  0.2458854941800189\n",
      "Iteration 23 : Train Accuracy : 0.73122, \tValid  Accuracy : 0.7598,\t Train Loss : 48559.59785068415, \tValid Loss :  9204.530615842603 , Time : 0.3838106609764509\n",
      "\t\tErrorPercent on sample:  0.21440000000000003 ErrorThreshold:  0.23359121947101794\n",
      "Iteration 24 : Train Accuracy : 0.76386, \tValid  Accuracy : 0.7904,\t Train Loss : 42194.77003587672, \tValid Loss :  7924.148829809362 , Time : 6.233181386021897\n",
      "\t\tErrorPercent on sample:  0.19769230769230772 ErrorThreshold:  0.22191165849746702\n",
      "Iteration 25 : Train Accuracy : 0.78038, \tValid  Accuracy : 0.8043,\t Train Loss : 37059.534752568376, \tValid Loss :  6923.509931722158 , Time : 7.3690752210095525\n",
      "\t\tErrorPercent on sample:  0.17962962962962958 ErrorThreshold:  0.21081607557259366\n",
      "Iteration 26 : Train Accuracy : 0.78306, \tValid  Accuracy : 0.8053,\t Train Loss : 41345.72104784944, \tValid Loss :  7848.647309794004 , Time : 45.866898105014116\n",
      "\t\tErrorPercent on sample:  0.18071428571428572 ErrorThreshold:  0.20027527179396395\n",
      "Iteration 27 : Train Accuracy : 0.7831, \tValid  Accuracy : 0.8053,\t Train Loss : 41342.51231312592, \tValid Loss :  7847.908163619326 , Time : 0.4441601219587028\n",
      "\t\tErrorPercent on sample:  0.17862068965517242 ErrorThreshold:  0.19026150820426574\n",
      "Iteration 28 : Train Accuracy : 0.7831, \tValid  Accuracy : 0.8053,\t Train Loss : 41342.51010518204, \tValid Loss :  7847.907654979836 , Time : 0.45491917501203716\n",
      "\t\tErrorPercent on sample:  0.17800000000000005 ErrorThreshold:  0.18074843279405245\n",
      "Iteration 29 : Train Accuracy : 0.7831, \tValid  Accuracy : 0.8053,\t Train Loss : 41342.51010371018, \tValid Loss :  7847.907654640747 , Time : 0.4736094690160826\n",
      "\t\tErrorPercent on sample:  0.1412903225806451 ErrorThreshold:  0.1717110111543498\n",
      "Iteration 30 : Train Accuracy : 0.83096, \tValid  Accuracy : 0.8479,\t Train Loss : 31823.47411584601, \tValid Loss :  5926.721941043172 , Time : 21.60924718400929\n",
      "\t\tErrorPercent on sample:  0.14 ErrorThreshold:  0.1631254605966323\n",
      "Iteration 31 : Train Accuracy : 0.83096, \tValid  Accuracy : 0.848,\t Train Loss : 31823.496170666567, \tValid Loss :  5926.747151621774 , Time : 0.48603398399427533\n",
      "\t\tErrorPercent on sample:  0.14060606060606062 ErrorThreshold:  0.15496918756680067\n",
      "Iteration 32 : Train Accuracy : 0.83096, \tValid  Accuracy : 0.848,\t Train Loss : 31823.49618814136, \tValid Loss :  5926.747167561266 , Time : 0.6255930970073678\n",
      "\t\tErrorPercent on sample:  0.14117647058823535 ErrorThreshold:  0.14722072818846063\n",
      "Iteration 33 : Train Accuracy : 0.83096, \tValid  Accuracy : 0.848,\t Train Loss : 31823.496188151672, \tValid Loss :  5926.747167570639 , Time : 0.6761532530072145\n",
      "\t\tErrorPercent on sample:  0.12828571428571434 ErrorThreshold:  0.1398596917790376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34 : Train Accuracy : 0.84466, \tValid  Accuracy : 0.8622,\t Train Loss : 28346.790711102418, \tValid Loss :  5167.807284004782 , Time : 13.285712484037504\n",
      "\t\tErrorPercent on sample:  0.1280555555555556 ErrorThreshold:  0.1328667071900857\n",
      "Iteration 35 : Train Accuracy : 0.84512, \tValid  Accuracy : 0.861,\t Train Loss : 26539.218590904195, \tValid Loss :  4843.461712721951 , Time : 44.28299803700065\n",
      "\t\tErrorPercent on sample:  0.11054054054054052 ErrorThreshold:  0.1262233718305814\n",
      "Iteration 36 : Train Accuracy : 0.85648, \tValid  Accuracy : 0.872,\t Train Loss : 25127.618580896382, \tValid Loss :  4580.237540164983 , Time : 22.480579782044515\n",
      "\t\tErrorPercent on sample:  0.1110526315789474 ErrorThreshold:  0.11991220323905233\n",
      "Iteration 37 : Train Accuracy : 0.85654, \tValid  Accuracy : 0.8719,\t Train Loss : 25127.888073738734, \tValid Loss :  4580.263596582722 , Time : 0.5676208170480095\n",
      "\t\tErrorPercent on sample:  0.11076923076923073 ErrorThreshold:  0.11391659307709971\n",
      "Iteration 38 : Train Accuracy : 0.85654, \tValid  Accuracy : 0.8719,\t Train Loss : 25127.888212510697, \tValid Loss :  4580.263610039066 , Time : 0.5779478129697964\n",
      "\t\tErrorPercent on sample:  0.09750000000000003 ErrorThreshold:  0.10822076342324471\n",
      "Iteration 39 : Train Accuracy : 0.8705, \tValid  Accuracy : 0.886,\t Train Loss : 22502.597329933436, \tValid Loss :  4072.745075589225 , Time : 12.807818412024062\n",
      "\t\tErrorPercent on sample:  0.10121951219512193 ErrorThreshold:  0.10280972525208247\n",
      "Iteration 40 : Train Accuracy : 0.86882, \tValid  Accuracy : 0.8856,\t Train Loss : 22089.490496170565, \tValid Loss :  3977.114761353334 , Time : 0.6803591209463775\n",
      "\t\tErrorPercent on sample:  0.09666666666666668 ErrorThreshold:  0.09766923898947834\n",
      "Iteration 41 : Train Accuracy : 0.87322, \tValid  Accuracy : 0.887,\t Train Loss : 21492.23587453512, \tValid Loss :  3861.8804868110424 , Time : 14.073011094005778\n",
      "\t\tErrorPercent on sample:  0.08372093023255811 ErrorThreshold:  0.09278577704000442\n",
      "Iteration 42 : Train Accuracy : 0.8832, \tValid  Accuracy : 0.8994,\t Train Loss : 19779.94245428637, \tValid Loss :  3521.6455465782674 , Time : 22.58407628297573\n",
      "\t\tErrorPercent on sample:  0.08363636363636362 ErrorThreshold:  0.08814648818800419\n",
      "Iteration 43 : Train Accuracy : 0.88316, \tValid  Accuracy : 0.8994,\t Train Loss : 19779.533109164324, \tValid Loss :  3521.56365360676 , Time : 0.6652861370239407\n",
      "\t\tErrorPercent on sample:  0.0822222222222222 ErrorThreshold:  0.08373916377860398\n",
      "Iteration 44 : Train Accuracy : 0.88572, \tValid  Accuracy : 0.9007,\t Train Loss : 19199.692140206, \tValid Loss :  3407.3146107625917 , Time : 6.542302682995796\n",
      "\t\tErrorPercent on sample:  0.07869565217391306 ErrorThreshold:  0.07955220558967377\n",
      "Iteration 45 : Train Accuracy : 0.88756, \tValid  Accuracy : 0.9001,\t Train Loss : 18869.471724356998, \tValid Loss :  3350.8982859381554 , Time : 14.281196500000078\n",
      "\t\tErrorPercent on sample:  0.07382978723404254 ErrorThreshold:  0.07557459531019008\n",
      "Iteration 46 : Train Accuracy : 0.89608, \tValid  Accuracy : 0.9081,\t Train Loss : 17605.107908041373, \tValid Loss :  3134.234918307164 , Time : 58.42313945898786\n",
      "\t\tErrorPercent on sample:  0.06937499999999996 ErrorThreshold:  0.07179586554468056\n",
      "Iteration 47 : Train Accuracy : 0.90078, \tValid  Accuracy : 0.9109,\t Train Loss : 16837.85955210923, \tValid Loss :  2997.1189603811104 , Time : 21.592253062000964\n",
      "\t\tErrorPercent on sample:  0.06632653061224492 ErrorThreshold:  0.06820607226744653\n",
      "Iteration 48 : Train Accuracy : 0.90208, \tValid  Accuracy : 0.9136,\t Train Loss : 16440.01920426516, \tValid Loss :  2927.5077770567445 , Time : 23.024524844950065\n",
      "\t\tErrorPercent on sample:  0.06440000000000001 ErrorThreshold:  0.0647957686540742\n",
      "Iteration 49 : Train Accuracy : 0.90304, \tValid  Accuracy : 0.916,\t Train Loss : 16209.766791477277, \tValid Loss :  2892.525471779763 , Time : 14.137833667977247\n",
      "\t\tErrorPercent on sample:  0.060196078431372535 ErrorThreshold:  0.06155598022137049\n",
      "Iteration 50 : Train Accuracy : 0.90578, \tValid  Accuracy : 0.915,\t Train Loss : 15881.355619626924, \tValid Loss :  2829.4739771073246 , Time : 21.75200538401259\n",
      "\t\tErrorPercent on sample:  0.058076923076923026 ErrorThreshold:  0.05847818121030196\n",
      "Iteration 51 : Train Accuracy : 0.90896, \tValid  Accuracy : 0.921,\t Train Loss : 15157.5076399962, \tValid Loss :  2706.503166606464 , Time : 36.84981974802213\n",
      "\t\tErrorPercent on sample:  0.05528301886792453 ErrorThreshold:  0.05555427214978686\n",
      "Iteration 52 : Train Accuracy : 0.91096, \tValid  Accuracy : 0.9206,\t Train Loss : 14777.074990529767, \tValid Loss :  2636.6035825844315 , Time : 15.612552666978445\n",
      "\t\tErrorPercent on sample:  0.05203703703703699 ErrorThreshold:  0.052776558542297514\n",
      "Iteration 53 : Train Accuracy : 0.91432, \tValid  Accuracy : 0.9243,\t Train Loss : 14215.710894132244, \tValid Loss :  2558.0072837203197 , Time : 51.54278122901451\n",
      "\t\tErrorPercent on sample:  0.04854545454545456 ErrorThreshold:  0.05013773061518263\n",
      "Iteration 54 : Train Accuracy : 0.9163, \tValid  Accuracy : 0.9258,\t Train Loss : 13858.931922225705, \tValid Loss :  2496.23268466224 , Time : 54.69137699302519\n",
      "\t\tErrorPercent on sample:  0.04749999999999999 ErrorThreshold:  0.0476308440844235\n",
      "Iteration 55 : Train Accuracy : 0.91642, \tValid  Accuracy : 0.9251,\t Train Loss : 13887.503351666259, \tValid Loss :  2496.9611361489347 , Time : 10.48811294999905\n",
      "\t\tErrorPercent on sample:  0.04456140350877191 ErrorThreshold:  0.045249301880202326\n",
      "Iteration 56 : Train Accuracy : 0.9178, \tValid  Accuracy : 0.9259,\t Train Loss : 13682.249901370631, \tValid Loss :  2476.9700966580413 , Time : 25.55186240799958\n",
      "\t\tErrorPercent on sample:  0.04293103448275859 ErrorThreshold:  0.04298683678619221\n",
      "Iteration 57 : Train Accuracy : 0.9199, \tValid  Accuracy : 0.9281,\t Train Loss : 13330.760883803301, \tValid Loss :  2409.7550918979728 , Time : 39.61700134596322\n",
      "\t\tErrorPercent on sample:  0.0394915254237288 ErrorThreshold:  0.040837494946882595\n",
      "Iteration 58 : Train Accuracy : 0.92088, \tValid  Accuracy : 0.9286,\t Train Loss : 13187.188120542647, \tValid Loss :  2400.0047007543526 , Time : 32.541182334010955\n",
      "\t\tErrorPercent on sample:  0.03849999999999998 ErrorThreshold:  0.038795620199538465\n",
      "Iteration 59 : Train Accuracy : 0.92218, \tValid  Accuracy : 0.929,\t Train Loss : 12994.56613401235, \tValid Loss :  2355.270012885373 , Time : 23.811162581958342\n",
      "\t\tErrorPercent on sample:  0.03836065573770486 ErrorThreshold:  0.038795620199538465\n",
      "Iteration 60 : Train Accuracy : 0.92202, \tValid  Accuracy : 0.9296,\t Train Loss : 13064.89493716516, \tValid Loss :  2372.098009285894 , Time : 1.4323776780511253\n",
      "\t\tErrorPercent on sample:  0.03806451612903228 ErrorThreshold:  0.038795620199538465\n",
      "Iteration 61 : Train Accuracy : 0.92202, \tValid  Accuracy : 0.9296,\t Train Loss : 13064.95995067688, \tValid Loss :  2372.111421891289 , Time : 1.2157806559698656\n",
      "\t\tErrorPercent on sample:  0.03857142857142859 ErrorThreshold:  0.038795620199538465\n",
      "Iteration 62 : Train Accuracy : 0.9221, \tValid  Accuracy : 0.9289,\t Train Loss : 13109.826781612952, \tValid Loss :  2373.0555671187212 , Time : 17.46410411101533\n",
      "\t\tErrorPercent on sample:  0.038124999999999964 ErrorThreshold:  0.038795620199538465\n",
      "Iteration 63 : Train Accuracy : 0.9228, \tValid  Accuracy : 0.9304,\t Train Loss : 12981.641599395021, \tValid Loss :  2356.3886354827937 , Time : 1.1952448569936678\n",
      "\t\tErrorPercent on sample:  0.03876923076923078 ErrorThreshold:  0.038795620199538465\n",
      "Iteration 64 : Train Accuracy : 0.9228, \tValid  Accuracy : 0.9304,\t Train Loss : 12981.6561664206, \tValid Loss :  2356.393385491793 , Time : 1.121679136005696\n",
      "\t\tErrorPercent on sample:  0.038787878787878816 ErrorThreshold:  0.038795620199538465\n",
      "Iteration 65 : Train Accuracy : 0.9228, \tValid  Accuracy : 0.9304,\t Train Loss : 12981.656170835417, \tValid Loss :  2356.3933869330635 , Time : 1.2625142720062286\n",
      "\t\tErrorPercent on sample:  0.03746268656716423 ErrorThreshold:  0.038795620199538465\n",
      "Iteration 66 : Train Accuracy : 0.9221, \tValid  Accuracy : 0.9287,\t Train Loss : 13058.296751148395, \tValid Loss :  2357.468717280734 , Time : 15.752863291010726\n",
      "\t\tErrorPercent on sample:  0.038088235294117645 ErrorThreshold:  0.038795620199538465\n",
      "Iteration 67 : Train Accuracy : 0.92348, \tValid  Accuracy : 0.9304,\t Train Loss : 12800.551272940387, \tValid Loss :  2329.083515102508 , Time : 1.5139988819719292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tErrorPercent on sample:  0.038115942028985494 ErrorThreshold:  0.038795620199538465\n",
      "Iteration 68 : Train Accuracy : 0.9237, \tValid  Accuracy : 0.9301,\t Train Loss : 12781.798778080005, \tValid Loss :  2319.0566974184217 , Time : 6.997113585006446\n",
      "\t\tErrorPercent on sample:  0.03785714285714281 ErrorThreshold:  0.038795620199538465\n",
      "Iteration 69 : Train Accuracy : 0.92494, \tValid  Accuracy : 0.9341,\t Train Loss : 12557.190196289204, \tValid Loss :  2269.9109127521815 , Time : 77.10921359597705\n"
     ]
    }
   ],
   "source": [
    "trainLogRetroT = train_loopRetroApproxT(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphique et analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francoisdavid/miniconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py:128: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(calculatesTimes(trainLogSG[\"time\"]), trainLogSG[\"train_lossSG\"] , color='Blue')\n",
    "plt.plot(calculatesTimes(trainLogFD[\"time\"]), trainLogFD[\"train_lossFD\"], color ='Red' )\n",
    "plt.plot(calculatesTimes(trainLogSAG[\"time\"][:800]), trainLogSAG[\"train_lossFD\"][:800] ,color='Pink')\n",
    "plt.plot(calculatesTimes(trainLogRetro[\"time\"]), trainLogRetro[\"train_lossFD\"] , color='Yellow')\n",
    "\n",
    "plt.xlabel('Temps en Secondes')\n",
    "plt.ylabel('Erreur d\\'entropie croisée')\n",
    "\n",
    "plt.legend([\"Stochastic Gradient\", \"Finite  Gradient\" , \"Stochastic Average Gradient\", \"Retrospective Appoximation\"])\n",
    "plt.title(\"Convergence de l'erreur d\\'entropie croisée des 3 algorithmes sur le dataset MNIST\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que, au départ, cette technique adaptée du \"Retrospective Approximation\" converge rapidement vers l'optimum avant de se diriger de manière plutôt constante tel l'algorithme du SAG. L'algorithme du Retrospective Approximation a toutefois une plus  grande erreur que le SAG sur tout le graphique. À quelques reprises, lorsque la taille de l'échantillon augmente, l'algorithme prend un lap de temps considérable à obtenir une solution (qui satisfait le seuil d'erreur voulu) dépendamment des nouvelles données dans l'échantillon de chaque itération. Naturellement, plus l'échantillon est grand, plus le temps d'une itération augmente pour obtenir un niveau de perfomance désiré. Le coût d'itération est donc dépendent des nouvelles données dans l'échantillon analyser. À cause que de nouveaux échantillons moins représentatifs de l'ensemble des données ont quelquesfois augmenté la fonction optimale que nous désirons minimiser, ce pour quoi une technique de \"Early-Stopping\" serait adéquate s'il n'est pas possible d'exécuter l'algorithme pour une longue période de temps afin d'obtenir l'optimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En bout de ligne, alors que la  taille de l'échantillon grandit, celui-ci devient plus représentatif de l'ensemble et on obtient une meilleure solution pour l'ensemble de fonctions/paires d'entrainement. Lorsque la taille de l'échantillon évalué devient égale (ou similaire) à la taille de l'ensemble des données d'apprentissage, l'algorithme agit un peu comme le Finite Gradient puisqu'il calcule le gradient idéal en prenant en compte le gradient des itérations antérieures. Cependant, à ce point dans l'algorithme, prendre en compte le gradient des itérations antérieures n'est probablement pas avantageux puisque l'échantillon comporte déjà toutes (ou presque) les données de l'ensemble. Les anciens gradients deviennentt donc une information désuète et le gradient calculé durant l'itération présente est probablement une meilleure estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SG Temps pour 1000 itérations:  0.7366669293014857  secondes\n",
      "FD Temps pour 1 itération:  15.659318439675554  secondes\n",
      "SAG Temps pour 1000 itérations:  1.6737234646915748  secondes\n",
      "RetroApprox Temps pour 1 itération:  12.728815621713874  secondes\n"
     ]
    }
   ],
   "source": [
    "print(\"SG Temps pour 1000 itérations: \", np.array(trainLogSG[\"time\"]).mean() * 1000 , \" secondes\")\n",
    "print(\"FD Temps pour 1 itération: \", np.array(trainLogFD[\"time\"]).mean(), \" secondes\")\n",
    "print(\"SAG Temps pour 1000 itérations: \", np.array(trainLogSAG[\"time\"][:800]).mean(), \" secondes\")\n",
    "print(\"RetroApprox Temps pour 1 itération: \", np.array(trainLogRetro[\"time\"]).mean(), \" secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au départ, puisque l'échantillon est très petit, les itérations sont très rapide. Cependant, lorsque l'échantillon est grand, si les nouvelles paires de données de celui-ci sont plus ou moins similaires aux données antérieures, l'algorithme peut prendre un laps de temps considérable. C'est pour cette raison qu'une itération prend (dans notre cas) presque autant de temps qu'une de l'algorithme du Finite Difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainLogRetro[\"time\"], color='Blue')\n",
    "\n",
    "plt.xlabel('Itérations')\n",
    "plt.ylabel('Temps par itération')\n",
    "\n",
    "plt.legend([\"Retrospective Appoximation\"])\n",
    "plt.title(\"Convergence de l'erreur d\\'entropie croisée des 3 algorithmes sur le dataset MNIST\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous pouvons voir, certaines itérations prennent un laps de temps minime en comparaison à d'autres lorsque les nouvelles données/fonctions de l'échantillon sont mal représentées par les données antérieures de l'échantillon. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francoisdavid/miniconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py:128: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(calculatesTimes(trainLogSG[\"time\"]), trainLogSG[\"validation_lossSG\"] , color='Blue')\n",
    "plt.plot(calculatesTimes(trainLogFD[\"time\"]), trainLogFD[\"validation_lossFD\"], color ='Red' )\n",
    "plt.plot(calculatesTimes(trainLogSAG[\"time\"][:800]), trainLogSAG[\"validation_lossFD\"][:800] ,color='Pink')\n",
    "plt.plot(calculatesTimes(trainLogRetro[\"time\"]), trainLogRetro[\"validation_lossFD\"] , color='Yellow')\n",
    "\n",
    "plt.xlabel('Temps en Secondes')\n",
    "plt.ylabel('Erreur d\\'entropie croisée')\n",
    "\n",
    "plt.legend([\"Stochastic Gradient\", \"Finite  Gradient\" , \"Stochastic Average Gradient\", \"Retrospective Appoximation\"])\n",
    "plt.title(\"Convergence de l'erreur d\\'entropie croisée des 3 algorithmes sur le dataset MNIST\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que l'évaluation de l'algorithme sur l'ensemble de validation démontre les mêmes tendances qu'avec l'ensemble d'entrainement. Donc cela signifie que les tendances sont représentatives des données similaires au MNIST et le modèle peut performer de manière similaire sur de nouvelles images du même type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il serait intéressant d'explorer certains ajustements des paramètres pour améliorer la convergence de cet algorithme. Quoiqu'il ne soit pas aussi performant que le SAG, il semble prometteur puisque l'algorithme converge assez rapidement vers le minimum espéré. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
